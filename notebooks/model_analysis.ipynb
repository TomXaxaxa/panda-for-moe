{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/run-400/checkpoint-final\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_weights(model, key: str) -> list[dict[str, torch.Tensor]]:\n",
    "    params = [\n",
    "        {\n",
    "            \"Wq\": getattr(l, key).q_proj.weight,\n",
    "            \"Wk\": getattr(l, key).k_proj.weight,\n",
    "            \"Wv\": getattr(l, key).v_proj.weight,\n",
    "        }\n",
    "        for l in model.model.model.encoder.layers  # lol\n",
    "    ]\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_attn_map(\n",
    "    weights: list[dict[str, torch.Tensor]], index: int, shift: bool = False\n",
    ") -> np.ndarray:\n",
    "    attn_map = (weights[index][\"Wq\"] @ weights[index][\"Wk\"].T).detach().cpu().numpy()\n",
    "    if shift:\n",
    "        attn_map = (attn_map - np.min(attn_map)) / (np.max(attn_map) - np.min(attn_map))\n",
    "    return attn_map\n",
    "\n",
    "\n",
    "def symmetric_distance(attn_map: np.ndarray) -> float:\n",
    "    return (\n",
    "        0.5\n",
    "        * np.linalg.norm(attn_map - attn_map.T, \"fro\")\n",
    "        / np.linalg.norm(attn_map, \"fro\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_weights = get_attn_weights(pft_model, \"temporal_self_attn\")\n",
    "channel_weights = get_attn_weights(pft_model, \"channel_self_attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(temporal_weights, 0)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(channel_weights, 0)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = pft_model.model.model.encoder.layers[0].ff\n",
    "print(llayer)\n",
    "ffw = llayer[0].weight.detach().cpu().numpy()\n",
    "print(symmetric_distance(ffw))\n",
    "\n",
    "U, S, V = np.linalg.svd(ffw)\n",
    "threshold = 1e-3\n",
    "rank = np.sum(S > threshold)\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(S) + 1), S, \"o-\", linewidth=2)\n",
    "plt.title(\"Scree Plot of Singular Values\")\n",
    "plt.xlabel(\"Singular Value Index\")\n",
    "plt.ylabel(\"Singular Value Magnitude\")\n",
    "plt.grid(True)\n",
    "plt.yscale(\"log\")  # Log scale to better visualize the decay\n",
    "plt.axhline(\n",
    "    y=threshold, color=\"r\", linestyle=\"--\", label=f\"Threshold ({threshold:.1e})\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "reconstructed = U[:, :rank] @ np.diag(S)[:rank, :rank] @ V[:rank, :]\n",
    "plt.figure()\n",
    "plt.imshow(np.log(reconstructed**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    attn_map = get_attn_map(temporal_weights, i)\n",
    "    ax.imshow(attn_map, cmap=\"RdBu\")\n",
    "    ax.set_title(f\"Layer {i}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"pretrain\",\n",
    "    pretrain_path=\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/mlm40_stand_nonoiser-1/checkpoint-final\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_weights = get_attn_weights(mlm_model, \"channel_self_attn\")\n",
    "temporal_weights = get_attn_weights(mlm_model, \"temporal_self_attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(temporal_weights, 3)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(channel_weights, 3)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    attn_map = get_attn_map(channel_weights, i)\n",
    "    ax.imshow(attn_map, cmap=\"RdBu\")\n",
    "    ax.set_title(f\"Layer {i}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
