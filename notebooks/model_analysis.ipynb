{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import plot_trajs_multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_weights(model, key: str) -> list[dict[str, torch.Tensor]]:\n",
    "    params = [\n",
    "        {\n",
    "            \"Wq\": getattr(l, key).q_proj.weight,\n",
    "            \"Wk\": getattr(l, key).k_proj.weight,\n",
    "            \"Wv\": getattr(l, key).v_proj.weight,\n",
    "        }\n",
    "        for l in model.model.model.encoder.layers  # lol\n",
    "    ]\n",
    "    return params\n",
    "\n",
    "\n",
    "def get_attn_map(\n",
    "    weights: list[dict[str, torch.Tensor]], index: int, shift: bool = False\n",
    ") -> np.ndarray:\n",
    "    attn_map = (weights[index][\"Wq\"] @ weights[index][\"Wk\"].T).detach().cpu().numpy()\n",
    "    if shift:\n",
    "        attn_map = (attn_map - np.min(attn_map)) / (np.max(attn_map) - np.min(attn_map))\n",
    "    return attn_map\n",
    "\n",
    "\n",
    "def symmetric_distance(attn_map: np.ndarray) -> float:\n",
    "    return (\n",
    "        0.5\n",
    "        * np.linalg.norm(attn_map - attn_map.T, \"fro\")\n",
    "        / np.linalg.norm(attn_map, \"fro\")\n",
    "    )  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_weights = get_attn_weights(pft_model, \"temporal_self_attn\")\n",
    "channel_weights = get_attn_weights(pft_model, \"channel_self_attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(temporal_weights, 0)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_map = get_attn_map(channel_weights, 0)\n",
    "print(symmetric_distance(attn_map))\n",
    "plt.figure()\n",
    "plt.imshow(np.log(attn_map**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llayer = pft_model.model.model.encoder.layers[0].ff\n",
    "print(llayer)\n",
    "ffw = llayer[0].weight.detach().cpu().numpy()\n",
    "print(symmetric_distance(ffw))\n",
    "\n",
    "U, S, V = np.linalg.svd(ffw)\n",
    "threshold = 1e-3\n",
    "rank = np.sum(S > threshold)\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(S) + 1), S, \"o-\", linewidth=2)\n",
    "plt.title(\"Scree Plot of Singular Values\")\n",
    "plt.xlabel(\"Singular Value Index\")\n",
    "plt.ylabel(\"Singular Value Magnitude\")\n",
    "plt.grid(True)\n",
    "plt.yscale(\"log\")  # Log scale to better visualize the decay\n",
    "plt.axhline(\n",
    "    y=threshold, color=\"r\", linestyle=\"--\", label=f\"Threshold ({threshold:.1e})\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "reconstructed = U[:, :rank] @ np.diag(S)[:rank, :rank] @ V[:rank, :]\n",
    "plt.figure()\n",
    "plt.imshow(np.log(reconstructed**2), cmap=\"RdBu\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    attn_map = get_attn_map(temporal_weights, i)\n",
    "    ax.imshow(attn_map, cmap=\"RdBu\")\n",
    "    ax.set_title(f\"Layer {i}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attn_map(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    patch_size: int,\n",
    "    sample_idx: int,\n",
    "    layer_idx: int,\n",
    "    head_idx: int,\n",
    "    prefix: str = \"\",\n",
    ") -> None:\n",
    "    \"\"\"Plot attention matrix with corresponding timeseries patches along edges.\"\"\"\n",
    "    attention_type = \"temporal\" if layer_idx % 2 == 0 else \"channel\"\n",
    "    patches = context.reshape(context.shape[0], -1, patch_size)\n",
    "    if attention_type == \"channel\":\n",
    "        patches = patches.transpose(1, 0, 2)\n",
    "\n",
    "    context_tensor = torch.from_numpy(context.T).float().to(pft_model.device)[None, ...]\n",
    "    pred = model(context_tensor, output_attentions=True)\n",
    "    attn_weights = pred.attentions\n",
    "\n",
    "    # Extract attention weights for specified sample, layer and head\n",
    "    num_samples = attn_weights[layer_idx].shape[0]\n",
    "    attn = attn_weights[layer_idx][sample_idx, head_idx].detach().cpu().numpy()\n",
    "    n_patches = attn.shape[0]\n",
    "\n",
    "    # Create figure with gridspec layout\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # Create main grid with padding for colorbar\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[1, 0.05], wspace=0.05)\n",
    "\n",
    "    # Create sub-grid for the plots\n",
    "    gs = outer_grid[0].subgridspec(\n",
    "        2, 2, width_ratios=[0.15, 0.85], height_ratios=[0.15, 0.85], wspace=0, hspace=0\n",
    "    )\n",
    "\n",
    "    # Plot attention matrix first to get its size\n",
    "    ax_main = fig.add_subplot(gs[1, 1])\n",
    "    im = ax_main.imshow(attn, extent=(0, n_patches, n_patches, 0))\n",
    "    ax_main.set_xticks([])\n",
    "    ax_main.set_yticks([])\n",
    "\n",
    "    # Plot patches along top\n",
    "    ax_top = fig.add_subplot(gs[0, 1])\n",
    "    for i in range(n_patches):\n",
    "        x = np.linspace(i, i + 1, patch_size)\n",
    "        ax_top.plot(x, patches[sample_idx, i], linewidth=1)\n",
    "    ax_top.set_xlim(0, n_patches)\n",
    "    ax_top.set_xticks([])\n",
    "    ax_top.set_yticks([])\n",
    "    ax_top.grid(True)\n",
    "\n",
    "    # Plot patches along left side\n",
    "    ax_left = fig.add_subplot(gs[1, 0])\n",
    "    for i in range(n_patches):\n",
    "        y = np.linspace(i, i + 1, patch_size)\n",
    "        ax_left.plot(-patches[sample_idx, i], y, linewidth=1)\n",
    "    ax_left.set_ylim(n_patches, 0)\n",
    "    ax_left.set_xticks([])\n",
    "    ax_left.set_yticks([])\n",
    "    ax_left.grid(True)\n",
    "\n",
    "    # Add colorbar\n",
    "    ax_cbar = fig.add_subplot(outer_grid[1])\n",
    "    plt.colorbar(im, cax=ax_cbar)\n",
    "\n",
    "    # Remove empty subplot\n",
    "    fig.delaxes(fig.add_subplot(gs[0, 0]))\n",
    "\n",
    "    # Force exact alignment of subplots\n",
    "    main_pos = ax_main.get_position()\n",
    "    ax_top.set_position(\n",
    "        [main_pos.x0, main_pos.y1, main_pos.width, ax_top.get_position().height]  # type: ignore\n",
    "    )\n",
    "    ax_left.set_position(\n",
    "        [\n",
    "            ax_left.get_position().x0,\n",
    "            main_pos.y0,\n",
    "            ax_left.get_position().width,\n",
    "            main_pos.height,\n",
    "        ]  # type: ignore\n",
    "    )\n",
    "    ax_cbar.set_position(\n",
    "        [\n",
    "            ax_cbar.get_position().x0,\n",
    "            main_pos.y0,\n",
    "            ax_cbar.get_position().width,\n",
    "            main_pos.height,\n",
    "        ]  # type: ignore\n",
    "    )\n",
    "    sample_type = \"channel\" if attention_type == \"temporal\" else \"patch\"\n",
    "    ax_top.set_title(\n",
    "        f\"{prefix}{attention_type} attention @ layer {layer_idx}, head {head_idx}, ({sample_type} {sample_idx + 1}/{num_samples})\"\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dystformer.utils import get_system_filepaths, load_trajectory_from_arrow\n",
    "\n",
    "dyst_name = \"Lorenz\"\n",
    "test_data_dirs = \"/stor/work/AMDG_Gilpin_Summer2024/data/final_base40\"\n",
    "syspaths = get_system_filepaths(dyst_name, test_data_dirs, \"train\")\n",
    "\n",
    "sample_idx = 0\n",
    "trajectory, _ = load_trajectory_from_arrow(syspaths[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attn_map(\n",
    "    pft_model.model,\n",
    "    trajectory[:, :1024],\n",
    "    16,\n",
    "    sample_idx=1,\n",
    "    layer_idx=0,\n",
    "    head_idx=1,\n",
    "    prefix=syspaths[0].parent.stem + \" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_prediction(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    groundtruth: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    title: str | None = None,\n",
    "    save_path: str | None = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    context_tensor = torch.from_numpy(context.T).float().to(pft_model.device)[None, ...]\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    total_length = context.shape[1] + prediction_length\n",
    "    context_ts = np.arange(context.shape[1]) / total_length\n",
    "    pred_ts = np.arange(context.shape[1], total_length) / total_length\n",
    "\n",
    "    # Create figure with gridspec layout\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "    # Create main grid with padding for colorbar\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "\n",
    "    # Create sub-grid for the plots\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context, alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth, linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*pred.T, color=\"red\", label=\"Prediction\")\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")  # type: ignore\n",
    "    ax_3d.get_legend().remove() if ax_3d.get_legend() else None\n",
    "    handles, labels = ax_3d.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax_3d.legend(by_label.values(), by_label.keys(), loc=\"upper right\", fontsize=8)\n",
    "    if title is not None:\n",
    "        title_name = title.replace(\"_\", \" \")\n",
    "        ax_3d.set_title(title_name, fontweight=\"bold\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(context_ts, context[i], alpha=0.5, color=\"black\")\n",
    "        ax.plot(pred_ts, groundtruth[i], linestyle=\"--\", color=\"black\")\n",
    "        ax.plot(pred_ts, pred[:, i], color=\"red\")\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "    # plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "pred_length = 512\n",
    "start_time = 2048\n",
    "end_time = start_time + context_length\n",
    "plot_model_prediction(\n",
    "    pft_model,\n",
    "    trajectory[:, start_time:end_time],  # context\n",
    "    trajectory[:, end_time : end_time + pred_length],  # ground truth\n",
    "    pred_length,\n",
    "    limit_prediction_length=False,\n",
    "    title=dyst_name,\n",
    "    save_path=os.path.join(\n",
    "        \"figs\",\n",
    "        run_name,\n",
    "        dyst_name,\n",
    "        f\"{dyst_name}_sample{sample_idx}_context{start_time}-{end_time}_pred{pred_length}_.pdf\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "pred_length = 256\n",
    "start_time = 128\n",
    "end_time = start_time + context_length\n",
    "plot_model_prediction(\n",
    "    pft_model,\n",
    "    trajectory[:, start_time:end_time],  # context\n",
    "    trajectory[:, end_time : end_time + pred_length],  # ground truth\n",
    "    pred_length,\n",
    "    limit_prediction_length=False,\n",
    "    title=dyst_name,\n",
    "    save_path=os.path.join(\n",
    "        \"figs\",\n",
    "        run_name,\n",
    "        dyst_name,\n",
    "        f\"{dyst_name}_sample{sample_idx}_context{start_time}-{end_time}_pred{pred_length}_.pdf\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyst_name = \"HyperXu_SprottF\"\n",
    "split = \"final_skew40\"\n",
    "subsplit = \"test_zeroshot\"\n",
    "test_data_dirs = f\"/stor/work/AMDG_Gilpin_Summer2024/data/copy/{split}\"\n",
    "syspaths = get_system_filepaths(dyst_name, test_data_dirs, subsplit)\n",
    "\n",
    "sample_idx = 0\n",
    "trajectory, _ = load_trajectory_from_arrow(syspaths[sample_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_subsampled = trajectory[:, ::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trajs_multivariate(np.expand_dims(traj_subsampled, axis=0), show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "pred_length = 128\n",
    "start_time = 2048\n",
    "end_time = start_time + context_length\n",
    "\n",
    "save_path = os.path.join(\n",
    "    \"figs\",\n",
    "    run_name,\n",
    "    split,\n",
    "    subsplit,\n",
    "    dyst_name,\n",
    "    f\"{dyst_name}_sample{sample_idx}_context{start_time}-{end_time}_pred{pred_length}_.pdf\",\n",
    ")\n",
    "\n",
    "plot_model_prediction(\n",
    "    pft_model,\n",
    "    traj_subsampled[:, start_time:end_time],  # context\n",
    "    traj_subsampled[:, end_time : end_time + pred_length],  # ground truth\n",
    "    pred_length,\n",
    "    limit_prediction_length=False,\n",
    "    # sliding_context=True,\n",
    "    title=dyst_name,\n",
    "    save_path=None,  # save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
