{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_name = \"pft_stand_rff_univariate-0\"\n",
    "# run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "# run_name = \"pft_linattn_noemb_from_scratch-0\"\n",
    "run_name = \"pft_chattn_fullemb_pretrained-0\"\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SineND:\n",
    "    freqs: list[float]\n",
    "    ts: np.ndarray\n",
    "\n",
    "    def __call__(self, s: float):\n",
    "        return np.array([np.sin(2 * np.pi * s * f * self.ts) for f in self.freqs])\n",
    "\n",
    "\n",
    "ts = np.linspace(0, 1, 4096)\n",
    "incomm_fn = SineND([1.0, np.pi, np.pi**2], ts)\n",
    "comm_fn = SineND([1, 3, 9], ts)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "gs = fig.add_gridspec(\n",
    "    2, 2, height_ratios=[0.5, 0.5], width_ratios=[0.4, 0.6], wspace=0.2, hspace=0\n",
    ")\n",
    "ax = fig.add_subplot(gs[:, 0], projection=\"3d\")\n",
    "ax.plot3D(*incomm_fn(1), color=\"blue\", label=\"incomm\")\n",
    "ax.plot3D(*comm_fn(1), color=\"orange\", label=\"comm\")\n",
    "ax.legend()\n",
    "for i, d in enumerate([incomm_fn(1), comm_fn(1)]):\n",
    "    ax = fig.add_subplot(gs[i, 1])\n",
    "    for j in range(3):\n",
    "        ax.plot(ts, d[j], color=[\"blue\", \"orange\"][i])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_attn_map_sequence(\n",
    "    model,\n",
    "    series_generator,\n",
    "    series_params: np.ndarray,\n",
    "    context_length: int,\n",
    "    channel_idx: int,\n",
    "    head_idx: int,\n",
    "    patch_size: int,\n",
    "    colormap=\"magma\",\n",
    "    show_title=True,\n",
    "    save_path: str | None = None,\n",
    "    fps: int = 30,\n",
    "    linear_attn: bool = False,\n",
    "):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from IPython.display import HTML\n",
    "    from matplotlib.animation import FuncAnimation\n",
    "    from matplotlib.gridspec import GridSpec\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    gs = GridSpec(3, 4, figure=fig, height_ratios=[1, 2, 2])\n",
    "\n",
    "    ax_ts = fig.add_subplot(gs[0, :])\n",
    "    ax_ts.set_xlim(0, 1)\n",
    "    ax_ts.set_xticks([])\n",
    "    ax_ts.set_yticks([])\n",
    "    (line,) = ax_ts.plot([], [])  # Empty line for time series\n",
    "\n",
    "    # Create attention map axes\n",
    "    axes = []\n",
    "    im_list = []\n",
    "    for i in range(8):\n",
    "        row = (i // 4) + 1  # Start from row 1 (after time series)\n",
    "        col = i % 4\n",
    "        ax = fig.add_subplot(gs[row, col])\n",
    "        im = ax.imshow(np.zeros((context_length, context_length)), cmap=colormap)\n",
    "        ax.set_axis_off()\n",
    "        ax.set_title(f\"Layer {2 * i}\")\n",
    "        axes.append(ax)\n",
    "        im_list.append(im)\n",
    "\n",
    "    attnmaps = np.zeros(\n",
    "        (len(series_params), 8, context_length // 16, context_length // 16)\n",
    "    )\n",
    "    ts = np.linspace(0, 1, context_length + 128)\n",
    "\n",
    "    def update(frame):\n",
    "        param = series_params[frame]\n",
    "        series = series_generator(param)\n",
    "        context = series[:, :context_length]\n",
    "\n",
    "        context_tensor = torch.from_numpy(context.T).float().to(model.device)[None, ...]\n",
    "        pred = model(context_tensor, output_attentions=True, linear_attn=linear_attn)\n",
    "        attn_weights = pred.attentions\n",
    "\n",
    "        for i, ax in enumerate(axes):\n",
    "            attnmap = (\n",
    "                attn_weights[(1 if len(attn_weights) == 8 else 2) * i][\n",
    "                    channel_idx, head_idx\n",
    "                ]\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            attnmaps[frame, i, :, :] = attnmap\n",
    "            im_list[i].set_array(attnmap)\n",
    "            vmin, vmax = attnmap.min(), attnmap.max()\n",
    "            im_list[i].set_clim(vmin, vmax)\n",
    "\n",
    "        # plot context and prediction\n",
    "        pred_channel = pred.prediction_outputs[0, :, channel_idx].detach().cpu().numpy()\n",
    "        ax_ts.clear()\n",
    "\n",
    "        for i in range(1, context_length // patch_size + 1):\n",
    "            boundary = i * patch_size\n",
    "            if boundary < context_length + 1:\n",
    "                ax_ts.axvline(\n",
    "                    x=float(ts[boundary]), color=\"gray\", linestyle=\":\", alpha=0.5\n",
    "                )\n",
    "\n",
    "        ax_ts.plot(ts[:context_length], context[channel_idx], color=\"black\")\n",
    "        ax_ts.plot(\n",
    "            ts[context_length:],\n",
    "            series[channel_idx, context_length : context_length + 128],\n",
    "            color=\"black\",\n",
    "            linestyle=\"--\",\n",
    "        )\n",
    "        ax_ts.plot(ts[context_length:], pred_channel, color=\"red\")\n",
    "        ax_ts.set_xlim(0, 1)\n",
    "        ax_ts.set_xticks([])\n",
    "        ax_ts.set_yticks([])\n",
    "        ax_ts.set_title(\n",
    "            f\"Input Time Series head {head_idx} channel {channel_idx} param={param:.3f}\"\n",
    "        )\n",
    "\n",
    "        return im_list\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig,\n",
    "        update,\n",
    "        frames=len(series_params),\n",
    "        interval=1000 / fps,\n",
    "        blit=True,\n",
    "    )\n",
    "\n",
    "    if save_path is not None:\n",
    "        anim.save(\n",
    "            save_path,\n",
    "            writer=\"pillow\" if save_path.endswith(\".gif\") else \"ffmpeg\",\n",
    "            fps=fps,\n",
    "        )\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.close()\n",
    "        display(HTML(anim.to_jshtml()))\n",
    "\n",
    "    return attnmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_idx = 2\n",
    "channel_idx = 2\n",
    "\n",
    "params = np.linspace(20, 30, 50)\n",
    "attnmaps = temporal_attn_map_sequence(\n",
    "    pft_model.model,\n",
    "    incomm_fn,\n",
    "    params,\n",
    "    context_length=512,\n",
    "    channel_idx=channel_idx,\n",
    "    head_idx=head_idx,\n",
    "    patch_size=16,\n",
    "    fps=5,\n",
    "    save_path=f\"../figures/interp_{run_name}_{channel_idx}_{head_idx}.mp4\",\n",
    "    linear_attn=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(attnmaps, axis=(2, 3), ord=\"fro\")\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "print(norms.shape)\n",
    "for i in range(8):\n",
    "    sc = plt.plot(params, norms[:, i], color=plt.cm.tab10(i), label=f\"Layer {2 * i}\")\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", alpha=0.7)\n",
    "plt.title(\"Attention Map Norm\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_attn_maps(\n",
    "    model,\n",
    "    series: np.ndarray,\n",
    "    context_length: int,\n",
    "    linear_attn: bool = False,\n",
    "):\n",
    "    context = series[:, :context_length]\n",
    "    if context.ndim == 1:\n",
    "        context = context[None, ...]\n",
    "    context_tensor = torch.from_numpy(context).float().to(model.device)\n",
    "    pred = model(\n",
    "        context_tensor[:, -context_length:, :],\n",
    "        output_attentions=True,\n",
    "        linear_attn=linear_attn,\n",
    "    )\n",
    "    return pred.attentions\n",
    "\n",
    "\n",
    "def interaction_index(\n",
    "    matrix: np.ndarray, axes: tuple[int, int] = (-2, -1)\n",
    ") -> float | np.ndarray:\n",
    "    fronorm = np.linalg.norm(matrix, axis=axes, ord=\"fro\")\n",
    "    twonorm = np.linalg.norm(matrix, axis=axes, ord=2)\n",
    "    return (fronorm - twonorm) / fronorm\n",
    "\n",
    "\n",
    "def mean_row_entropy(\n",
    "    matrix: np.ndarray, axis: int = -1, eps: float = 1e-10\n",
    ") -> float | np.ndarray:\n",
    "    assert np.allclose(matrix.sum(axis=axis), 1), (\n",
    "        \"All rows must be a probability distribution\"\n",
    "    )\n",
    "    return -np.sum(matrix * np.log(matrix + eps), axis=axis).mean(axis=axis)\n",
    "\n",
    "\n",
    "def fronorm(matrix: np.ndarray, axes: tuple[int, int] = (-2, -1)) -> float | np.ndarray:\n",
    "    return np.linalg.norm(matrix, axis=axes, ord=\"fro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN UNLESS YOU DONT HAVE BISPECTRA.NPY\n",
    "@dataclass\n",
    "class TwoToneSine:\n",
    "    freqs1: np.ndarray\n",
    "    freqs2: np.ndarray\n",
    "    base_freq: float\n",
    "    ts: np.ndarray\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.indices = np.arange(self.freqs1.shape[0] * self.freqs2.shape[0])\n",
    "        self.basewave = np.sin(2 * np.pi * self.base_freq * self.ts)\n",
    "\n",
    "    @property\n",
    "    def dims(self) -> int:\n",
    "        return 3\n",
    "\n",
    "    def product_array_indices(self, s: slice) -> tuple[np.ndarray, ...]:\n",
    "        return np.unravel_index(\n",
    "            self.indices[s], (self.freqs1.shape[0], self.freqs2.shape[0])\n",
    "        )\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.freqs1.shape[0] * self.freqs2.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int | slice) -> np.ndarray:\n",
    "        if isinstance(idx, int):\n",
    "            i = idx % self.freqs1.shape[0]\n",
    "            j = idx // self.freqs1.shape[0]\n",
    "            return np.array(\n",
    "                [\n",
    "                    np.sin(2 * np.pi * self.freqs1[i] * self.ts),\n",
    "                    np.sin(2 * np.pi * self.freqs2[j] * self.ts),\n",
    "                    np.sin(2 * np.pi * self.base_freq * self.ts),\n",
    "                ]\n",
    "            ).T\n",
    "        elif isinstance(idx, slice):\n",
    "            idxi, idxj = self.product_array_indices(idx)\n",
    "            return np.stack(\n",
    "                [\n",
    "                    np.sin(2 * np.pi * self.freqs1[idxi, None] * self.ts),\n",
    "                    np.sin(2 * np.pi * self.freqs2[idxj, None] * self.ts),\n",
    "                    self.basewave[None, :].repeat(len(idxi), axis=0),\n",
    "                ],\n",
    "                axis=-1,\n",
    "            )\n",
    "\n",
    "\n",
    "resolution = 1024\n",
    "freqs = np.linspace(1, 50, resolution)\n",
    "series_fn = TwoToneSine(freqs, freqs, 10, np.linspace(0, 1, 1024))\n",
    "\n",
    "bispectra = np.zeros((8, resolution * resolution, 3, 8))\n",
    "channel_idx = 1\n",
    "head_idx = 7\n",
    "batch_size = 2048\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for batch in trange(resolution * resolution // batch_size):\n",
    "    series_batch = series_fn[batch * batch_size : (batch + 1) * batch_size]\n",
    "    attn_weights = extract_attn_maps(\n",
    "        pft_model.model,\n",
    "        series_batch,\n",
    "        512,\n",
    "        linear_attn=False,\n",
    "    )\n",
    "    for i in range(8):\n",
    "        attnmap = attn_weights[2 * i].detach().cpu().numpy()\n",
    "        attnmap = attnmap.reshape(batch_size, 3, 8, 32, 32)\n",
    "        response = fronorm(attnmap)\n",
    "        bispectra[i, batch * batch_size : (batch + 1) * batch_size] = response\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "bispectra = bispectra.reshape(-1, resolution, resolution, 3, 8)\n",
    "\n",
    "np.save(\"bispectra.npy\", bispectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bispectra = np.load(\"bispectra.npy\")\n",
    "\n",
    "bispectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_idx = 0\n",
    "head_idx = 2\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "for i in range(8):\n",
    "    axes[i // 4, i % 4].imshow(\n",
    "        bispectra[i, :, :, channel_idx, head_idx], origin=\"lower\"\n",
    "    )\n",
    "    axes[i // 4, i % 4].set_title(f\"Layer {2 * i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bispectra_across_checkpoints(\n",
    "    series_fn,\n",
    "    checkpoint_dir: str,\n",
    "    context_length: int = 512,\n",
    "    batch_size: int = 2048,\n",
    "    figsize: tuple[int, int] = (20, 10),\n",
    "    dims: int | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the bispectra across all checkpoints in the given directory.\n",
    "\n",
    "    Assumes that the checkpoint directory contains checkpoint-{i} folders for i in [0, 1, 2, ...]\n",
    "    and a single checkpoint-final folder.\n",
    "    \"\"\"\n",
    "    if dims is None:\n",
    "        assert hasattr(series_fn, \"dims\"), (\n",
    "            \"series_fn must have a dims attribute if dims is not provided\"\n",
    "        )\n",
    "    dims = dims or series_fn.dims\n",
    "\n",
    "    checkpoints = os.listdir(checkpoint_dir)\n",
    "    checkpoints.remove(\"checkpoint-final\")\n",
    "    checkpoints = sorted(checkpoints, key=lambda x: int(x.split(\"-\")[-1]))\n",
    "\n",
    "    for checkpoint in tqdm(checkpoints, desc=\"Processing checkpoints\"):\n",
    "        model = PatchTSTPipeline.from_pretrained(\n",
    "            mode=\"predict\",\n",
    "            pretrain_path=f\"{checkpoint_dir}/{checkpoint}\",\n",
    "            device_map=\"cuda:0\",\n",
    "        )\n",
    "        num_heads = model.model.config.num_attention_heads\n",
    "        num_tokens = context_length // model.model.config.patch_length\n",
    "\n",
    "        attnmap_shape = (batch_size, dims, num_heads, num_tokens, num_tokens)\n",
    "\n",
    "        bispectra = np.zeros(\n",
    "            (model.model.config.num_hidden_layers, resolution * resolution, dims, 8)\n",
    "        )\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        for batch in trange(resolution * resolution // batch_size):\n",
    "            attn_weights = extract_attn_maps(\n",
    "                model.model,\n",
    "                series_fn[batch * batch_size : (batch + 1) * batch_size],\n",
    "                context_length,\n",
    "                linear_attn=False,\n",
    "            )\n",
    "            for i in range(8):\n",
    "                attnmap = (\n",
    "                    attn_weights[2 * i].detach().cpu().numpy().reshape(attnmap_shape)\n",
    "                )\n",
    "                response = fronorm(attnmap)\n",
    "                bispectra[i, batch * batch_size : (batch + 1) * batch_size] = response\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        bispectra = bispectra.reshape(-1, resolution, resolution, 3, 8)\n",
    "\n",
    "        # cleanup manually\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    print(checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = os.environ[\"WORK\"]\n",
    "plot_bispectra_across_checkpoints(\n",
    "    series_fn,\n",
    "    f\"{workdir}/checkpoints/pft_chattn_fullemb_pretrained-0\",\n",
    "    figsize=(20, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
