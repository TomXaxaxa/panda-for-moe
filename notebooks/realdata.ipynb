{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import safe_standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/pft_chattn_emb_w_poly-0/checkpoint-final\",\n",
    "    device_map=\"cuda:1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_start_and_stride(\n",
    "    model,\n",
    "    data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    ntrials=100,\n",
    "    start_buffer_proportion=0.5,\n",
    "    min_strided_pts=10,\n",
    "):\n",
    "    def satisfied(start, stride):\n",
    "        return (data.shape[0] - start) / stride >= context_length + prediction_length\n",
    "\n",
    "    def objective(start, stride):\n",
    "        strided_data = data[start::stride]\n",
    "        context = (\n",
    "            torch.from_numpy(strided_data[:context_length]).float().to(model.device)\n",
    "        )\n",
    "        future = strided_data[context_length : context_length + prediction_length]\n",
    "        pred = (\n",
    "            model.predict(context, prediction_length).squeeze().detach().cpu().numpy()\n",
    "        )\n",
    "        return np.linalg.norm(pred - future)\n",
    "\n",
    "    def sample_start_and_stride():\n",
    "        valid_length = data.shape[0] - context_length - prediction_length\n",
    "        start_buffer_length = int(valid_length * start_buffer_proportion)\n",
    "        start = np.random.randint(0, valid_length - start_buffer_length)\n",
    "        stride = np.random.randint(1, (valid_length - start) // min_strided_pts)\n",
    "        return start, stride\n",
    "\n",
    "    best_cost = np.inf\n",
    "    best_start = None\n",
    "    best_stride = None\n",
    "    for trial in range(ntrials):\n",
    "        start, stride = sample_start_and_stride()\n",
    "        while not satisfied(start, stride):\n",
    "            start, stride = sample_start_and_stride()\n",
    "\n",
    "        cost = objective(start, stride)\n",
    "        if cost < best_cost:\n",
    "            best_cost = cost\n",
    "            best_start = start\n",
    "            best_stride = stride\n",
    "\n",
    "    return best_start, best_stride, best_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    title: str | None = None,\n",
    "    show: bool = True,\n",
    "    transpose: bool = True,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    context = data[:, :context_length]\n",
    "    groundtruth = data[:, context_length : context_length + prediction_length]\n",
    "    context_tensor = torch.from_numpy(context.T if transpose else context).float()\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if not transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    total_length = context.shape[1] + prediction_length\n",
    "    context_ts = np.arange(context.shape[1]) / total_length\n",
    "    pred_ts = np.arange(context.shape[1], total_length) / total_length\n",
    "\n",
    "    if show:\n",
    "        fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "        outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "        gs = outer_grid[1].subgridspec(\n",
    "            3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0\n",
    "        )\n",
    "        ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "        ax_3d.plot(*context[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "        ax_3d.plot(*groundtruth[:3], linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "        ax_3d.plot(*pred.T[:3], color=\"red\", label=\"Prediction\")\n",
    "        ax_3d.legend(loc=\"upper right\", fontsize=12)\n",
    "        ax_3d.set_xlabel(\"$x_1$\")\n",
    "        ax_3d.set_ylabel(\"$x_2$\")\n",
    "        ax_3d.set_zlabel(\"$x_3$\")\n",
    "        if title is not None:\n",
    "            ax_3d.set_title(title)\n",
    "\n",
    "        axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "        for i, ax in enumerate(axes_1d):\n",
    "            ax.plot(context_ts, context[i], alpha=0.5, color=\"black\")\n",
    "            ax.plot(pred_ts, groundtruth[i], linestyle=\"--\", color=\"black\")\n",
    "            ax.plot(pred_ts, pred[:, i], color=\"red\")\n",
    "            ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "            ax.set_aspect(\"auto\")\n",
    "        axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start, best_stride, best_cost = optimize_start_and_stride(\n",
    "    pft_model, pendulum_data[:, :4], 512, 128, ntrials=500, start_buffer_proportion=0.4\n",
    ")\n",
    "print(best_start, best_stride, best_cost)\n",
    "subsampled_pendulum_data = pendulum_data[best_start::best_stride, -4:]\n",
    "stand_subsampled_pendulum_data = safe_standardize(subsampled_pendulum_data, axis=0)\n",
    "standpred = plot_model_prediction(\n",
    "    pft_model, stand_subsampled_pendulum_data.T, 512, 128, show=False\n",
    ")\n",
    "print(subsampled_pendulum_data.shape, pendulum_data.shape)\n",
    "pred = safe_standardize(\n",
    "    standpred, axis=0, context=subsampled_pendulum_data[:512], denormalize=True\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# ## The position of the pivot point (mostly constant)\n",
    "# plt.plot(stand_subsampled_pendulum_data[:512, 1], -stand_subsampled_pendulum_data[:512, 0], color=\"black\")\n",
    "# plt.plot(standpred[:, 1], -standpred[:, 0], color=\"black\")\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:512, 1],\n",
    "    -subsampled_pendulum_data[:512, 0],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[512 : 512 + 128, 1],\n",
    "    -subsampled_pendulum_data[512 : 512 + 128, 0],\n",
    "    color=\"blue\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.plot(pred[:, 1], -pred[:, 0], color=\"blue\")\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:512, 3],\n",
    "    -subsampled_pendulum_data[:512, 2],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[512 : 512 + 128, 3],\n",
    "    -subsampled_pendulum_data[512 : 512 + 128, 2],\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(pred[:, 3], -pred[:, 2], color=\"red\")\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=\"black\", alpha=0.5, label=\"Context\"),\n",
    "    Line2D([0], [0], color=\"black\", linestyle=\"--\", label=\"Ground Truth\"),\n",
    "    Line2D([0], [0], color=\"red\", label=\"Prediction\"),\n",
    "]\n",
    "plt.legend(handles=legend_elements)\n",
    "\n",
    "plt.title(\"Double Pendulum\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "context_ts = np.arange(512) / (512 + 128)\n",
    "pred_ts = np.arange(512, 512 + 128) / (512 + 128)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(context_ts, subsampled_pendulum_data[:512, i], color=\"black\", alpha=0.5)\n",
    "    ax.plot(\n",
    "        pred_ts,\n",
    "        subsampled_pendulum_data[512 : 512 + 128, i],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    ax.plot(pred_ts, pred[:, i], color=\"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 0\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)\n",
    "print(worm_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(worm_data[:1000, 0], worm_data[:1000, 1], worm_data[:1000, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "best_start, best_stride, best_cost = optimize_start_and_stride(\n",
    "    pft_model,\n",
    "    worm_data,\n",
    "    512,\n",
    "    128,\n",
    "    ntrials=500,\n",
    "    start_buffer_proportion=0.10,\n",
    "    min_strided_pts=100,\n",
    ")\n",
    "print(best_start, best_stride, best_cost)\n",
    "subsampled_worm_data = worm_data[best_start::best_stride, :]\n",
    "stand_subsampled_worm_data = safe_standardize(subsampled_worm_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    pft_model, stand_subsampled_worm_data.T, 512, 128, title=\"Eigenworm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbulent Boundary Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbpca_data = np.load(\n",
    "    f\"{base_dir}/turbulence/BLexp_Re980_pca10.pkl\", allow_pickle=True\n",
    ")\n",
    "print(turbpca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(turbpca_data[:, 0], turbpca_data[:, 1], turbpca_data[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start, best_stride, best_cost = optimize_start_and_stride(\n",
    "    pft_model,\n",
    "    turbpca_data,\n",
    "    512,\n",
    "    128,\n",
    "    ntrials=500,\n",
    "    start_buffer_proportion=0.10,\n",
    "    min_strided_pts=100,\n",
    ")\n",
    "print(best_start, best_stride, best_cost)\n",
    "subsampled_turbpca_data = turbpca_data[best_start::best_stride, :]\n",
    "stand_subsampled_turbpca_data = safe_standardize(subsampled_turbpca_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_turbpca_data.T,\n",
    "    512,\n",
    "    128,\n",
    "    title=\"Turbulent Boundary Layer PCA modes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Von Karman Street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Von Karman Street\n",
    "RE_VAL = 1200\n",
    "vortex_fpath = (\n",
    "    f\"{base_dir}/von_karman_street/vortex_street_vorticities_Re_{RE_VAL}_pca10.pkl\"\n",
    ")\n",
    "pod_fpath = f\"{base_dir}/von_karman_street/vortex_street_pod_Re_{RE_VAL}_long.npz\"\n",
    "vel_fpath = f\"{base_dir}/von_karman_street/vortex_street_velocities_Re_{RE_VAL}.npz\"\n",
    "vortex_data = np.load(vortex_fpath, allow_pickle=True)\n",
    "pod_data = np.load(pod_fpath, allow_pickle=True)\n",
    "vfield = np.load(vel_fpath, allow_pickle=True)\n",
    "print(vortex_data.shape, pod_data.shape, vfield.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(vortex_data[:, 0], vortex_data[:, 1], vortex_data[:, 2], linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_start, best_stride, best_cost = optimize_start_and_stride(\n",
    "    pft_model,\n",
    "    vortex_data,\n",
    "    512,\n",
    "    128,\n",
    "    ntrials=500,\n",
    "    start_buffer_proportion=0.90,\n",
    "    min_strided_pts=10,\n",
    ")\n",
    "print(best_start, best_stride, best_cost)\n",
    "subsampled_vortex_data = vortex_data[best_start::best_stride, :]\n",
    "stand_subsampled_vortex_data = safe_standardize(subsampled_vortex_data, axis=0)\n",
    "predictions = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_vortex_data.T,\n",
    "    512,\n",
    "    128,\n",
    "    title=\"Von Karman Vortex Sheet PCA modes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"{base_dir}/electrocardiogram/ecg_train.csv.gz\"\n",
    "ecg_data = np.loadtxt(fpath, delimiter=\",\")\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(ecg_data[:1000], ecg_data[1:1001], ecg_data[2:1002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "best_start, best_stride, best_cost = optimize_start_and_stride(\n",
    "    pft_model,\n",
    "    ecg_data[:, None],\n",
    "    context_length,\n",
    "    128,\n",
    "    ntrials=1000,\n",
    "    start_buffer_proportion=0.10,\n",
    "    min_strided_pts=100,\n",
    ")\n",
    "print(best_start, best_stride, best_cost)\n",
    "subsampled_ecg_data = ecg_data[best_start::best_stride]\n",
    "stand_subsampled_ecg_data = safe_standardize(subsampled_ecg_data, axis=0)\n",
    "standpred = plot_model_prediction(\n",
    "    pft_model, stand_subsampled_ecg_data[None, :], context_length, 128, show=False\n",
    ")\n",
    "pred = safe_standardize(\n",
    "    standpred, axis=0, context=subsampled_ecg_data[:context_length], denormalize=True\n",
    ")\n",
    "\n",
    "context_ts = np.arange(context_length) / (context_length + 128)\n",
    "pred_ts = np.arange(context_length, context_length + 128) / (context_length + 128)\n",
    "\n",
    "plt.title(\"ECG\")\n",
    "plt.plot(\n",
    "    context_ts,\n",
    "    subsampled_ecg_data[:context_length],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"context\",\n",
    ")\n",
    "plt.plot(\n",
    "    pred_ts,\n",
    "    subsampled_ecg_data[context_length : context_length + 128],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"groundtruth\",\n",
    ")\n",
    "plt.plot(pred_ts, pred, color=\"red\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timelag_embedding(data, lag, dims):\n",
    "    \"\"\"\n",
    "    Embed a univariate time series into a higher-dimensional space using time-lagged embedding.\n",
    "\n",
    "    Args:\n",
    "        data: Input data array (n_timesteps,)\n",
    "        lag: Time lag for embedding\n",
    "    \"\"\"\n",
    "    n_timesteps = data.shape[0]\n",
    "    embedded_data = np.zeros((n_timesteps - lag * (dims - 1), dims))\n",
    "    for i in range(dims):\n",
    "        embedded_data[:, i] = data[i * lag : i * lag + n_timesteps - lag * (dims - 1)]\n",
    "    return embedded_data\n",
    "\n",
    "\n",
    "ecg_lagged = timelag_embedding(ecg_data, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_ecg_lagged = safe_standardize(ecg_lagged, axis=0)\n",
    "predictions = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_ecg_lagged.T,\n",
    "    512,\n",
    "    128,\n",
    "    title=\"ECG Time-lagged embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_error_scaling(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    ntrials: int,\n",
    "    lags: list[int],\n",
    "    dims: list[int],\n",
    "):\n",
    "    errors = np.zeros((len(lags), len(dims)))\n",
    "    for i, lag in enumerate(lags):\n",
    "        for j, dim in enumerate(dims):\n",
    "            embedded_data = timelag_embedding(data, lag, dim)\n",
    "            for start in np.random.randint(\n",
    "                0, len(embedded_data) - context_length - prediction_length, size=ntrials\n",
    "            ):\n",
    "                context = embedded_data[start : start + context_length]\n",
    "                stand_context = safe_standardize(context, axis=0)\n",
    "                stand_predictions = plot_model_prediction(\n",
    "                    model,\n",
    "                    stand_context.T,\n",
    "                    context_length,\n",
    "                    prediction_length,\n",
    "                    show=False,\n",
    "                )\n",
    "                if stand_predictions.ndim == 1:\n",
    "                    stand_predictions = stand_predictions[:, None]\n",
    "                predictions = safe_standardize(\n",
    "                    stand_predictions, axis=0, context=context, denormalize=True\n",
    "                )\n",
    "                errors[i, j] += (\n",
    "                    np.linalg.norm(\n",
    "                        predictions\n",
    "                        - embedded_data[\n",
    "                            start + context_length : start\n",
    "                            + context_length\n",
    "                            + prediction_length\n",
    "                        ]\n",
    "                    )\n",
    "                    / dim\n",
    "                )\n",
    "    errors /= ntrials\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = np.arange(1, 11)\n",
    "dims = np.arange(1, 21)\n",
    "errors = lag_error_scaling(\n",
    "    pft_model, ecg_data, 512, 128, ntrials=10, lags=lags, dims=dims\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(errors)\n",
    "plt.yticks(range(len(lags)), lags)\n",
    "plt.xticks(range(len(dims)), dims)\n",
    "plt.ylabel(\"Lag\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.title(\"ECG Time-lagged embedding per-dimension error scaling\")\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "\n",
    "chronos = ChronosPipeline.from_pretrained(\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_mini_ft-0/checkpoint-final\",\n",
    "    device_map=\"cuda:5\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = plot_model_prediction(\n",
    "    chronos,\n",
    "    ecg_lagged.T,\n",
    "    512,\n",
    "    128,\n",
    "    show=True,\n",
    "    transpose=False,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrials = 10\n",
    "prediction_length = 128\n",
    "errors = np.zeros((len(lags), len(dims)))\n",
    "for i, lag in enumerate(lags):\n",
    "    for j, dim in enumerate(dims):\n",
    "        embedded_data = timelag_embedding(ecg_data, lag, dim)\n",
    "        for start in np.random.randint(\n",
    "            0, len(embedded_data) - context_length - prediction_length, size=ntrials\n",
    "        ):\n",
    "            print(f\"{lag=}, {dim=}, {start=}\")\n",
    "            context = embedded_data[start : start + context_length]\n",
    "            predictions = plot_model_prediction(\n",
    "                chronos,\n",
    "                context.T,\n",
    "                context_length,\n",
    "                prediction_length,\n",
    "                show=False,\n",
    "                transpose=False,\n",
    "                num_samples=1,\n",
    "                limit_prediction_length=False,\n",
    "            )\n",
    "            if predictions.ndim == 1:\n",
    "                predictions = predictions[:, None]\n",
    "            errors[i, j] += (\n",
    "                np.linalg.norm(\n",
    "                    predictions\n",
    "                    - embedded_data[\n",
    "                        start + context_length : start\n",
    "                        + context_length\n",
    "                        + prediction_length\n",
    "                    ]\n",
    "                )\n",
    "                / dim\n",
    "            )\n",
    "errors /= ntrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(errors)\n",
    "plt.yticks(range(len(lags)), lags)\n",
    "plt.xticks(range(len(dims)), dims)\n",
    "plt.ylabel(\"Lag\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.title(\"ECG Time-lagged embedding per-dimension error scaling\")\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
