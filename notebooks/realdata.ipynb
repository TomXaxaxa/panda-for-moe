{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import safe_standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../custom_style.mplstyle\"):\n",
    "    plt.style.use([\"ggplot\", \"../custom_style.mplstyle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "# run_name = \"pft_chattn_noembed_pretrained_correct-0\"  # chattn + mlm\n",
    "# run_name = \"pft_linattnpolyemb_from_scratch-0\"\n",
    "\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_finetune_stand_updated-0/checkpoint-final\",\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_mini_ft-0/checkpoint-final\",\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_bolt_mini-12/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=\"cuda:4\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast and Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    differenced: bool = False,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: The model to use for forecasting.\n",
    "        context: The context to forecast (n_timesteps, n_features)\n",
    "        context_length: The length of the context.\n",
    "        prediction_length: The length of the prediction.\n",
    "        transpose: Whether to transpose the data.\n",
    "\n",
    "    Returns:\n",
    "        The forecasted data (prediction_length, n_features)\n",
    "    \"\"\"\n",
    "    preprocessed_context = context.copy()\n",
    "\n",
    "    if differenced:\n",
    "        differenced_context = np.diff(preprocessed_context, axis=0)\n",
    "        preprocessed_context = differenced_context.copy()\n",
    "    if standardize:\n",
    "        preprocessed_context = safe_standardize(preprocessed_context, axis=0)\n",
    "\n",
    "    context_tensor = torch.from_numpy(\n",
    "        preprocessed_context.T if transpose else preprocessed_context\n",
    "    ).float()\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, verbose=False, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    if standardize:\n",
    "        pred = safe_standardize(\n",
    "            pred,\n",
    "            axis=0,\n",
    "            context=differenced_context if differenced else context,\n",
    "            denormalize=True,\n",
    "        )\n",
    "    if differenced:\n",
    "        pred = np.cumsum(pred, axis=0) + context[-1]\n",
    "\n",
    "    # prediction length may be shorter than model output length\n",
    "    return pred[:prediction_length, :]\n",
    "\n",
    "\n",
    "def compute_rollout_metrics(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    step: int = 64,\n",
    "    num_windows: int = 5,\n",
    "    metrics: list[str] = [\"mse\", \"mae\", \"smape\"],\n",
    "    **kwargs,\n",
    ") -> tuple[dict[str, np.ndarray], dict[str, np.ndarray], np.ndarray, list[np.ndarray]]:\n",
    "    full_metrics = defaultdict(\n",
    "        lambda: np.zeros((num_windows, prediction_length // step))\n",
    "    )\n",
    "    starts = np.random.randint(\n",
    "        0, len(data) - context_length - prediction_length, num_windows\n",
    "    )\n",
    "    predictions = []\n",
    "    for s in tqdm(range(num_windows), desc=\"Sampling contexts\", total=num_windows):\n",
    "        start = starts[s]\n",
    "        context = data[start : start + context_length]\n",
    "        prediction = forecast(model, context, prediction_length, **kwargs)\n",
    "        for i in range(0, prediction_length, step):\n",
    "            pred = prediction[i : i + step]\n",
    "\n",
    "            gt = data[start + context_length + i : start + context_length + i + step]\n",
    "            submetrics = compute_metrics(pred, gt, include=metrics)\n",
    "            for k, v in submetrics.items():\n",
    "                full_metrics[k][s, i // step] += v\n",
    "        predictions.append(prediction)\n",
    "    mean_metrics = {k: v.mean(axis=0) for k, v in full_metrics.items()}\n",
    "    std_metrics = {\n",
    "        k: v.std(axis=0) / np.sqrt(num_windows) for k, v in full_metrics.items()\n",
    "    }\n",
    "    return mean_metrics, std_metrics, starts, predictions\n",
    "\n",
    "\n",
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    color: str = \"red\",\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length]\n",
    "    groundtruth = data[context_length : context_length + prediction_length]\n",
    "    prediction = forecast(\n",
    "        model, context, prediction_length, transpose, standardize, **kwargs\n",
    "    )\n",
    "\n",
    "    total_length = context_length + prediction_length\n",
    "    context_ts = np.arange(context_length + 1)\n",
    "    pred_ts = np.arange(context_length, total_length)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context.T[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth.T[:3], linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*prediction.T[:3], color=color, label=\"Prediction\")\n",
    "    ax_3d.legend(loc=\"upper right\", fontsize=8)\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(context_ts, data[: context_length + 1, i], alpha=0.5, color=\"black\")\n",
    "        ax.plot(pred_ts, groundtruth[:, i], linestyle=\"--\", color=\"black\")\n",
    "        ax.plot(pred_ts, prediction[:, i], color=color)\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    data: np.ndarray,\n",
    "    predictions_dict: dict[str, np.ndarray],\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    figsize: tuple[int, int] = (6, 6),\n",
    "    legend_kwargs: dict[str, Any] = {},\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    context = data[: context_length + 1, :3]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :3]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax._axis3don = False\n",
    "\n",
    "    # Combine all data to find min/max bounds\n",
    "    all_data = [context, groundtruth] + [\n",
    "        pred[:, :3] for pred in predictions_dict.values()\n",
    "    ]\n",
    "    mins = np.array([d.min(axis=0) for d in all_data])\n",
    "    maxs = np.array([d.max(axis=0) for d in all_data])\n",
    "\n",
    "    xmin, ymin, zmin = np.min(mins, axis=0)\n",
    "    xmax, ymax, zmax = np.max(maxs, axis=0)\n",
    "\n",
    "    ax.xaxis.pane.set_visible(False)\n",
    "    ax.yaxis.pane.set_visible(False)\n",
    "    ax.zaxis.pane.set_visible(False)\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.plot3D(*context.T, alpha=0.1, color=\"black\", zorder=1)\n",
    "    ax.plot3D(\n",
    "        *groundtruth.T,\n",
    "        alpha=0.8,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=2,\n",
    "        label=\"Ground Truth\",\n",
    "    )\n",
    "    for model_name, prediction in predictions_dict.items():\n",
    "        ax.plot3D(\n",
    "            *prediction[:, :3].T,\n",
    "            label=model_name,\n",
    "            zorder=10 if model_name == \"Our Model\" else 1,\n",
    "        )\n",
    "    ax.legend(**legend_kwargs)\n",
    "\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        xmax - xmin,\n",
    "        0,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        -ymax + ymin,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        0,\n",
    "        zmax - zmin,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)\n",
    "\n",
    "# data is non-stationary, subsample and detrend it\n",
    "subsampled_pendulum_data = pendulum_data[::10, -4:]\n",
    "\n",
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "metrics = [\"mse\", \"mae\", \"smape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        subsampled_pendulum_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        subsampled_pendulum_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:context_length, 3],\n",
    "    -subsampled_pendulum_data[:context_length, 2],\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[context_length : context_length + prediction_length, 3],\n",
    "    -subsampled_pendulum_data[context_length : context_length + prediction_length, 2],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.plot(pft_prediction[:, 3], -pft_prediction[:, 2], color=\"red\")\n",
    "plt.plot(chronos_prediction[:, 3], -chronos_prediction[:, 2], color=\"blue\")\n",
    "\n",
    "steps = np.arange(0, prediction_length, step)\n",
    "axins = inset_axes(plt.gca(), width=\"40%\", height=\"20%\", loc=\"upper right\", borderpad=1)\n",
    "axins.plot(steps + step, pft_metrics[\"smape\"], color=\"red\")\n",
    "axins.plot(steps + step, chronos_metrics[\"smape\"], color=\"blue\")\n",
    "axins.set_ylabel(\"sMAPE\")\n",
    "axins.set_xlabel(\"Prediction Length\")\n",
    "axins.set_xticks([32, 64, 96, 128])\n",
    "axins.set_xlim(step, prediction_length);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "context_ts = np.arange(context_length + 1)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        context_ts,\n",
    "        subsampled_pendulum_data[: context_length + 1, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    ax.plot(\n",
    "        pred_ts,\n",
    "        subsampled_pendulum_data[\n",
    "            context_length : context_length + prediction_length, i\n",
    "        ],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.plot(pred_ts, pft_prediction[:, i], color=\"red\")\n",
    "    ax.plot(pred_ts, chronos_prediction[:, i], color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, pft_starts, pft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        pft_model,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        sliding_context=True,\n",
    "        limit_prediction_length=False,\n",
    "    )\n",
    ")\n",
    "chronos_mean_metrics, chronos_std_metrics, chronos_starts, chronos_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "total_ts = np.arange(len(subsampled_pendulum_data))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        total_ts,\n",
    "        subsampled_pendulum_data[:, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    for j, (c, p) in enumerate(zip(chronos_starts, pft_starts)):\n",
    "        pft_pred_ts = np.arange(\n",
    "            p + context_length, p + context_length + prediction_length\n",
    "        )\n",
    "        chronos_context_ts = np.arange(c, c + context_length)\n",
    "        chronos_pred_ts = np.arange(\n",
    "            c + context_length, c + context_length + prediction_length\n",
    "        )\n",
    "        ax.plot(pft_pred_ts, pft_predictions[j][:, i], color=\"red\", alpha=0.1)\n",
    "        ax.plot(chronos_pred_ts, chronos_predictions[j][:, i], color=\"blue\", alpha=0.1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "ts = np.arange(8, prediction_length + 8, 8)\n",
    "plt.plot(ts, pft_mean_metrics[\"smape\"], marker=\"o\", color=\"red\")\n",
    "plt.fill_between(\n",
    "    ts,\n",
    "    pft_mean_metrics[\"smape\"] - pft_std_metrics[\"smape\"],\n",
    "    pft_mean_metrics[\"smape\"] + pft_std_metrics[\"smape\"],\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.plot(ts, chronos_mean_metrics[\"smape\"], marker=\"o\", color=\"blue\")\n",
    "plt.fill_between(\n",
    "    ts,\n",
    "    chronos_mean_metrics[\"smape\"] - chronos_std_metrics[\"smape\"],\n",
    "    chronos_mean_metrics[\"smape\"] + chronos_std_metrics[\"smape\"],\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.xticks(ts)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)[2048::1]\n",
    "eigenworms = loadmat(f\"{base_dir}/worm_behavior/data/EigenWorms.mat\")[\"EigenWorms\"]\n",
    "\n",
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "print(worm_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "# def reconstruct_worm(coeffs, eigenworms, segment_length=1.0):\n",
    "#     \"\"\"\n",
    "#     Reconstruct a worm from its coefficients and the eigenworms.\n",
    "\n",
    "#     Args:\n",
    "#         coeffs: The coefficients of the worm (n_timesteps, n_eigenworms)\n",
    "#         eigenworms: The eigenworms (n_features, n_eigenworms)\n",
    "#         segment_length: The length of each segment of the worm.\n",
    "\n",
    "#     Returns:\n",
    "#         The reconstructed worm.\n",
    "#     \"\"\"\n",
    "#     T, nworms = coeffs.shape\n",
    "#     n_segments = eigenworms.shape[0]\n",
    "#     basis = eigenworms[:, :nworms]\n",
    "#     theta = coeffs @ basis.T\n",
    "\n",
    "#     x = np.zeros((T, n_segments + 1))\n",
    "#     y = np.zeros((T, n_segments + 1))\n",
    "#     x[:, 1:] = segment_length * np.cos(theta)\n",
    "#     y[:, 1:] = segment_length * np.sin(theta)\n",
    "\n",
    "#     return x.cumsum(axis=1), y.cumsum(axis=1)\n",
    "\n",
    "\n",
    "# def animate_worm(x, y, num_frames=200, interval=50, save_path=None):\n",
    "#     \"\"\"\n",
    "#     Create an animation of the worm's movement over time.\n",
    "\n",
    "#     Args:\n",
    "#         x: Array of x coordinates with shape (T, n_segments+1)\n",
    "#         y: Array of y coordinates with shape (T, n_segments+1)\n",
    "#         num_frames: Number of frames to include in the animation\n",
    "#         interval: Time between frames in milliseconds\n",
    "\n",
    "#     Returns:\n",
    "#         HTML animation that can be displayed in the notebook\n",
    "#     \"\"\"\n",
    "#     fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "#     # Set consistent axis limits for the animation\n",
    "#     x_min, x_max = x.min(), x.max()\n",
    "#     y_min, y_max = y.min(), y.max()\n",
    "\n",
    "#     # Add some padding to the limits\n",
    "#     x_padding = (x_max - x_min) * 0.1\n",
    "#     y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "#     ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "#     ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "#     ax.set_aspect(\"equal\")\n",
    "#     ax.set_title(\"Worm Movement\")\n",
    "\n",
    "#     # Create line and fill objects\n",
    "#     line = ax.plot([], [], \"b-\", lw=2)[0]\n",
    "#     fill = ax.fill([], [], color=\"blue\")\n",
    "#     time_text = ax.text(0.02, 0.95, \"\", transform=ax.transAxes)\n",
    "\n",
    "#     # Calculate width profile - increases toward middle, decreases toward ends\n",
    "#     n_points = x.shape[1]\n",
    "#     width_profile = np.zeros(n_points)\n",
    "#     max_width = 3  # Maximum width of the worm body\n",
    "#     for i in range(n_points):\n",
    "#         arg = 2 * i / (n_points - 1) - 1  # normalize to [-1, 1]\n",
    "#         width_profile[i] = max_width * (\n",
    "#             1\n",
    "#             / (1 + np.exp(-8 * (arg + 0.7)))\n",
    "#             * (1 - 1 / (1 + np.exp(-8 * (arg - 0.7))))\n",
    "#         )\n",
    "\n",
    "#     def init():\n",
    "#         line.set_data([], [])\n",
    "#         fill[0].set_xy(np.zeros((0, 2)))\n",
    "#         time_text.set_text(\"\")\n",
    "#         return line, fill[0], time_text\n",
    "\n",
    "#     def update(frame):\n",
    "#         # Update the centerline\n",
    "#         line.set_data(x[frame], y[frame])\n",
    "\n",
    "#         # Calculate perpendicular vectors for width\n",
    "#         dx = np.diff(x[frame])\n",
    "#         dy = np.diff(y[frame])\n",
    "#         # Normalize and rotate 90 degrees to get perpendicular direction\n",
    "#         lengths = np.sqrt(dx**2 + dy**2)\n",
    "#         nx = -dy / lengths\n",
    "#         ny = dx / lengths\n",
    "\n",
    "#         # Create polygon vertices for the worm body\n",
    "#         vertices = []\n",
    "\n",
    "#         # Top edge (add points from head to tail)\n",
    "#         for i in range(n_points - 1):\n",
    "#             vertices.append(\n",
    "#                 (\n",
    "#                     x[frame][i] + width_profile[i] * nx[i],\n",
    "#                     y[frame][i] + width_profile[i] * ny[i],\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         # Bottom edge (add points from tail to head)\n",
    "#         for i in range(n_points - 2, -1, -1):\n",
    "#             vertices.append(\n",
    "#                 (\n",
    "#                     x[frame][i] - width_profile[i] * nx[i],\n",
    "#                     y[frame][i] - width_profile[i] * ny[i],\n",
    "#                 )\n",
    "#             )\n",
    "\n",
    "#         # Update the fill\n",
    "#         fill[0].set_xy(vertices)\n",
    "#         time_text.set_text(f\"Frame: {frame}\")\n",
    "\n",
    "#         return line, fill[0], time_text\n",
    "\n",
    "#     # Use a subset of frames if there are too many\n",
    "#     total_frames = min(num_frames, len(x))\n",
    "#     frame_indices = np.linspace(0, len(x) - 1, total_frames, dtype=int)\n",
    "\n",
    "#     anim = FuncAnimation(\n",
    "#         fig, update, frames=frame_indices, init_func=init, blit=True, interval=interval\n",
    "#     )\n",
    "#     if save_path is not None:\n",
    "#         anim.save(save_path, writer=\"ffmpeg\")\n",
    "#     plt.close()\n",
    "#     return HTML(anim.to_jshtml())\n",
    "\n",
    "\n",
    "# # Create and display the animation\n",
    "# x, y = reconstruct_worm(worm_data, eigenworms)\n",
    "# worm_animation = animate_worm(x[:1000], y[:1000], save_path=\"../figures/wormanim.mp4\")\n",
    "\n",
    "# worm_animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Worms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    worm_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=True,\n",
    ")\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        worm_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos,\n",
    "    worm_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=True,\n",
    ")\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        worm_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    worm_data,\n",
    "    pft_prediction,\n",
    "    chronos_prediction,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    pft_metrics,\n",
    "    chronos_metrics,\n",
    "    step=step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    worm_data,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=True,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    worm_data,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    differenced=True,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, pft_starts, pft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        pft_model,\n",
    "        worm_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        sliding_context=True,\n",
    "        limit_prediction_length=False,\n",
    "        differenced=True,\n",
    "    )\n",
    ")\n",
    "chronos_mean_metrics, chronos_std_metrics, chronos_starts, chronos_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos,\n",
    "        worm_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        differenced=True,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "ts = np.arange(8, prediction_length + 8, 8)\n",
    "plt.plot(ts, pft_mean_metrics[\"smape\"], marker=\"o\", color=\"red\")\n",
    "plt.fill_between(\n",
    "    ts,\n",
    "    pft_mean_metrics[\"smape\"] - pft_std_metrics[\"smape\"],\n",
    "    pft_mean_metrics[\"smape\"] + pft_std_metrics[\"smape\"],\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.plot(ts, chronos_mean_metrics[\"smape\"], marker=\"o\", color=\"blue\")\n",
    "plt.fill_between(\n",
    "    ts,\n",
    "    chronos_mean_metrics[\"smape\"] - chronos_std_metrics[\"smape\"],\n",
    "    chronos_mean_metrics[\"smape\"] + chronos_std_metrics[\"smape\"],\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.ylabel(\"sMAPE\")\n",
    "plt.xticks(ts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbulent Boundary Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbpca_data = np.load(\n",
    "    f\"{base_dir}/turbulence/BLexp_Re980_pca10.pkl\", allow_pickle=True\n",
    ")\n",
    "subsampled_turbpca_data = turbpca_data[512::1]\n",
    "print(subsampled_turbpca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=True,\n",
    ")\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        turbpca_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos,\n",
    "    subsampled_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=True,\n",
    ")\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        turbpca_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    turbpca_data,\n",
    "    pft_prediction,\n",
    "    chronos_prediction,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    pft_metrics,\n",
    "    chronos_metrics,\n",
    "    step=step,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=True,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    differenced=True,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronic Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netfpath = f\"{base_dir}/electronic_circuit/Structure/Net_1.dat\"\n",
    "# fpath = f\"{base_dir}/electronic_circuit/R1/ST_0_3.dat\"\n",
    "fpath = f\"{base_dir}/electronic_circuit/R1/ST_50_3.dat\"\n",
    "net = np.loadtxt(netfpath)\n",
    "circuit_data = np.loadtxt(fpath)\n",
    "print(net.shape, circuit_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 64\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        circuit_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "chronos_ft_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_ft_prediction[0 : i + step],\n",
    "        circuit_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_ft_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_ft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_prediction = forecast(\n",
    "    chronos_zs,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "chronos_zs_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_zs_prediction[0 : i + step],\n",
    "        circuit_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_zs_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_zs_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    circuit_data,\n",
    "    {\n",
    "        \"Our Model\": pft_prediction,\n",
    "        \"Chronos 20M Finetune\": chronos_ft_prediction,\n",
    "        \"Chronos 20M\": chronos_zs_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    legend_kwargs={\"loc\": \"center right\", \"frameon\": True},\n",
    "    save_path=\"figs/circuit_comparison.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    circuit_data[start_time:],\n",
    "    512,\n",
    "    512,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_zs,\n",
    "    circuit_data[start_time:],\n",
    "    512,\n",
    "    512,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupling Strength Scaling Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify data by type {1, 2, 3} and sort by coupling strength\n",
    "fpaths = os.listdir(f\"{base_dir}/electronic_circuit/R1\")\n",
    "ec_fpaths = defaultdict(list)\n",
    "for fpath in fpaths:\n",
    "    ec_fpaths[int(fpath.split(\"_\")[2][0])].append(fpath)\n",
    "for k, v in ec_fpaths.items():\n",
    "    ec_fpaths[k] = sorted(v, key=lambda x: int(x.split(\"_\")[1]))\n",
    "print(ec_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_fpaths[3][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "pft_errors = {\n",
    "    k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()\n",
    "}\n",
    "chronos_errors = {\n",
    "    k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()\n",
    "}\n",
    "for k, v in tqdm(\n",
    "    ec_fpaths.items(), desc=\"Processing type-k circuit data\", total=len(ec_fpaths)\n",
    "):\n",
    "    for i, fpath in tqdm(\n",
    "        enumerate(v), desc=f\"Processing type-{k} circuit data\", total=len(v)\n",
    "    ):\n",
    "        circuit_data = np.loadtxt(f\"{base_dir}/electronic_circuit/R1/{fpath}\")\n",
    "        pft_prediction = forecast(\n",
    "            pft_model,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            sliding_context=True,\n",
    "        )\n",
    "        chronos_prediction = forecast(\n",
    "            chronos_ft,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            transpose=True,\n",
    "            limit_prediction_length=False,\n",
    "            num_samples=1,\n",
    "        )\n",
    "        for chunk, j in enumerate(\n",
    "            np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "        ):\n",
    "            pft_submetrics = compute_metrics(\n",
    "                pft_prediction[0 : j + step],\n",
    "                circuit_data[context_length : context_length + j + step],\n",
    "                include=metrics,\n",
    "            )\n",
    "            chronos_submetrics = compute_metrics(\n",
    "                chronos_prediction[0 : j + step],\n",
    "                circuit_data[context_length : context_length + j + step],\n",
    "                include=metrics,\n",
    "            )\n",
    "            for metric in metrics:\n",
    "                pft_errors[k][metric][chunk, i] = pft_submetrics[metric]\n",
    "                chronos_errors[k][metric][chunk, i] = chronos_submetrics[metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pft_errors = {\n",
    "    m: np.mean([pft_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}\n",
    "mean_chronos_errors = {\n",
    "    m: np.mean([chronos_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}\n",
    "\n",
    "# std_pft_errors = {\n",
    "#     m: np.std([pft_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "# }\n",
    "# std_chronos_errors = {\n",
    "#     m: np.std([chronos_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "# }\n",
    "ste_pft_errors = {\n",
    "    m: np.std([pft_errors[k][m] for k in ec_fpaths], axis=0) / np.sqrt(len(ec_fpaths))\n",
    "    for m in metrics\n",
    "}\n",
    "ste_chronos_errors = {\n",
    "    m: np.std([chronos_errors[k][m] for k in ec_fpaths], axis=0)\n",
    "    / np.sqrt(len(ec_fpaths))\n",
    "    for m in metrics\n",
    "}\n",
    "\n",
    "# rescale the smape\n",
    "mean_pft_errors[\"smape\"] = mean_pft_errors[\"smape\"] / 2\n",
    "mean_chronos_errors[\"smape\"] = mean_chronos_errors[\"smape\"] / 2\n",
    "ste_pft_errors[\"smape\"] = ste_pft_errors[\"smape\"] / 2\n",
    "ste_chronos_errors[\"smape\"] = ste_chronos_errors[\"smape\"] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(mean_pft_errors[\"smape\"][-1], label=\"Our Model\")\n",
    "plt.plot(mean_chronos_errors[\"smape\"][-1], label=\"Chronos 20M Finetune\")\n",
    "plt.fill_between(\n",
    "    np.arange(len(mean_pft_errors[\"smape\"][-1])),\n",
    "    mean_pft_errors[\"smape\"][-1] - ste_pft_errors[\"smape\"][-1],\n",
    "    mean_pft_errors[\"smape\"][-1] + ste_pft_errors[\"smape\"][-1],\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.fill_between(\n",
    "    np.arange(len(mean_chronos_errors[\"smape\"][-1])),\n",
    "    mean_chronos_errors[\"smape\"][-1] - ste_chronos_errors[\"smape\"][-1],\n",
    "    mean_chronos_errors[\"smape\"][-1] + ste_chronos_errors[\"smape\"][-1],\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.xlabel(\"Coupling Strength\", fontweight=\"bold\")\n",
    "plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"center right\", frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/circuit_coupling_strength_scaling.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.title(r\"% $\\Delta$sMAPE\", fontweight=\"bold\")\n",
    "percentage_error = (\n",
    "    chronos_errors[k][\"smape\"] - pft_errors[k][\"smape\"]\n",
    ") / chronos_errors[k][\"smape\"]\n",
    "plt.imshow(percentage_error, cmap=\"RdBu_r\", label=f\"Type-{k}\", aspect=\"auto\")\n",
    "plt.ylabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.yticks(\n",
    "    np.arange(n_steps),\n",
    "    np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "    + prediction_length // n_steps,\n",
    ")\n",
    "plt.xlabel(\"Coupling Strength\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"figs/circuit_coupling_strength_scaling_percentage_error.pdf\", bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"{base_dir}/electrocardiogram/ecg_train.csv.gz\"\n",
    "ecg_data = np.loadtxt(fpath, delimiter=\",\")\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "start = 0\n",
    "stride = 1\n",
    "\n",
    "subsampled_ecg_data = ecg_data[start::stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times_to_show = np.arange(0, len(subsampled_ecg_data) - 1024, 20000)\n",
    "print(len(start_times_to_show))\n",
    "print(start_times_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times_extra = np.arange(4096, len(subsampled_ecg_data) - 1024, 4096)\n",
    "print(len(start_times_extra))\n",
    "print(start_times_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = np.concatenate([start_times_to_show, start_times_extra])\n",
    "print(len(start_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_times = np.arange(64, prediction_length + 64, 64)\n",
    "print(compute_metrics_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_rollout_metrics = defaultdict(dict)\n",
    "our_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times, desc=f\"Forecasting PFT for {len(start_times)} context windows...\"\n",
    "):\n",
    "    pft_prediction = forecast(\n",
    "        pft_model,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        limit_prediction_length=False,\n",
    "        sliding_context=True,\n",
    "    )\n",
    "    our_predictions[start_time] = pft_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            pft_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in our_rollout_metrics[metric_name]:\n",
    "                our_rollout_metrics[metric_name][t] = []\n",
    "            our_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(our_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_rollout_metrics = defaultdict(dict)\n",
    "chronos_ft_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times,\n",
    "    desc=f\"Forecasting Chronos FT for {len(start_times)} context windows...\",\n",
    "):\n",
    "    chronos_prediction = forecast(\n",
    "        chronos_ft,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    chronos_ft_predictions[start_time] = chronos_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            chronos_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in chronos_ft_rollout_metrics[metric_name]:\n",
    "                chronos_ft_rollout_metrics[metric_name][t] = []\n",
    "            chronos_ft_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(chronos_ft_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_rollout_metrics = defaultdict(dict)\n",
    "chronos_zs_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times,\n",
    "    desc=f\"Forecasting Chronos ZS for {len(start_times)} context windows...\",\n",
    "):\n",
    "    chronos_prediction = forecast(\n",
    "        chronos_zs,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    chronos_zs_predictions[start_time] = chronos_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            chronos_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in chronos_zs_rollout_metrics[metric_name]:\n",
    "                chronos_zs_rollout_metrics[metric_name][t] = []\n",
    "            chronos_zs_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(chronos_zs_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_ecg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean_rollout_metrics = defaultdict(dict)\n",
    "baseline_mean_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times, desc=f\"Forecasting PFT for {len(start_times)} context windows...\"\n",
    "):\n",
    "    baseline_mean_prediction = np.mean(\n",
    "        np.expand_dims(\n",
    "            subsampled_ecg_data[start_time : start_time + context_length], axis=0\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    baseline_mean_predictions[start_time] = baseline_mean_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            baseline_mean_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in baseline_mean_rollout_metrics[metric_name]:\n",
    "                baseline_mean_rollout_metrics[metric_name][t] = []\n",
    "            baseline_mean_rollout_metrics[metric_name][t].append(\n",
    "                submetrics[metric_name]\n",
    "            )\n",
    "print(baseline_mean_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get default colors\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length_to_show = 512\n",
    "\n",
    "# Plot predictions and metrics\n",
    "context_ts = np.arange(context_length + 1)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length_to_show)\n",
    "error_ts = (\n",
    "    np.arange(context_length - step, context_length + prediction_length_to_show, step)\n",
    "    + step\n",
    ")\n",
    "\n",
    "\n",
    "selected_start_times = [4096, 40_000, 60_000]\n",
    "n_examples = len(selected_start_times)\n",
    "\n",
    "fig, axes = plt.subplots(n_examples, 1, figsize=(6, 3), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "linewidth = 1\n",
    "for i, start_time in enumerate(selected_start_times):\n",
    "    print(start_time)\n",
    "    axes[i].plot(\n",
    "        context_ts,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length + 1],\n",
    "        color=\"black\",\n",
    "        alpha=0.8,\n",
    "        linewidth=linewidth,\n",
    "        label=\"context\",\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        subsampled_ecg_data[\n",
    "            start_time + context_length : start_time\n",
    "            + context_length\n",
    "            + prediction_length_to_show\n",
    "        ],\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=linewidth,\n",
    "        label=\"groundtruth\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        our_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[0],\n",
    "        linewidth=linewidth,\n",
    "        zorder=10,\n",
    "        # alpha=0.8,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        chronos_ft_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[1],\n",
    "        linewidth=linewidth,\n",
    "        alpha=0.8,\n",
    "        zorder=2,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        chronos_zs_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[2],\n",
    "        linewidth=linewidth if i < 2 else 3,\n",
    "        alpha=0.8 if i < 2 else 1,\n",
    "        zorder=1 if i < 2 else 8,\n",
    "    )\n",
    "\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/ecg_all_models_forecasts.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array([1, 2, 3])\n",
    "tmp = tmp / 2\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, standard deviation, and standard error for each model\n",
    "def calculate_stats(\n",
    "    data_dict: dict[int, np.ndarray | list[float]], use_rescaled_smape: bool = False\n",
    "):\n",
    "    if use_rescaled_smape:\n",
    "        data_dict = {t: list(np.array(v) / 2) for t, v in data_dict.items()}\n",
    "    mean_vals = {t: np.mean(v) for t, v in data_dict.items()}\n",
    "    median_vals = {t: np.median(v) for t, v in data_dict.items()}\n",
    "    std_vals = {t: np.std(v) for t, v in data_dict.items()}\n",
    "    ste_vals = {t: std_vals[t] / np.sqrt(len(data_dict[t])) for t in data_dict.keys()}\n",
    "    return mean_vals, median_vals, std_vals, ste_vals\n",
    "\n",
    "\n",
    "# Helper function to plot a model's results with error bands\n",
    "def plot_model_results(\n",
    "    mean_dict: dict[int, float],\n",
    "    ste_dict: dict[int, float],\n",
    "    marker: str,\n",
    "    label: str,\n",
    "    color: str | None = None,\n",
    "):\n",
    "    x_values = list(mean_dict.keys())\n",
    "    y_values = list(mean_dict.values())\n",
    "    y_errors = list(ste_dict.values())\n",
    "\n",
    "    plt.plot(x_values, y_values, marker=marker, label=label, color=color)\n",
    "    plt.fill_between(\n",
    "        x_values,\n",
    "        np.array(y_values) - np.array(y_errors),\n",
    "        np.array(y_values) + np.array(y_errors),\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "\n",
    "metric_name = \"smape\"\n",
    "metric_name_title = \"sMAPE\"\n",
    "# Calculate statistics for all models\n",
    "mean_metric_ours, median_metric_ours, _, ste_metric_ours = calculate_stats(\n",
    "    our_rollout_metrics[metric_name], use_rescaled_smape=metric_name == \"smape\"\n",
    ")\n",
    "mean_metric_chronos_ft, median_metric_chronos_ft, _, ste_metric_chronos_ft = (\n",
    "    calculate_stats(\n",
    "        chronos_ft_rollout_metrics[metric_name],\n",
    "        use_rescaled_smape=metric_name == \"smape\",\n",
    "    )\n",
    ")\n",
    "mean_metric_chronos_zs, median_metric_chronos_zs, _, ste_metric_chronos_zs = (\n",
    "    calculate_stats(\n",
    "        chronos_zs_rollout_metrics[metric_name],\n",
    "        use_rescaled_smape=metric_name == \"smape\",\n",
    "    )\n",
    ")\n",
    "mean_metric_baseline_mean, median_metric_baseline_mean, _, ste_metric_baseline_mean = (\n",
    "    calculate_stats(\n",
    "        baseline_mean_rollout_metrics[metric_name],\n",
    "        use_rescaled_smape=metric_name == \"smape\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot each model\n",
    "plot_model_results(mean_metric_ours, ste_metric_ours, \"o\", label=\"Our Model\")\n",
    "plot_model_results(\n",
    "    mean_metric_chronos_ft, ste_metric_chronos_ft, \"s\", label=\"Chronos 20M Finetune\"\n",
    ")\n",
    "plot_model_results(\n",
    "    mean_metric_chronos_zs, ste_metric_chronos_zs, \"v\", label=\"Chronos ZS\"\n",
    ")\n",
    "plot_model_results(\n",
    "    mean_metric_baseline_mean,\n",
    "    ste_metric_baseline_mean,\n",
    "    \"D\",\n",
    "    label=\"Mean Baseline\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.xticks(list(mean_metric_ours.keys()))\n",
    "plt.title(\"ECG\", fontweight=\"bold\")\n",
    "plt.ylabel(metric_name_title, fontweight=\"bold\")\n",
    "# plt.title(metric_name_title, fontweight=\"bold\")\n",
    "# Set y-axis to use scientific notation\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.ylim(13, None)\n",
    "\n",
    "plt.legend(loc=\"lower center\", frameon=True, fontsize=8, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figs/ecg_all_models_{metric_name}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
