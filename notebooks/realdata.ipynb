{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import safe_standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/pft_chattn_emb_w_poly-0/checkpoint-final\",\n",
    "    device_map=\"cuda:1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos = ChronosPipeline.from_pretrained(\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_bolt_mini-12/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = False,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: The model to use for forecasting.\n",
    "        context: The context to forecast (n_timesteps, n_features)\n",
    "        context_length: The length of the context.\n",
    "        prediction_length: The length of the prediction.\n",
    "        transpose: Whether to transpose the data.\n",
    "\n",
    "    Returns:\n",
    "        The forecasted data (prediction_length, n_features)\n",
    "    \"\"\"\n",
    "    preprocessed_context = context.copy().T if transpose else context.copy()\n",
    "    if standardize:\n",
    "        preprocessed_context = safe_standardize(preprocessed_context, axis=0)\n",
    "    context_tensor = torch.from_numpy(preprocessed_context).float()\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    if standardize:\n",
    "        pred = safe_standardize(pred, axis=0, context=context, denormalize=True)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length]\n",
    "    groundtruth = data[context_length : context_length + prediction_length]\n",
    "    prediction = forecast(model, context, prediction_length, transpose, **kwargs)\n",
    "    metrics = compute_metrics(\n",
    "        prediction, groundtruth, include_metrics=[\"mse\", \"mae\", \"smape\"]\n",
    "    )\n",
    "    print(metrics)\n",
    "\n",
    "    total_length = context_length + prediction_length\n",
    "    context_ts = np.arange(context_length + 1) / total_length\n",
    "    pred_ts = np.arange(context_length, total_length) / total_length\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context.T[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth.T[:3], linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*prediction.T[:3], color=\"red\", label=\"Prediction\")\n",
    "    ax_3d.legend(loc=\"upper right\", fontsize=12)\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(context_ts, data[i, : context_length + 1], alpha=0.5, color=\"black\")\n",
    "        ax.plot(pred_ts, groundtruth[:, i], linestyle=\"--\", color=\"black\")\n",
    "        ax.plot(pred_ts, prediction[:, i], color=\"red\")\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)\n",
    "\n",
    "# data is non-stationary, subsample and detrend it\n",
    "subsampled_pendulum_data = pendulum_data[::10, -4:]\n",
    "subsampled_pendulum_diff = np.diff(subsampled_pendulum_data, axis=0)\n",
    "\n",
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_diff[:512],\n",
    "    128,\n",
    "    standardize=True,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "pft_prediction = subsampled_pendulum_data[512] + diff_prediction.cumsum(axis=0)\n",
    "\n",
    "pft_metrics = compute_metrics(\n",
    "    pft_prediction,\n",
    "    subsampled_pendulum_data[512 : 512 + 128],\n",
    "    include=[\"mse\", \"mae\", \"smape\"],\n",
    ")\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    chronos,\n",
    "    subsampled_pendulum_diff[:512],\n",
    "    128,\n",
    "    standardize=False,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    ")\n",
    "chronos_prediction = subsampled_pendulum_data[512] + diff_prediction.cumsum(axis=0)\n",
    "\n",
    "chronos_metrics = compute_metrics(\n",
    "    chronos_prediction,\n",
    "    subsampled_pendulum_data[512 : 512 + 128],\n",
    "    include=[\"mse\", \"mae\", \"smape\"],\n",
    ")\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# The position of the tip of the first pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:512, 1],\n",
    "    -subsampled_pendulum_data[:512, 0],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[512 : 512 + 128, 1],\n",
    "    -subsampled_pendulum_data[512 : 512 + 128, 0],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.plot(pft_prediction[:, 1], -pft_prediction[:, 0], linestyle=\"--\", color=\"blue\")\n",
    "plt.plot(\n",
    "    chronos_prediction[:, 1], -chronos_prediction[:, 0], linestyle=\"--\", color=\"red\"\n",
    ")\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:512, 3],\n",
    "    -subsampled_pendulum_data[:512, 2],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[512 : 512 + 128, 3],\n",
    "    -subsampled_pendulum_data[512 : 512 + 128, 2],\n",
    "    linestyle=\"--\",\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(pft_prediction[:, 3], -pft_prediction[:, 2], color=\"blue\")\n",
    "plt.plot(chronos_prediction[:, 3], -chronos_prediction[:, 2], color=\"red\")\n",
    "\n",
    "axins = inset_axes(plt.gca(), width=\"40%\", height=\"20%\", loc=\"upper right\")\n",
    "width = 0.3\n",
    "# metrics = [\"mse\", \"mae\", \"smape\"]\n",
    "metrics = [\"smape\"]\n",
    "for i, metric in enumerate(metrics):\n",
    "    offset = 0\n",
    "    axins.bar(\n",
    "        np.arange(2) * width + offset,\n",
    "        [pft_metrics[metric], chronos_metrics[metric]],\n",
    "        width,\n",
    "        color=[\"blue\", \"red\"],\n",
    "        label=metric,\n",
    "    )\n",
    "axins.set_xticks([])\n",
    "# axins.legend(loc=\"upper left\", ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
    "\n",
    "context_ts = np.arange(512 + 1) / (512 + 128)\n",
    "pred_ts = np.arange(512, 512 + 128) / (512 + 128)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        context_ts, subsampled_pendulum_data[: 512 + 1, i], color=\"black\", alpha=0.5\n",
    "    )\n",
    "    ax.plot(\n",
    "        pred_ts,\n",
    "        subsampled_pendulum_data[512 : 512 + 128, i],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "    )\n",
    "    ax.plot(pred_ts, prediction[:, i], color=\"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 4\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)\n",
    "\n",
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "print(worm_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(worm_data[:1000, 0], worm_data[:1000, 1], worm_data[:1000, 2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stride = 1\n",
    "subsampled_worm_data = worm_data[start::stride, :]\n",
    "stand_subsampled_worm_data = safe_standardize(subsampled_worm_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_worm_data.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"Eigenworm\",\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "subsampled_worm_data = worm_data[start::stride, :]\n",
    "stand_subsampled_worm_data = safe_standardize(subsampled_worm_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    stand_subsampled_worm_data.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"Eigenworm\",\n",
    "    transpose=False,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbulent Boundary Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbpca_data = np.load(\n",
    "    f\"{base_dir}/turbulence/BLexp_Re980_pca10.pkl\", allow_pickle=True\n",
    ")\n",
    "print(turbpca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(turbpca_data[:, 0], turbpca_data[:, 1], turbpca_data[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stride = 1\n",
    "subsampled_turbpca_data = turbpca_data[start::stride, :]\n",
    "stand_subsampled_turbpca_data = safe_standardize(subsampled_turbpca_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_turbpca_data.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"Turbulent Boundary Layer PCA modes\",\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_turbpca_data = turbpca_data[start::stride, :]\n",
    "stand_subsampled_turbpca_data = safe_standardize(subsampled_turbpca_data, axis=0)\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    stand_subsampled_turbpca_data.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"Turbulent Boundary Layer PCA modes\",\n",
    "    transpose=False,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"{base_dir}/electrocardiogram/ecg_train.csv.gz\"\n",
    "ecg_data = np.loadtxt(fpath, delimiter=\",\")\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot3D(ecg_data[:1000], ecg_data[1:1001], ecg_data[2:1002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "start = 0\n",
    "stride = 1\n",
    "subsampled_ecg_data = ecg_data[start::stride]\n",
    "stand_subsampled_ecg_data = safe_standardize(subsampled_ecg_data, axis=0)\n",
    "standpred = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_subsampled_ecg_data[None, :],\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show=False,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "pred = safe_standardize(\n",
    "    standpred, axis=0, context=subsampled_ecg_data[:context_length], denormalize=True\n",
    ")\n",
    "mse = (\n",
    "    np.linalg.norm(\n",
    "        pred - subsampled_ecg_data[context_length : context_length + prediction_length]\n",
    "    )\n",
    "    / prediction_length\n",
    ")\n",
    "smape_error = (\n",
    "    smape(\n",
    "        pred, subsampled_ecg_data[context_length : context_length + prediction_length]\n",
    "    )\n",
    "    / 2\n",
    ")\n",
    "\n",
    "context_ts = np.arange(context_length + 1) / (context_length + prediction_length)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length) / (\n",
    "    context_length + prediction_length\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title(f\"ECG (MSE: {mse:.4f}, SMAPE: {smape_error:.4f})\")\n",
    "plt.plot(\n",
    "    context_ts,\n",
    "    subsampled_ecg_data[: context_length + 1],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"context\",\n",
    ")\n",
    "plt.plot(\n",
    "    pred_ts,\n",
    "    subsampled_ecg_data[context_length : context_length + prediction_length],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"groundtruth\",\n",
    ")\n",
    "plt.plot(pred_ts, pred, color=\"red\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standpred = plot_model_prediction(\n",
    "    chronos,\n",
    "    stand_subsampled_ecg_data[None, :],\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show=False,\n",
    "    transpose=False,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "pred = safe_standardize(\n",
    "    standpred, axis=0, context=subsampled_ecg_data[:context_length], denormalize=True\n",
    ")\n",
    "mse = (\n",
    "    np.linalg.norm(\n",
    "        pred - subsampled_ecg_data[context_length : context_length + prediction_length]\n",
    "    )\n",
    "    / prediction_length\n",
    ")\n",
    "smape_error = (\n",
    "    smape(\n",
    "        pred, subsampled_ecg_data[context_length : context_length + prediction_length]\n",
    "    )\n",
    "    / 2\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title(f\"ECG (MSE: {mse:.4f}, SMAPE: {smape_error:.4f})\")\n",
    "plt.plot(\n",
    "    context_ts,\n",
    "    subsampled_ecg_data[: context_length + 1],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"context\",\n",
    ")\n",
    "plt.plot(\n",
    "    pred_ts,\n",
    "    subsampled_ecg_data[context_length : context_length + prediction_length],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"groundtruth\",\n",
    ")\n",
    "plt.plot(pred_ts, pred, color=\"red\", label=\"prediction\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timelag_embedding(data, lag, dims):\n",
    "    \"\"\"\n",
    "    Embed a univariate time series into a higher-dimensional space using time-lagged embedding.\n",
    "\n",
    "    Args:\n",
    "        data: Input data array (n_timesteps,)\n",
    "        lag: Time lag for embedding\n",
    "    \"\"\"\n",
    "    n_timesteps = data.shape[0]\n",
    "    embedded_data = np.zeros((n_timesteps - lag * (dims - 1), dims))\n",
    "    for i in range(dims):\n",
    "        embedded_data[:, i] = data[i * lag : i * lag + n_timesteps - lag * (dims - 1)]\n",
    "    return embedded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_lagged = timelag_embedding(ecg_data, 1, 10)\n",
    "stand_ecg_lagged = safe_standardize(ecg_lagged, axis=0)\n",
    "predictions = plot_model_prediction(\n",
    "    pft_model,\n",
    "    stand_ecg_lagged.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"ECG Time-lagged embedding\",\n",
    "    sliding_context=False,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = plot_model_prediction(\n",
    "    chronos,\n",
    "    stand_ecg_lagged.T,\n",
    "    512,\n",
    "    512,\n",
    "    title=\"ECG Time-lagged embedding\",\n",
    "    transpose=False,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_error_scaling(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    ntrials: int,\n",
    "    lags: list[int],\n",
    "    dims: list[int],\n",
    "    **kwargs,\n",
    "):\n",
    "    errors = np.zeros((len(lags), len(dims)))\n",
    "    for i, lag in enumerate(lags):\n",
    "        for j, dim in enumerate(dims):\n",
    "            print(f\"{lag=}, {dim=}\")\n",
    "            embedded_data = timelag_embedding(data, lag, dim)\n",
    "            for start in np.random.randint(\n",
    "                0, len(embedded_data) - context_length - prediction_length, size=ntrials\n",
    "            ):\n",
    "                context = embedded_data[start:]\n",
    "                stand_context = safe_standardize(context, axis=0)\n",
    "                stand_predictions = plot_model_prediction(\n",
    "                    model,\n",
    "                    stand_context.T,\n",
    "                    context_length,\n",
    "                    prediction_length,\n",
    "                    show=False,\n",
    "                    **kwargs,\n",
    "                )\n",
    "                if stand_predictions.ndim == 1:\n",
    "                    stand_predictions = stand_predictions[:, None]\n",
    "                predictions = safe_standardize(\n",
    "                    stand_predictions, axis=0, context=context, denormalize=True\n",
    "                )\n",
    "                errors[i, j] += (\n",
    "                    np.linalg.norm(\n",
    "                        predictions\n",
    "                        - embedded_data[\n",
    "                            start + context_length : start\n",
    "                            + context_length\n",
    "                            + prediction_length\n",
    "                        ]\n",
    "                    )\n",
    "                    / prediction_length\n",
    "                )\n",
    "    errors /= ntrials\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = np.arange(1, 11)\n",
    "dims = np.arange(1, 11)\n",
    "errors = lag_error_scaling(\n",
    "    pft_model,\n",
    "    ecg_data,\n",
    "    512,\n",
    "    512,\n",
    "    ntrials=10,\n",
    "    lags=lags,\n",
    "    dims=dims,\n",
    "    sliding_context=False,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(errors)\n",
    "plt.yticks(range(len(lags)), lags)\n",
    "plt.xticks(range(len(dims)), dims)\n",
    "plt.ylabel(\"Lag\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.title(\"ECG Time-lagged embedding per-dimension error scaling\")\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = lag_error_scaling(\n",
    "    chronos,\n",
    "    ecg_data,\n",
    "    512,\n",
    "    512,\n",
    "    ntrials=10,\n",
    "    lags=lags,\n",
    "    dims=dims,\n",
    "    limit_prediction_length=False,\n",
    "    transpose=False,\n",
    "    num_samples=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(errors)\n",
    "plt.yticks(range(len(lags)), lags)\n",
    "plt.xticks(range(len(dims)), dims)\n",
    "plt.ylabel(\"Lag\")\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.title(\"ECG Time-lagged embedding per-dimension error scaling\")\n",
    "plt.colorbar(shrink=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
