{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Any\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import apply_custom_style, safe_standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply matplotlib style from config\n",
    "apply_custom_style(\"../config/plotting.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "default_markers = \"osvDPX^<>p*hH81\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\"mse\", \"mae\", \"smape\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"  # NOTE: this is still the best\n",
    "# run_name = \"pft_chattn_noembed_pretrained_correct-0\"  # chattn + mlm\n",
    "# run_name = \"pft_linattnpolyemb_from_scratch-0\"\n",
    "\n",
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_finetune_stand_updated-0/checkpoint-final\",\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_mini_ft-0/checkpoint-final\",\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_bolt_mini-12/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=\"cuda:4\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast and Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    differenced: bool = False,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: The model to use for forecasting.\n",
    "        context: The context to forecast (n_timesteps, n_features)\n",
    "        context_length: The length of the context.\n",
    "        prediction_length: The length of the prediction.\n",
    "        transpose: Whether to transpose the data.\n",
    "\n",
    "    Returns:\n",
    "        The forecasted data (prediction_length, n_features)\n",
    "    \"\"\"\n",
    "    preprocessed_context = context.copy()\n",
    "\n",
    "    if differenced:\n",
    "        differenced_context = np.diff(preprocessed_context, axis=0)\n",
    "        preprocessed_context = differenced_context.copy()\n",
    "    if standardize:\n",
    "        preprocessed_context = safe_standardize(preprocessed_context, axis=0)\n",
    "\n",
    "    context_tensor = torch.from_numpy(\n",
    "        preprocessed_context.T if transpose else preprocessed_context\n",
    "    ).float()\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, verbose=False, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    if standardize:\n",
    "        pred = safe_standardize(\n",
    "            pred,\n",
    "            axis=0,\n",
    "            context=differenced_context if differenced else context,\n",
    "            denormalize=True,\n",
    "        )\n",
    "    if differenced:\n",
    "        pred = np.cumsum(pred, axis=0) + context[-1]\n",
    "\n",
    "    # prediction length may be shorter than model output length\n",
    "    return pred[:prediction_length, :] if pred.ndim == 2 else pred[:prediction_length]\n",
    "\n",
    "\n",
    "def compute_rollout_metrics(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    starts: np.ndarray | list[int] | None = None,\n",
    "    num_windows: int | None = None,\n",
    "    step: int = 64,\n",
    "    metrics: list[str] = [\"mse\", \"mae\", \"smape\"],\n",
    "    **kwargs,\n",
    ") -> tuple[\n",
    "    dict[str, np.ndarray],\n",
    "    dict[str, np.ndarray],\n",
    "    np.ndarray | list[int],\n",
    "    list[np.ndarray],\n",
    "]:\n",
    "    if starts is not None:\n",
    "        assert num_windows is None, \"num_windows must be None if starts is provided\"\n",
    "        num_windows = len(starts)\n",
    "    else:\n",
    "        if num_windows is None:\n",
    "            raise ValueError(\"num_windows must be provided if starts is not provided\")\n",
    "        starts = np.random.randint(\n",
    "            0, len(data) - context_length - prediction_length, num_windows\n",
    "        )\n",
    "\n",
    "    assert len(starts) == num_windows, \"starts must be a list of length num_windows\"\n",
    "    assert max(starts) < len(data) - context_length - prediction_length, (\n",
    "        \"starts must be less than the length of the data\"\n",
    "    )\n",
    "\n",
    "    full_metrics = defaultdict(\n",
    "        lambda: np.zeros((num_windows, prediction_length // step))\n",
    "    )\n",
    "\n",
    "    predictions = []\n",
    "    for s in tqdm(range(num_windows), desc=\"Sampling contexts\", total=num_windows):\n",
    "        start = starts[s]\n",
    "        context = data[start : start + context_length]\n",
    "        prediction = forecast(model, context, prediction_length, **kwargs)\n",
    "        for i in range(0, prediction_length, step):\n",
    "            pred = prediction[i : i + step]\n",
    "\n",
    "            gt = data[start + context_length + i : start + context_length + i + step]\n",
    "            submetrics = compute_metrics(pred, gt, include=metrics)\n",
    "            for k, v in submetrics.items():\n",
    "                full_metrics[k][s, i // step] += v\n",
    "        predictions.append(prediction)\n",
    "    mean_metrics = {k: v.mean(axis=0) for k, v in full_metrics.items()}\n",
    "    std_metrics = {\n",
    "        k: v.std(axis=0) / np.sqrt(num_windows) for k, v in full_metrics.items()\n",
    "    }\n",
    "    return mean_metrics, std_metrics, starts, predictions\n",
    "\n",
    "\n",
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    color: str = \"red\",\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length]\n",
    "    groundtruth = data[context_length : context_length + prediction_length]\n",
    "    prediction = forecast(\n",
    "        model, context, prediction_length, transpose, standardize, **kwargs\n",
    "    )\n",
    "\n",
    "    total_length = context_length + prediction_length\n",
    "    context_ts = np.arange(context_length + 1)\n",
    "    pred_ts = np.arange(context_length, total_length)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context.T[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth.T[:3], linestyle=\"-\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*prediction.T[:3], color=color, label=\"Prediction\")\n",
    "    ax_3d.legend(loc=\"upper right\", fontsize=8)\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")\n",
    "\n",
    "    # Make clean projection\n",
    "    ax_3d.grid(False)\n",
    "    ax_3d.set_facecolor(\"white\")\n",
    "    ax_3d.set_xticks([])\n",
    "    ax_3d.set_yticks([])\n",
    "    ax_3d.set_zticks([])\n",
    "    ax_3d.axis(\"off\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(\n",
    "            context_ts,\n",
    "            data[: context_length + 1, i],\n",
    "            alpha=0.5,\n",
    "            color=\"black\",\n",
    "        )\n",
    "        ax.plot(pred_ts, groundtruth[:, i], linestyle=\"-\", color=\"black\")\n",
    "        ax.plot(pred_ts, prediction[:, i], color=color)\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast_3d(\n",
    "    data: np.ndarray,\n",
    "    predictions_dict: dict[str, np.ndarray],\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    figsize: tuple[int, int] = (6, 6),\n",
    "    show_legend: bool = True,\n",
    "    legend_kwargs: dict[str, Any] = {},\n",
    "    save_path: str | None = None,\n",
    "):\n",
    "    context = data[: context_length + 1, :3]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :3]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax._axis3don = False\n",
    "\n",
    "    # Combine all data to find min/max bounds\n",
    "    all_data = [context, groundtruth] + [\n",
    "        pred[:, :3] for pred in predictions_dict.values()\n",
    "    ]\n",
    "    mins = np.array([d.min(axis=0) for d in all_data])\n",
    "    maxs = np.array([d.max(axis=0) for d in all_data])\n",
    "\n",
    "    xmin, ymin, zmin = np.min(mins, axis=0)\n",
    "    xmax, ymax, zmax = np.max(maxs, axis=0)\n",
    "\n",
    "    ax.xaxis.pane.set_visible(False)\n",
    "    ax.yaxis.pane.set_visible(False)\n",
    "    ax.zaxis.pane.set_visible(False)\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.plot3D(*context.T, alpha=0.1, color=\"black\", zorder=1)\n",
    "    ax.plot3D(\n",
    "        *groundtruth.T,\n",
    "        alpha=0.8,\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        zorder=2,\n",
    "        label=\"Ground Truth\",\n",
    "    )\n",
    "    for model_name, prediction in predictions_dict.items():\n",
    "        ax.plot3D(\n",
    "            *prediction[:, :3].T,\n",
    "            label=model_name,\n",
    "            zorder=10 if model_name == \"Our Model\" else 1,\n",
    "        )\n",
    "    if show_legend:\n",
    "        ax.legend(**legend_kwargs)\n",
    "\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        xmax - xmin,\n",
    "        0,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        -ymax + ymin,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        0,\n",
    "        zmax - zmin,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_comparison(\n",
    "    model_metrics: dict[str, tuple[dict[str, np.ndarray], dict[str, np.ndarray]]],\n",
    "    prediction_length: int,\n",
    "    compute_metrics_time_interval: int,\n",
    "    metric_name: str = \"smape\",\n",
    "    colors: list[str] = default_colors,\n",
    "    markers: str = default_markers,\n",
    "    title: str | None = None,\n",
    "    figsize: tuple[float, float] = (4, 3),\n",
    "    show_legend: bool = True,\n",
    "    legend_kwargs: dict[str, Any] = {},\n",
    "    ylim: tuple[float | None, float | None] | None = None,\n",
    "    save_path: str | None = None,\n",
    "    metric_name_mapping: dict[str, str] = {\"smape\": \"sMAPE\"},\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot comparison between different models on a given metric.\n",
    "\n",
    "    Args:\n",
    "        model_metrics: Dictionary with model names as keys and tuples of (mean_metrics, std_metrics) as values\n",
    "        metric_name: Name of the metric to plot\n",
    "        prediction_length: Length of prediction\n",
    "        compute_metrics_time_interval: Time interval for computing metrics\n",
    "        save_path: Path to save the figure\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    ts = np.arange(\n",
    "        compute_metrics_time_interval,\n",
    "        prediction_length + compute_metrics_time_interval,\n",
    "        compute_metrics_time_interval,\n",
    "    )\n",
    "\n",
    "    for i, (model_name, (mean_metrics, std_metrics)) in enumerate(\n",
    "        model_metrics.items()\n",
    "    ):\n",
    "        plt.plot(\n",
    "            ts,\n",
    "            mean_metrics[metric_name],\n",
    "            color=colors[i],\n",
    "            marker=markers[i],\n",
    "            label=model_name,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            ts,\n",
    "            mean_metrics[metric_name] - std_metrics[metric_name],\n",
    "            mean_metrics[metric_name] + std_metrics[metric_name],\n",
    "            alpha=0.1,\n",
    "            color=colors[i],\n",
    "        )\n",
    "\n",
    "    metric_name_title = metric_name.upper()\n",
    "    if metric_name in metric_name_mapping:\n",
    "        metric_name_title = metric_name_mapping[metric_name]\n",
    "\n",
    "    plt.ylabel(metric_name_title, fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "    if show_legend:\n",
    "        plt.legend(loc=\"lower right\", frameon=True, **legend_kwargs)\n",
    "    plt.xticks(ts)\n",
    "    plt.tight_layout()\n",
    "    if title is not None:\n",
    "        plt.title(title, fontweight=\"bold\")\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    if save_path is not None:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)\n",
    "\n",
    "# data is non-stationary, subsample and detrend it\n",
    "subsampled_pendulum_data = pendulum_data[::10, -4:]\n",
    "print(subsampled_pendulum_data.shape)\n",
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "compute_metrics_time_interval = 16\n",
    "\n",
    "differenced = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "start_time = 0\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[start_time : start_time + context_length, 3],\n",
    "    -subsampled_pendulum_data[start_time : start_time + context_length, 2],\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[\n",
    "        start_time + context_length : start_time + context_length + prediction_length,\n",
    "        3,\n",
    "    ],\n",
    "    -subsampled_pendulum_data[\n",
    "        start_time + context_length : start_time + context_length + prediction_length,\n",
    "        2,\n",
    "    ],\n",
    "    alpha=0.8,\n",
    "    color=\"black\",\n",
    "    linestyle=\"-\",\n",
    ")\n",
    "# get rid of the ticks\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.plot(pft_prediction[:, 3], -pft_prediction[:, 2])\n",
    "# plt.plot(chronos_ft_prediction[:, 3], -chronos_ft_prediction[:, 2])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/double_pendulum_forecasts.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rseed = 123\n",
    "num_windows_pendulum = 20\n",
    "rng = np.random.default_rng(rseed)\n",
    "pendulum_start_times = rng.choice(\n",
    "    len(subsampled_pendulum_data) - context_length - prediction_length,\n",
    "    size=num_windows_pendulum,\n",
    "    replace=False,\n",
    ")\n",
    "print(pendulum_start_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, _, pft_predictions = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data,\n",
    "    context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    starts=pendulum_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_mean_metrics, chronos_ft_std_metrics, _, chronos_ft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_ft,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length=prediction_length,\n",
    "        starts=pendulum_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_mean_metrics, chronos_zs_std_metrics, _, chronos_zs_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_zs,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length=prediction_length,\n",
    "        starts=pendulum_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "total_ts = np.arange(len(subsampled_pendulum_data))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        total_ts,\n",
    "        subsampled_pendulum_data[:, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    for j, start_time in enumerate(pendulum_start_times):\n",
    "        pft_pred_ts = np.arange(\n",
    "            start_time + context_length, start_time + context_length + prediction_length\n",
    "        )\n",
    "        chronos_ft_context_ts = np.arange(start_time, start_time + context_length)\n",
    "        chronos_ft_pred_ts = np.arange(\n",
    "            start_time + context_length,\n",
    "            start_time + context_length + prediction_length,\n",
    "        )\n",
    "        chronos_zs_context_ts = np.arange(start_time, start_time + context_length)\n",
    "        chronos_zs_pred_ts = np.arange(\n",
    "            start_time + context_length,\n",
    "            start_time + context_length + prediction_length,\n",
    "        )\n",
    "        ax.plot(\n",
    "            pft_pred_ts, pft_predictions[j][:, i], color=default_colors[0], alpha=0.1\n",
    "        )\n",
    "        ax.plot(\n",
    "            chronos_ft_pred_ts,\n",
    "            chronos_ft_predictions[j][:, i],\n",
    "            color=default_colors[1],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        ax.plot(\n",
    "            chronos_zs_pred_ts,\n",
    "            chronos_zs_predictions[j][:, i],\n",
    "            color=default_colors[2],\n",
    "            alpha=0.1,\n",
    "        )\n",
    "        # get rid of the ticks\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"Our Model\": (pft_mean_metrics, pft_std_metrics),\n",
    "    \"Chronos 20M SFT\": (chronos_ft_mean_metrics, chronos_ft_std_metrics),\n",
    "    \"Chronos 20M\": (chronos_zs_mean_metrics, chronos_zs_std_metrics),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    compute_metrics_time_interval,\n",
    "    metric_name=\"smape\",\n",
    "    save_path=\"../figures/double_pendulum_comparison_smape.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)\n",
    "eigenworms = loadmat(f\"{base_dir}/worm_behavior/data/EigenWorms.mat\")[\"EigenWorms\"]\n",
    "\n",
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "worm_data_subsampled = worm_data[2048::1]\n",
    "print(worm_data_subsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def reconstruct_worm(coeffs, eigenworms, segment_length=1.0):\n",
    "    \"\"\"\n",
    "    Reconstruct a worm from its coefficients and the eigenworms.\n",
    "\n",
    "    Args:\n",
    "        coeffs: The coefficients of the worm (n_timesteps, n_eigenworms)\n",
    "        eigenworms: The eigenworms (n_features, n_eigenworms)\n",
    "        segment_length: The length of each segment of the worm.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed worm.\n",
    "    \"\"\"\n",
    "    T, nworms = coeffs.shape\n",
    "    n_segments = eigenworms.shape[0]\n",
    "    basis = eigenworms[:, :nworms]\n",
    "    theta = coeffs @ basis.T\n",
    "\n",
    "    x = np.zeros((T, n_segments + 1))\n",
    "    y = np.zeros((T, n_segments + 1))\n",
    "    x[:, 1:] = segment_length * np.cos(theta)\n",
    "    y[:, 1:] = segment_length * np.sin(theta)\n",
    "\n",
    "    return x.cumsum(axis=1), y.cumsum(axis=1)\n",
    "\n",
    "\n",
    "def animate_worm(x, y, num_frames=200, interval=50, save_path=None):\n",
    "    \"\"\"\n",
    "    Create an animation of the worm's movement over time.\n",
    "\n",
    "    Args:\n",
    "        x: Array of x coordinates with shape (T, n_segments+1)\n",
    "        y: Array of y coordinates with shape (T, n_segments+1)\n",
    "        num_frames: Number of frames to include in the animation\n",
    "        interval: Time between frames in milliseconds\n",
    "\n",
    "    Returns:\n",
    "        HTML animation that can be displayed in the notebook\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Set consistent axis limits for the animation\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "\n",
    "    # Add some padding to the limits\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(\"Worm Movement\")\n",
    "\n",
    "    # Create line and fill objects\n",
    "    line = ax.plot([], [], \"b-\", lw=2)[0]\n",
    "    fill = ax.fill([], [], color=\"blue\")\n",
    "    time_text = ax.text(0.02, 0.95, \"\", transform=ax.transAxes)\n",
    "\n",
    "    # Calculate width profile - increases toward middle, decreases toward ends\n",
    "    n_points = x.shape[1]\n",
    "    width_profile = np.zeros(n_points)\n",
    "    max_width = 3  # Maximum width of the worm body\n",
    "    for i in range(n_points):\n",
    "        arg = 2 * i / (n_points - 1) - 1  # normalize to [-1, 1]\n",
    "        width_profile[i] = max_width * (\n",
    "            1\n",
    "            / (1 + np.exp(-8 * (arg + 0.7)))\n",
    "            * (1 - 1 / (1 + np.exp(-8 * (arg - 0.7))))\n",
    "        )\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        fill[0].set_xy(np.zeros((0, 2)))\n",
    "        time_text.set_text(\"\")\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    def update(frame):\n",
    "        # Update the centerline\n",
    "        line.set_data(x[frame], y[frame])\n",
    "\n",
    "        # Calculate perpendicular vectors for width\n",
    "        dx = np.diff(x[frame])\n",
    "        dy = np.diff(y[frame])\n",
    "        # Normalize and rotate 90 degrees to get perpendicular direction\n",
    "        lengths = np.sqrt(dx**2 + dy**2)\n",
    "        nx = -dy / lengths\n",
    "        ny = dx / lengths\n",
    "\n",
    "        # Create polygon vertices for the worm body\n",
    "        vertices = []\n",
    "\n",
    "        # Top edge (add points from head to tail)\n",
    "        for i in range(n_points - 1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] + width_profile[i] * nx[i],\n",
    "                    y[frame][i] + width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Bottom edge (add points from tail to head)\n",
    "        for i in range(n_points - 2, -1, -1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] - width_profile[i] * nx[i],\n",
    "                    y[frame][i] - width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Update the fill\n",
    "        fill[0].set_xy(vertices)\n",
    "        time_text.set_text(f\"Frame: {frame}\")\n",
    "\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    # Use a subset of frames if there are too many\n",
    "    total_frames = min(num_frames, len(x))\n",
    "    frame_indices = np.linspace(0, len(x) - 1, total_frames, dtype=int)\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig, update, frames=frame_indices, init_func=init, blit=True, interval=interval\n",
    "    )\n",
    "    if save_path is not None:\n",
    "        anim.save(save_path, writer=\"ffmpeg\")\n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and display the animation\n",
    "# x, y = reconstruct_worm(worm_data_subsampled, eigenworms)\n",
    "# worm_animation = animate_worm(x[:1000], y[:1000], save_path=\"../figures/wormanim.mp4\")\n",
    "\n",
    "# worm_animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast Worms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "differenced = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    worm_data_subsampled[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    worm_data_subsampled[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_3d(\n",
    "    worm_data_subsampled,\n",
    "    {\n",
    "        \"Our Model\": pft_prediction,\n",
    "        # \"Chronos 20M SFT\": chronos_ft_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show_legend=False,\n",
    "    save_path=\"../figures/worm_comparison.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    worm_data_subsampled,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    "    color=default_colors[0],\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    worm_data_subsampled,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    "    color=default_colors[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_time_interval = 64\n",
    "prediction_length = 512\n",
    "\n",
    "worms_start_times = np.arange(\n",
    "    0, len(worm_data_subsampled) - context_length - prediction_length, 1280\n",
    ")\n",
    "num_windows_worms = len(worms_start_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, _, pft_predictions = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    worm_data_subsampled,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    starts=worms_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_mean_metrics, chronos_ft_std_metrics, _, chronos_ft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_ft,\n",
    "        worm_data_subsampled,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        starts=worms_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        differenced=differenced,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_mean_metrics, chronos_zs_std_metrics, _, chronos_zs_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_zs,\n",
    "        worm_data_subsampled,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        starts=worms_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        differenced=differenced,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"Our Model\": (pft_mean_metrics, pft_std_metrics),\n",
    "    \"Chronos 20M SFT\": (chronos_ft_mean_metrics, chronos_ft_std_metrics),\n",
    "    \"Chronos 20M\": (chronos_zs_mean_metrics, chronos_zs_std_metrics),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    compute_metrics_time_interval,\n",
    "    metric_name=\"smape\",\n",
    "    save_path=\"../figures/worms_comparison_smape.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbulent Boundary Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbpca_data = np.load(\n",
    "    f\"{base_dir}/turbulence/BLexp_Re980_pca10.pkl\", allow_pickle=True\n",
    ")\n",
    "transient = 1024\n",
    "subsampled_turbpca_data = turbpca_data[transient::1]\n",
    "print(subsampled_turbpca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "\n",
    "differenced = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=False,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    subsampled_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_prediction = forecast(\n",
    "    chronos_zs,\n",
    "    subsampled_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_3d(\n",
    "    turbpca_data,\n",
    "    {\n",
    "        \"Our Model\": pft_prediction,\n",
    "        \"Chronos 20M SFT\": chronos_ft_prediction,\n",
    "        \"Chronos 20M\": chronos_zs_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show_legend=False,\n",
    "    legend_kwargs={\"loc\": \"center right\", \"frameon\": True},\n",
    "    save_path=\"../figures/turbpca_comparison.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    "    color=default_colors[0],\n",
    "    # save_path=\"../figures/turbpca_comparison_ourmodel.pdf\",\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    "    color=default_colors[1],\n",
    "    # save_path=\"../figures/turbpca_comparison_chronosft.pdf\",\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_zs,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    differenced=differenced,\n",
    "    color=default_colors[2],\n",
    "    # save_path=\"../figures/turbpca_comparison_chronoszs.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics_time_interval = 64\n",
    "turbpca_start_times = np.arange(\n",
    "    0, len(subsampled_turbpca_data) - context_length - prediction_length, 256\n",
    ")\n",
    "print(f\"Number of windows: {len(turbpca_start_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, _, pft_predictions = compute_rollout_metrics(\n",
    "    pft_model,\n",
    "    subsampled_turbpca_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    starts=turbpca_start_times,\n",
    "    step=compute_metrics_time_interval,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    "    differenced=differenced,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_mean_metrics, chronos_ft_std_metrics, _, chronos_ft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_ft,\n",
    "        subsampled_turbpca_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        starts=turbpca_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        differenced=differenced,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_mean_metrics, chronos_zs_std_metrics, _, chronos_zs_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos_zs,\n",
    "        subsampled_turbpca_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        starts=turbpca_start_times,\n",
    "        step=compute_metrics_time_interval,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        differenced=differenced,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    \"Our Model\": (pft_mean_metrics, pft_std_metrics),\n",
    "    \"Chronos 20M SFT\": (chronos_ft_mean_metrics, chronos_ft_std_metrics),\n",
    "    \"Chronos 20M\": (chronos_zs_mean_metrics, chronos_zs_std_metrics),\n",
    "}\n",
    "\n",
    "plot_metric_comparison(\n",
    "    model_metrics,\n",
    "    prediction_length,\n",
    "    compute_metrics_time_interval,\n",
    "    metric_name=\"smape\",\n",
    "    save_path=\"../figures/turbpca_comparison_smape.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronic Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netfpath = f\"{base_dir}/electronic_circuit/Structure/Net_1.dat\"\n",
    "subdir = \"R1\"\n",
    "fname = \"ST_100_3\"\n",
    "fpath = f\"{base_dir}/electronic_circuit/{subdir}/{fname}.dat\"\n",
    "net = np.loadtxt(netfpath)\n",
    "circuit_data = np.loadtxt(fpath)\n",
    "print(net.shape, circuit_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_prediction = forecast(\n",
    "    chronos_ft,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_prediction = forecast(\n",
    "    chronos_zs,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast_3d(\n",
    "    circuit_data,\n",
    "    {\n",
    "        \"Our Model\": pft_prediction,\n",
    "        \"Chronos 20M SFT\": chronos_ft_prediction,\n",
    "        \"Chronos 20M\": chronos_zs_prediction,\n",
    "    },\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    show_legend=False,\n",
    "    legend_kwargs={\"loc\": \"center right\", \"frameon\": True},\n",
    "    # save_path=f\"../figures/circuit_comparison_{subdir}_{fname}.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_ft,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    color=default_colors[1],\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos_zs,\n",
    "    circuit_data,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    deterministic=True,\n",
    "    color=default_colors[2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupling Strength Scaling Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify data by type {1, 2, 3} and sort by coupling strength\n",
    "fpaths = os.listdir(f\"{base_dir}/electronic_circuit/R1\")\n",
    "ec_fpaths = defaultdict(list)\n",
    "for fpath in fpaths:\n",
    "    ec_fpaths[int(fpath.split(\"_\")[2][0])].append(fpath)\n",
    "for k, v in ec_fpaths.items():\n",
    "    ec_fpaths[k] = sorted(v, key=lambda x: int(x.split(\"_\")[1]))\n",
    "\n",
    "# subset the data by coupling strength\n",
    "coupling_strength_interval = 25\n",
    "# ec_fpaths = {k: v[::coupling_strength_interval] for k, v in ec_fpaths.items()}\n",
    "for k, v in ec_fpaths.items():\n",
    "    ec_fpaths[k] = [\n",
    "        fpath\n",
    "        for fpath in v\n",
    "        if int(fpath.split(\"_\")[1]) % coupling_strength_interval == 0\n",
    "    ]\n",
    "\n",
    "print(ec_fpaths)\n",
    "\n",
    "coupling_strengths_lst = [\n",
    "    int(fpath.split(\"_\")[1]) for fpath in ec_fpaths[1]\n",
    "]  # Assume same coupling strength for ec splits\n",
    "print(coupling_strengths_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "step = prediction_length // n_steps\n",
    "\n",
    "metrics_by_model = {\n",
    "    \"Our Model\": {\n",
    "        k: {m: np.zeros((n_steps, len(v))) for m in metrics}\n",
    "        for k, v in ec_fpaths.items()\n",
    "    },\n",
    "    \"Chronos 20M SFT\": {\n",
    "        k: {m: np.zeros((n_steps, len(v))) for m in metrics}\n",
    "        for k, v in ec_fpaths.items()\n",
    "    },\n",
    "    \"Chronos 20M\": {\n",
    "        k: {m: np.zeros((n_steps, len(v))) for m in metrics}\n",
    "        for k, v in ec_fpaths.items()\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "for k, v in tqdm(\n",
    "    ec_fpaths.items(), desc=\"Processing type-k circuit data\", total=len(ec_fpaths)\n",
    "):\n",
    "    for i, fpath in tqdm(\n",
    "        enumerate(v), desc=f\"Processing type-{k} circuit data\", total=len(v)\n",
    "    ):\n",
    "        print(f\"{base_dir}/electronic_circuit/R1/{fpath}\")\n",
    "        circuit_data = np.loadtxt(f\"{base_dir}/electronic_circuit/R1/{fpath}\")\n",
    "        pft_prediction = forecast(\n",
    "            pft_model,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            sliding_context=True,\n",
    "        )\n",
    "        chronos_ft_prediction = forecast(\n",
    "            chronos_ft,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            transpose=True,\n",
    "            limit_prediction_length=False,\n",
    "            num_samples=1,\n",
    "            deterministic=True,\n",
    "        )\n",
    "        chronos_zs_prediction = forecast(\n",
    "            chronos_zs,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            transpose=True,\n",
    "            limit_prediction_length=False,\n",
    "            num_samples=1,\n",
    "            deterministic=True,\n",
    "        )\n",
    "\n",
    "        for chunk, j in enumerate(\n",
    "            np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "        ):\n",
    "            target = circuit_data[context_length : context_length + j + step]\n",
    "\n",
    "            # # Compute metrics for all models at once\n",
    "            curr_preds_by_model = {\n",
    "                \"Our Model\": pft_prediction[0 : j + step],\n",
    "                \"Chronos 20M SFT\": chronos_ft_prediction[0 : j + step],\n",
    "                \"Chronos 20M\": chronos_zs_prediction[0 : j + step],\n",
    "            }\n",
    "            # Compute metrics and store results\n",
    "            for model_name, pred in curr_preds_by_model.items():\n",
    "                model_metrics = compute_metrics(pred, target, include=metrics)\n",
    "                for metric in metrics:\n",
    "                    metrics_by_model[model_name][k][metric][chunk, i] = model_metrics[\n",
    "                        metric\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# saved_metrics_path_dict = {\n",
    "#     \"Our Model\": \"electronic_circuit_pft_errors.pkl\",\n",
    "#     \"Chronos 20M SFT\": \"electronic_circuit_chronos_ft_errors.pkl\",\n",
    "#     \"Chronos 20M\": \"electronic_circuit_chronos_zs_errors.pkl\",\n",
    "# }\n",
    "\n",
    "# metrics_by_model = {}\n",
    "# for model_name, path in saved_metrics_path_dict.items():\n",
    "#     metrics_by_model[model_name] = pickle.load(open(path, \"rb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics = {}\n",
    "std_metrics = {}\n",
    "\n",
    "for model_name, model_metrics in metrics_by_model.items():\n",
    "    mean_metrics[model_name] = {\n",
    "        m: np.mean([model_metrics[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "    }\n",
    "    std_metrics[model_name] = {\n",
    "        m: np.std([model_metrics[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "    }\n",
    "\n",
    "# Unpack for backward compatibility\n",
    "mean_pft_metrics = mean_metrics[\"Our Model\"]\n",
    "mean_chronos_ft_metrics = mean_metrics[\"Chronos 20M SFT\"]\n",
    "mean_chronos_zs_metrics = mean_metrics[\"Chronos 20M\"]\n",
    "std_pft_metrics = std_metrics[\"Our Model\"]\n",
    "std_chronos_ft_metrics = std_metrics[\"Chronos 20M SFT\"]\n",
    "std_chronos_zs_metrics = std_metrics[\"Chronos 20M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_strengths_lst = np.arange(metrics_by_model[\"Our Model\"][1][\"smape\"].shape[1])\n",
    "print(coupling_strengths_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "metric_rollout_length_idx = -1\n",
    "\n",
    "for model_name in metrics_by_model.keys():\n",
    "    data = mean_metrics[model_name][\"smape\"][metric_rollout_length_idx]  # / 2\n",
    "    std = std_metrics[model_name][\"smape\"][metric_rollout_length_idx]  # / 2\n",
    "\n",
    "    assert len(data) == len(coupling_strengths_lst)\n",
    "\n",
    "    plt.plot(coupling_strengths_lst, data, label=model_name)\n",
    "    plt.fill_between(coupling_strengths_lst, data - std, data + std, alpha=0.2)\n",
    "\n",
    "plt.xlabel(\"Coupling Strength\", fontweight=\"bold\")\n",
    "plt.ylabel(\"sMAPE\", fontweight=\"bold\")\n",
    "plt.legend(loc=\"upper right\", frameon=True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/circuit_coupling_strength_scaling.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "# plt.title(r\"% $\\Delta$sMAPE\", fontweight=\"bold\")\n",
    "plt.title(r\"Log sMAPE Ratio\", fontweight=\"bold\")\n",
    "\n",
    "# Define the starting coupling strength and range\n",
    "start_coupling = 0\n",
    "coupling_range = coupling_strengths_lst[coupling_strengths_lst >= start_coupling]\n",
    "\n",
    "pred_length_start_idx = 0\n",
    "# Extract the data for the specified coupling range\n",
    "chronos_data = metrics_by_model[\"Chronos 20M SFT\"][k][\"smape\"][\n",
    "    :, coupling_strengths_lst >= start_coupling\n",
    "]\n",
    "our_model_data = metrics_by_model[\"Our Model\"][k][\"smape\"][\n",
    "    :, coupling_strengths_lst >= start_coupling\n",
    "]\n",
    "\n",
    "# Calculate percentage error over the specified range\n",
    "# percentage_error = (our_model_data[pred_length_start_idx:, :] - chronos_data[pred_length_start_idx:, :]) / chronos_data[pred_length_start_idx:, :]\n",
    "percentage_error = np.log(\n",
    "    our_model_data[pred_length_start_idx:, :] / chronos_data[pred_length_start_idx:, :]\n",
    ")\n",
    "# percentage_error = (our_model_data[pred_length_start_idx:, :] - chronos_data[pred_length_start_idx:, :]) / ((chronos_data[pred_length_start_idx:, :] + our_model_data[pred_length_start_idx:, :]) / 2)\n",
    "print(percentage_error.shape)\n",
    "# Find the maximum absolute value to center the colormap at zero\n",
    "vmax = np.abs(percentage_error).max()\n",
    "\n",
    "# Flip the y-axis by using origin='upper' and adjusting the extent\n",
    "plt.imshow(\n",
    "    percentage_error,\n",
    "    cmap=\"RdBu\",\n",
    "    label=f\"Type-{k}\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=-vmax,\n",
    "    vmax=vmax,\n",
    "    extent=[coupling_range[0], coupling_range[-1], percentage_error.shape[0], 0],\n",
    "    origin=\"upper\",\n",
    ")\n",
    "plt.colorbar(format=\"%.1f\")\n",
    "plt.ylabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.yticks(\n",
    "    np.arange(n_steps - pred_length_start_idx),\n",
    "    [\n",
    "        str(i)\n",
    "        for i in np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "        + prediction_length // n_steps\n",
    "    ][pred_length_start_idx:],\n",
    ")\n",
    "plt.xlabel(\"Coupling Strength\", fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../figures/circuit_coupling_scaling_heatmap.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"{base_dir}/electrocardiogram/ecg_train.csv.gz\"\n",
    "ecg_data = np.loadtxt(fpath, delimiter=\",\")\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "start = 0\n",
    "stride = 1\n",
    "\n",
    "subsampled_ecg_data = ecg_data[start::stride]\n",
    "\n",
    "start_times_to_show = np.arange(0, len(subsampled_ecg_data) - 1024, 20000)\n",
    "start_times_extra = np.arange(4096, len(subsampled_ecg_data) - 1024, 4096)\n",
    "start_times = np.concatenate([start_times_to_show, start_times_extra])\n",
    "compute_metrics_times = np.arange(64, prediction_length + 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_rollout_metrics = defaultdict(dict)\n",
    "our_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times, desc=f\"Forecasting PFT for {len(start_times)} context windows...\"\n",
    "):\n",
    "    pft_prediction = forecast(\n",
    "        pft_model,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        limit_prediction_length=False,\n",
    "        sliding_context=True,\n",
    "    )\n",
    "    print(pft_prediction.shape)\n",
    "    our_predictions[start_time] = pft_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            pft_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in our_rollout_metrics[metric_name]:\n",
    "                our_rollout_metrics[metric_name][t] = []\n",
    "            our_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(our_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_rollout_metrics = defaultdict(dict)\n",
    "chronos_ft_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times,\n",
    "    desc=f\"Forecasting Chronos FT for {len(start_times)} context windows...\",\n",
    "):\n",
    "    chronos_prediction = forecast(\n",
    "        chronos_ft,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    chronos_ft_predictions[start_time] = chronos_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            chronos_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in chronos_ft_rollout_metrics[metric_name]:\n",
    "                chronos_ft_rollout_metrics[metric_name][t] = []\n",
    "            chronos_ft_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(chronos_ft_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_rollout_metrics = defaultdict(dict)\n",
    "chronos_zs_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times,\n",
    "    desc=f\"Forecasting Chronos ZS for {len(start_times)} context windows...\",\n",
    "):\n",
    "    chronos_prediction = forecast(\n",
    "        chronos_zs,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length],\n",
    "        prediction_length,\n",
    "        transpose=True,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "    )\n",
    "    chronos_zs_predictions[start_time] = chronos_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            chronos_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in chronos_zs_rollout_metrics[metric_name]:\n",
    "                chronos_zs_rollout_metrics[metric_name][t] = []\n",
    "            chronos_zs_rollout_metrics[metric_name][t].append(submetrics[metric_name])\n",
    "print(chronos_zs_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean_rollout_metrics = defaultdict(dict)\n",
    "baseline_mean_predictions = defaultdict()\n",
    "\n",
    "for start_time in tqdm(\n",
    "    start_times, desc=f\"Forecasting PFT for {len(start_times)} context windows...\"\n",
    "):\n",
    "    baseline_mean_prediction = np.mean(\n",
    "        np.expand_dims(\n",
    "            subsampled_ecg_data[start_time : start_time + context_length], axis=0\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    baseline_mean_predictions[start_time] = baseline_mean_prediction\n",
    "    for t in compute_metrics_times:\n",
    "        submetrics = compute_metrics(\n",
    "            baseline_mean_prediction[0:t],\n",
    "            subsampled_ecg_data[context_length : context_length + t],\n",
    "            include=metrics,\n",
    "        )\n",
    "        for metric_name in metrics:\n",
    "            if t not in baseline_mean_rollout_metrics[metric_name]:\n",
    "                baseline_mean_rollout_metrics[metric_name][t] = []\n",
    "            baseline_mean_rollout_metrics[metric_name][t].append(\n",
    "                submetrics[metric_name]\n",
    "            )\n",
    "print(baseline_mean_rollout_metrics[\"smape\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length_to_show = 512\n",
    "\n",
    "# Plot predictions and metrics\n",
    "context_ts = np.arange(context_length + 1)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length_to_show)\n",
    "error_ts = (\n",
    "    np.arange(context_length - step, context_length + prediction_length_to_show, step)\n",
    "    + step\n",
    ")\n",
    "\n",
    "selected_start_times = [4096, 40_000, 60_000]\n",
    "n_examples = len(selected_start_times)\n",
    "\n",
    "fig, axes = plt.subplots(n_examples, 1, figsize=(4, 3), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "linewidth = 1\n",
    "for i, start_time in enumerate(selected_start_times):\n",
    "    print(start_time)\n",
    "    axes[i].plot(\n",
    "        context_ts,\n",
    "        subsampled_ecg_data[start_time : start_time + context_length + 1],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "        linewidth=linewidth,\n",
    "        label=\"context\",\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        subsampled_ecg_data[\n",
    "            start_time + context_length : start_time\n",
    "            + context_length\n",
    "            + prediction_length_to_show\n",
    "        ],\n",
    "        color=\"black\",\n",
    "        linestyle=\"-\",\n",
    "        linewidth=linewidth,\n",
    "        label=\"groundtruth\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        our_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[0],\n",
    "        linewidth=linewidth,\n",
    "        zorder=10,\n",
    "        # alpha=0.8,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        chronos_ft_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[1],\n",
    "        linewidth=linewidth,\n",
    "        alpha=0.8,\n",
    "        zorder=2,\n",
    "    )\n",
    "    axes[i].plot(\n",
    "        pred_ts,\n",
    "        chronos_zs_predictions[start_time][:prediction_length_to_show],\n",
    "        # color=colors[2],\n",
    "        linewidth=linewidth if i < 2 else 2,\n",
    "        alpha=0.8 if i < 2 else 1,\n",
    "        zorder=1 if i < 2 else 8,\n",
    "    )\n",
    "\n",
    "    axes[i].set_xticks([])\n",
    "    axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/ecg_all_models_forecasts.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(data_dict: dict[int, np.ndarray | list[float]]):\n",
    "    \"\"\"\n",
    "    Calculate mean, standard deviation, and standard error for each model\n",
    "    \"\"\"\n",
    "    mean_vals = {t: np.mean(v) for t, v in data_dict.items()}\n",
    "    median_vals = {t: np.median(v) for t, v in data_dict.items()}\n",
    "    std_vals = {t: np.std(v) for t, v in data_dict.items()}\n",
    "    ste_vals = {t: std_vals[t] / np.sqrt(len(data_dict[t])) for t in data_dict.keys()}\n",
    "    return mean_vals, median_vals, std_vals, ste_vals\n",
    "\n",
    "\n",
    "def plot_model_results(\n",
    "    mean_dict: dict[int, float],\n",
    "    ste_dict: dict[int, float],\n",
    "    marker: str,\n",
    "    label: str,\n",
    "    color: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Helper function to plot a model's results with error bands\n",
    "    \"\"\"\n",
    "    x_values = list(mean_dict.keys())\n",
    "    y_values = list(mean_dict.values())\n",
    "    y_errors = list(ste_dict.values())\n",
    "\n",
    "    plt.plot(x_values, y_values, marker=marker, label=label, color=color)\n",
    "    plt.fill_between(\n",
    "        x_values,\n",
    "        np.array(y_values) - np.array(y_errors),\n",
    "        np.array(y_values) + np.array(y_errors),\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "\n",
    "metric_name = \"smape\"\n",
    "metric_name_title = \"sMAPE\"\n",
    "# Calculate statistics for all models\n",
    "mean_metric_ours, median_metric_ours, _, ste_metric_ours = calculate_stats(\n",
    "    our_rollout_metrics[metric_name]\n",
    ")\n",
    "mean_metric_chronos_ft, median_metric_chronos_ft, _, ste_metric_chronos_ft = (\n",
    "    calculate_stats(chronos_ft_rollout_metrics[metric_name])\n",
    ")\n",
    "mean_metric_chronos_zs, median_metric_chronos_zs, _, ste_metric_chronos_zs = (\n",
    "    calculate_stats(chronos_zs_rollout_metrics[metric_name])\n",
    ")\n",
    "mean_metric_baseline_mean, median_metric_baseline_mean, _, ste_metric_baseline_mean = (\n",
    "    calculate_stats(baseline_mean_rollout_metrics[metric_name])\n",
    ")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Plot each model\n",
    "plot_model_results(mean_metric_ours, ste_metric_ours, \"o\", label=\"Our Model\")\n",
    "plot_model_results(\n",
    "    mean_metric_chronos_ft, ste_metric_chronos_ft, \"s\", label=\"Chronos 20M SFT\"\n",
    ")\n",
    "plot_model_results(\n",
    "    mean_metric_chronos_zs, ste_metric_chronos_zs, \"v\", label=\"Chronos ZS\"\n",
    ")\n",
    "plot_model_results(\n",
    "    mean_metric_baseline_mean,\n",
    "    ste_metric_baseline_mean,\n",
    "    \"D\",\n",
    "    label=\"Mean Baseline\",\n",
    "    color=\"gray\",\n",
    ")\n",
    "\n",
    "# Add labels and show\n",
    "plt.xlabel(\"Prediction Length\", fontweight=\"bold\")\n",
    "plt.xticks(list(mean_metric_ours.keys()))\n",
    "# plt.title(\"ECG\", fontweight=\"bold\")\n",
    "plt.ylabel(metric_name_title, fontweight=\"bold\")\n",
    "# plt.title(metric_name_title, fontweight=\"bold\")\n",
    "# Set y-axis to use scientific notation\n",
    "# plt.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.ylim(13, None)\n",
    "\n",
    "plt.legend(loc=\"lower center\", frameon=True, ncol=2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../figures/ecg_all_models_{metric_name}.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
