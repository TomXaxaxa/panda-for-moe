{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.metrics import compute_metrics\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import safe_standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_model = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/pft_chattn_emb_w_poly-0/checkpoint-final\",\n",
    "    device_map=\"cuda:1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos = ChronosPipeline.from_pretrained(\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_bolt_mini-12/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    model,\n",
    "    context: np.ndarray,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: The model to use for forecasting.\n",
    "        context: The context to forecast (n_timesteps, n_features)\n",
    "        context_length: The length of the context.\n",
    "        prediction_length: The length of the prediction.\n",
    "        transpose: Whether to transpose the data.\n",
    "\n",
    "    Returns:\n",
    "        The forecasted data (prediction_length, n_features)\n",
    "    \"\"\"\n",
    "    preprocessed_context = context.copy().T if transpose else context.copy()\n",
    "    if standardize:\n",
    "        preprocessed_context = safe_standardize(\n",
    "            preprocessed_context, axis=int(transpose)\n",
    "        )\n",
    "    context_tensor = torch.from_numpy(preprocessed_context).float()\n",
    "    pred = (\n",
    "        model.predict(context_tensor, prediction_length, verbose=False, **kwargs)\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    if transpose:\n",
    "        pred = pred.T\n",
    "\n",
    "    if standardize:\n",
    "        pred = safe_standardize(pred, axis=0, context=context, denormalize=True)\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "def compute_rollout_metrics(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    step: int = 64,\n",
    "    num_windows: int = 5,\n",
    "    metrics: list[str] = [\"mse\", \"mae\", \"smape\"],\n",
    "    **kwargs,\n",
    ") -> tuple[dict[str, np.ndarray], dict[str, np.ndarray], np.ndarray, list[np.ndarray]]:\n",
    "    full_metrics = defaultdict(\n",
    "        lambda: np.zeros((num_windows, prediction_length // step))\n",
    "    )\n",
    "    starts = np.random.randint(\n",
    "        0, len(data) - context_length - prediction_length, num_windows\n",
    "    )\n",
    "    predictions = []\n",
    "    for s in tqdm(range(num_windows), desc=\"Sampling contexts\", total=num_windows):\n",
    "        start = starts[s]\n",
    "        context = data[start : start + context_length]\n",
    "        prediction = forecast(model, context, prediction_length, **kwargs)\n",
    "        for i in range(0, prediction_length, step):\n",
    "            pred = prediction[i : i + step]\n",
    "\n",
    "            gt = data[start + context_length + i : start + context_length + i + step]\n",
    "            submetrics = compute_metrics(pred, gt, include=metrics)\n",
    "            for k, v in submetrics.items():\n",
    "                full_metrics[k][s, i // step] += v\n",
    "        predictions.append(prediction)\n",
    "    mean_metrics = {k: v.mean(axis=0) for k, v in full_metrics.items()}\n",
    "    std_metrics = {\n",
    "        k: v.std(axis=0) / np.sqrt(num_windows) for k, v in full_metrics.items()\n",
    "    }\n",
    "    return mean_metrics, std_metrics, starts, predictions\n",
    "\n",
    "\n",
    "def plot_model_prediction(\n",
    "    model,\n",
    "    data: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    transpose: bool = False,\n",
    "    standardize: bool = True,\n",
    "    save_path: str | None = None,\n",
    "    color: str = \"red\",\n",
    "    **kwargs,\n",
    "):\n",
    "    context = data[:context_length]\n",
    "    groundtruth = data[context_length : context_length + prediction_length]\n",
    "    prediction = forecast(\n",
    "        model, context, prediction_length, transpose, standardize, **kwargs\n",
    "    )\n",
    "\n",
    "    total_length = context_length + prediction_length\n",
    "    context_ts = np.arange(context_length + 1)\n",
    "    pred_ts = np.arange(context_length, total_length)\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    outer_grid = fig.add_gridspec(1, 2, width_ratios=[0.5, 0.5], wspace=0.05)\n",
    "    gs = outer_grid[1].subgridspec(3, 1, height_ratios=[1 / 3] * 3, wspace=0, hspace=0)\n",
    "    ax_3d = fig.add_subplot(outer_grid[0], projection=\"3d\")\n",
    "    ax_3d.plot(*context.T[:3], alpha=0.5, color=\"black\", label=\"Context\")\n",
    "    ax_3d.plot(*groundtruth.T[:3], linestyle=\"--\", color=\"black\", label=\"Groundtruth\")\n",
    "    ax_3d.plot(*prediction.T[:3], color=color, label=\"Prediction\")\n",
    "    ax_3d.legend(loc=\"upper right\", fontsize=8)\n",
    "    ax_3d.set_xlabel(\"$x_1$\")\n",
    "    ax_3d.set_ylabel(\"$x_2$\")\n",
    "    ax_3d.set_zlabel(\"$x_3$\")\n",
    "\n",
    "    axes_1d = [fig.add_subplot(gs[i, 0]) for i in range(3)]\n",
    "    for i, ax in enumerate(axes_1d):\n",
    "        ax.plot(context_ts, data[: context_length + 1, i], alpha=0.5, color=\"black\")\n",
    "        ax.plot(pred_ts, groundtruth[:, i], linestyle=\"--\", color=\"black\")\n",
    "        ax.plot(pred_ts, prediction[:, i], color=color)\n",
    "        ax.set_ylabel(f\"$x_{i + 1}$\")\n",
    "        ax.set_aspect(\"auto\")\n",
    "    axes_1d[-1].set_xlabel(\"Time\")\n",
    "\n",
    "    if save_path is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(save_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    data: np.ndarray,\n",
    "    pft_prediction: np.ndarray,\n",
    "    chronos_prediction: np.ndarray,\n",
    "    context_length: int,\n",
    "    prediction_length: int,\n",
    "    pft_metrics: dict[str, list[float]],\n",
    "    chronos_metrics: dict[str, list[float]],\n",
    "    step: int = 8,\n",
    "    metric: str = \"smape\",\n",
    "    num_ticks: int = 4,\n",
    "):\n",
    "    context = data[: context_length + 1, :3]\n",
    "    groundtruth = data[context_length : context_length + prediction_length, :3]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax._axis3don = False\n",
    "\n",
    "    xmin, ymin, zmin = np.min(\n",
    "        np.stack(\n",
    "            [\n",
    "                context.min(axis=0),\n",
    "                groundtruth.min(axis=0),\n",
    "                pft_prediction[:, :3].min(axis=0),\n",
    "                chronos_prediction[:, :3].min(axis=0),\n",
    "            ]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    xmax, ymax, zmax = np.max(\n",
    "        np.stack(\n",
    "            [\n",
    "                context.max(axis=0),\n",
    "                groundtruth.max(axis=0),\n",
    "                pft_prediction[:, :3].max(axis=0),\n",
    "                chronos_prediction[:, :3].max(axis=0),\n",
    "            ]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    ax.xaxis.pane.set_visible(False)\n",
    "    ax.yaxis.pane.set_visible(False)\n",
    "    ax.zaxis.pane.set_visible(False)\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    ax.plot3D(*context.T, alpha=0.1, color=\"black\")\n",
    "    ax.plot3D(*groundtruth.T, alpha=0.5, color=\"black\", linestyle=\"--\")\n",
    "    ax.plot3D(*pft_prediction[:, :3].T, color=\"red\")\n",
    "    ax.plot3D(*chronos_prediction[:, :3].T, color=\"blue\")\n",
    "\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        xmax - xmin,\n",
    "        0,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        -ymax + ymin,\n",
    "        0,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.quiver(\n",
    "        xmin,\n",
    "        ymax,\n",
    "        zmin,\n",
    "        0,\n",
    "        0,\n",
    "        zmax - zmin,\n",
    "        color=\"black\",\n",
    "        linewidth=2,\n",
    "        arrow_length_ratio=0.05,\n",
    "        zorder=5,\n",
    "    )\n",
    "    ax.text(xmax + 1, ymax - 0.5, zmin, \"X\", fontsize=12)\n",
    "    ax.text(xmin, ymin - 2, zmin, \"Y\", fontsize=12)\n",
    "    ax.text(xmin - 0.5, ymax, zmax + 1, \"Z\", fontsize=12)\n",
    "\n",
    "    steps = np.arange(0, prediction_length, step)\n",
    "    axins = inset_axes(\n",
    "        plt.gca(), width=\"40%\", height=\"20%\", loc=\"upper right\", borderpad=1\n",
    "    )\n",
    "    axins.plot(steps + step, pft_metrics[metric], color=\"red\")\n",
    "    axins.plot(steps + step, chronos_metrics[metric], color=\"blue\")\n",
    "    axins.set_ylabel(metric)\n",
    "    axins.set_xlabel(\"Prediction Length\")\n",
    "    axins.set_xticks(\n",
    "        np.arange(\n",
    "            prediction_length // num_ticks,\n",
    "            prediction_length + prediction_length // num_ticks,\n",
    "            prediction_length // num_ticks,\n",
    "        )\n",
    "    )\n",
    "    axins.set_xlim(step, prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = \"train\"\n",
    "INDEX = 0\n",
    "WORK = os.environ.get(\"WORK\", \"\")\n",
    "base_dir = f\"{WORK}/physics-datasets\"\n",
    "fpath = f\"{base_dir}/double_pendulum_chaotic/train_and_test_split/dpc_dataset_traintest_4_200_csv/{SPLIT}/{INDEX}.csv\"\n",
    "pendulum_data = np.loadtxt(fpath)\n",
    "print(pendulum_data.shape)\n",
    "\n",
    "# data is non-stationary, subsample and detrend it\n",
    "subsampled_pendulum_data = pendulum_data[::10, -4:]\n",
    "subsampled_pendulum_diff = np.diff(subsampled_pendulum_data, axis=0)\n",
    "\n",
    "## The position of the pivot point (mostly constant)\n",
    "plt.plot(pendulum_data[:, 1], -pendulum_data[:, 0])\n",
    "\n",
    "## The position of the tip of the first pendulum\n",
    "plt.plot(pendulum_data[:, 3], -pendulum_data[:, 2])\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(pendulum_data[:, 5], -pendulum_data[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "metrics = [\"mse\", \"mae\", \"smape\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "# pft_prediction = subsampled_pendulum_data[context_length] + pft_diff_prediction.cumsum(\n",
    "#     axis=0\n",
    "# )\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        subsampled_pendulum_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos,\n",
    "    subsampled_pendulum_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "### Chronos diff prediction is bad\n",
    "# chronos_prediction = subsampled_pendulum_data[context_length] + chronos_diff_prediction.cumsum(\n",
    "#     axis=0\n",
    "# )\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        subsampled_pendulum_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "## The position of the tip of the second pendulum\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[:context_length, 3],\n",
    "    -subsampled_pendulum_data[:context_length, 2],\n",
    "    alpha=0.1,\n",
    "    color=\"black\",\n",
    ")\n",
    "plt.plot(\n",
    "    subsampled_pendulum_data[context_length : context_length + prediction_length, 3],\n",
    "    -subsampled_pendulum_data[context_length : context_length + prediction_length, 2],\n",
    "    alpha=0.5,\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "plt.plot(pft_prediction[:, 3], -pft_prediction[:, 2], color=\"red\")\n",
    "plt.plot(chronos_prediction[:, 3], -chronos_prediction[:, 2], color=\"blue\")\n",
    "\n",
    "steps = np.arange(0, prediction_length, step)\n",
    "axins = inset_axes(plt.gca(), width=\"40%\", height=\"20%\", loc=\"upper right\", borderpad=1)\n",
    "axins.plot(steps + step, pft_metrics[\"smape\"], color=\"red\")\n",
    "axins.plot(steps + step, chronos_metrics[\"smape\"], color=\"blue\")\n",
    "axins.set_ylabel(\"sMAPE\")\n",
    "axins.set_xlabel(\"Prediction Length\")\n",
    "axins.set_xticks([32, 64, 96, 128])\n",
    "axins.set_xlim(step, prediction_length);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "context_ts = np.arange(context_length + 1)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        context_ts,\n",
    "        subsampled_pendulum_data[: context_length + 1, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    ax.plot(\n",
    "        pred_ts,\n",
    "        subsampled_pendulum_data[\n",
    "            context_length : context_length + prediction_length, i\n",
    "        ],\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.plot(pred_ts, pft_prediction[:, i], color=\"red\")\n",
    "    ax.plot(pred_ts, chronos_prediction[:, i], color=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_mean_metrics, pft_std_metrics, pft_starts, pft_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        pft_model,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        sliding_context=True,\n",
    "        limit_prediction_length=False,\n",
    "    )\n",
    ")\n",
    "chronos_mean_metrics, chronos_std_metrics, chronos_starts, chronos_predictions = (\n",
    "    compute_rollout_metrics(\n",
    "        chronos,\n",
    "        subsampled_pendulum_data,\n",
    "        context_length,\n",
    "        prediction_length,\n",
    "        step=8,\n",
    "        num_windows=10,\n",
    "        limit_prediction_length=False,\n",
    "        num_samples=1,\n",
    "        deterministic=True,\n",
    "        transpose=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "\n",
    "total_ts = np.arange(len(subsampled_pendulum_data))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.plot(\n",
    "        total_ts,\n",
    "        subsampled_pendulum_data[:, i],\n",
    "        color=\"black\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    for j, (c, p) in enumerate(zip(chronos_starts, pft_starts)):\n",
    "        pft_pred_ts = np.arange(\n",
    "            p + context_length, p + context_length + prediction_length\n",
    "        )\n",
    "        chronos_context_ts = np.arange(c, c + context_length)\n",
    "        chronos_pred_ts = np.arange(\n",
    "            c + context_length, c + context_length + prediction_length\n",
    "        )\n",
    "        ax.plot(pft_pred_ts, pft_predictions[j][:, i], color=\"red\", alpha=0.1)\n",
    "        ax.plot(chronos_pred_ts, chronos_predictions[j][:, i], color=\"blue\", alpha=0.1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenworms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = 9\n",
    "fpath = f\"{base_dir}/worm_behavior/data/worm_{INDEX}.pkl\"\n",
    "worm_data = np.load(fpath, allow_pickle=True)[2048::1]\n",
    "eigenworms = loadmat(f\"{base_dir}/worm_behavior/data/EigenWorms.mat\")[\"EigenWorms\"]\n",
    "\n",
    "# de-NaN the data with linear interpolation\n",
    "time_idx = np.arange(len(worm_data))\n",
    "for d in range(worm_data.shape[1]):\n",
    "    mask = np.isnan(worm_data[:, d])\n",
    "    if mask.any():\n",
    "        valid = ~mask\n",
    "        worm_data[:, d] = np.interp(time_idx, time_idx[valid], worm_data[valid, d])\n",
    "assert not np.isnan(worm_data).any()\n",
    "\n",
    "print(worm_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "def reconstruct_worm(coeffs, eigenworms, segment_length=1.0):\n",
    "    \"\"\"\n",
    "    Reconstruct a worm from its coefficients and the eigenworms.\n",
    "\n",
    "    Args:\n",
    "        coeffs: The coefficients of the worm (n_timesteps, n_eigenworms)\n",
    "        eigenworms: The eigenworms (n_features, n_eigenworms)\n",
    "        segment_length: The length of each segment of the worm.\n",
    "\n",
    "    Returns:\n",
    "        The reconstructed worm.\n",
    "    \"\"\"\n",
    "    T, nworms = coeffs.shape\n",
    "    n_segments = eigenworms.shape[0]\n",
    "    basis = eigenworms[:, :nworms]\n",
    "    theta = coeffs @ basis.T\n",
    "\n",
    "    x = np.zeros((T, n_segments + 1))\n",
    "    y = np.zeros((T, n_segments + 1))\n",
    "    x[:, 1:] = segment_length * np.cos(theta)\n",
    "    y[:, 1:] = segment_length * np.sin(theta)\n",
    "\n",
    "    return x.cumsum(axis=1), y.cumsum(axis=1)\n",
    "\n",
    "\n",
    "def animate_worm(x, y, num_frames=200, interval=50, save_path=None):\n",
    "    \"\"\"\n",
    "    Create an animation of the worm's movement over time.\n",
    "\n",
    "    Args:\n",
    "        x: Array of x coordinates with shape (T, n_segments+1)\n",
    "        y: Array of y coordinates with shape (T, n_segments+1)\n",
    "        num_frames: Number of frames to include in the animation\n",
    "        interval: Time between frames in milliseconds\n",
    "\n",
    "    Returns:\n",
    "        HTML animation that can be displayed in the notebook\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Set consistent axis limits for the animation\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "\n",
    "    # Add some padding to the limits\n",
    "    x_padding = (x_max - x_min) * 0.1\n",
    "    y_padding = (y_max - y_min) * 0.1\n",
    "\n",
    "    ax.set_xlim(x_min - x_padding, x_max + x_padding)\n",
    "    ax.set_ylim(y_min - y_padding, y_max + y_padding)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(\"Worm Movement\")\n",
    "\n",
    "    # Create line and fill objects\n",
    "    line = ax.plot([], [], \"b-\", lw=2)[0]\n",
    "    fill = ax.fill([], [], color=\"blue\")\n",
    "    time_text = ax.text(0.02, 0.95, \"\", transform=ax.transAxes)\n",
    "\n",
    "    # Calculate width profile - increases toward middle, decreases toward ends\n",
    "    n_points = x.shape[1]\n",
    "    width_profile = np.zeros(n_points)\n",
    "    max_width = 3  # Maximum width of the worm body\n",
    "    for i in range(n_points):\n",
    "        arg = 2 * i / (n_points - 1) - 1  # normalize to [-1, 1]\n",
    "        width_profile[i] = max_width * (\n",
    "            1\n",
    "            / (1 + np.exp(-8 * (arg + 0.7)))\n",
    "            * (1 - 1 / (1 + np.exp(-8 * (arg - 0.7))))\n",
    "        )\n",
    "\n",
    "    def init():\n",
    "        line.set_data([], [])\n",
    "        fill[0].set_xy(np.zeros((0, 2)))\n",
    "        time_text.set_text(\"\")\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    def update(frame):\n",
    "        # Update the centerline\n",
    "        line.set_data(x[frame], y[frame])\n",
    "\n",
    "        # Calculate perpendicular vectors for width\n",
    "        dx = np.diff(x[frame])\n",
    "        dy = np.diff(y[frame])\n",
    "        # Normalize and rotate 90 degrees to get perpendicular direction\n",
    "        lengths = np.sqrt(dx**2 + dy**2)\n",
    "        nx = -dy / lengths\n",
    "        ny = dx / lengths\n",
    "\n",
    "        # Create polygon vertices for the worm body\n",
    "        vertices = []\n",
    "\n",
    "        # Top edge (add points from head to tail)\n",
    "        for i in range(n_points - 1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] + width_profile[i] * nx[i],\n",
    "                    y[frame][i] + width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Bottom edge (add points from tail to head)\n",
    "        for i in range(n_points - 2, -1, -1):\n",
    "            vertices.append(\n",
    "                (\n",
    "                    x[frame][i] - width_profile[i] * nx[i],\n",
    "                    y[frame][i] - width_profile[i] * ny[i],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Update the fill\n",
    "        fill[0].set_xy(vertices)\n",
    "        time_text.set_text(f\"Frame: {frame}\")\n",
    "\n",
    "        return line, fill[0], time_text\n",
    "\n",
    "    # Use a subset of frames if there are too many\n",
    "    total_frames = min(num_frames, len(x))\n",
    "    frame_indices = np.linspace(0, len(x) - 1, total_frames, dtype=int)\n",
    "\n",
    "    anim = FuncAnimation(\n",
    "        fig, update, frames=frame_indices, init_func=init, blit=True, interval=interval\n",
    "    )\n",
    "    if save_path is not None:\n",
    "        anim.save(save_path, writer=\"ffmpeg\")\n",
    "    plt.close()\n",
    "    return HTML(anim.to_jshtml())\n",
    "\n",
    "\n",
    "# Create and display the animation\n",
    "x, y = reconstruct_worm(worm_data, eigenworms)\n",
    "worm_animation = animate_worm(x[:1000], y[:1000], save_path=\"../figures/wormanim.mp4\")\n",
    "\n",
    "worm_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 128\n",
    "\n",
    "diffed_worm_data = np.diff(worm_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    pft_model,\n",
    "    diffed_worm_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "pft_prediction = worm_data[context_length] + diff_prediction.cumsum(axis=0)\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        worm_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    chronos,\n",
    "    diffed_worm_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "chronos_prediction = worm_data[context_length] + diff_prediction.cumsum(axis=0)\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        worm_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    worm_data,\n",
    "    pft_prediction,\n",
    "    chronos_prediction,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    pft_metrics,\n",
    "    chronos_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    worm_data,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    worm_data,\n",
    "    context_length=context_length,\n",
    "    prediction_length=prediction_length,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbulent Boundary Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbpca_data = np.load(\n",
    "    f\"{base_dir}/turbulence/BLexp_Re980_pca10.pkl\", allow_pickle=True\n",
    ")\n",
    "print(turbpca_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "\n",
    "diffed_turbpca_data = np.diff(turbpca_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    pft_model,\n",
    "    diffed_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "pft_prediction = turbpca_data[context_length] + diff_prediction.cumsum(axis=0)\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        turbpca_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_prediction = forecast(\n",
    "    chronos,\n",
    "    diffed_turbpca_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "chronos_prediction = turbpca_data[context_length] + diff_prediction.cumsum(axis=0)\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        turbpca_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    turbpca_data,\n",
    "    pft_prediction,\n",
    "    chronos_prediction,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    pft_metrics,\n",
    "    chronos_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    turbpca_data,\n",
    "    512,\n",
    "    512,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    turbpca_data,\n",
    "    512,\n",
    "    512,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electronic Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netfpath = f\"{base_dir}/electronic_circuit/Structure/Net_1.dat\"\n",
    "fpath = f\"{base_dir}/electronic_circuit/R1/ST_0_3.dat\"\n",
    "net = np.loadtxt(netfpath)\n",
    "circuit_data = np.loadtxt(fpath)\n",
    "print(net.shape, circuit_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        circuit_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos,\n",
    "    circuit_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        circuit_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(\n",
    "    circuit_data,\n",
    "    pft_prediction,\n",
    "    chronos_prediction,\n",
    "    context_length,\n",
    "    prediction_length,\n",
    "    pft_metrics,\n",
    "    chronos_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "_ = plot_model_prediction(\n",
    "    pft_model,\n",
    "    circuit_data,\n",
    "    512,\n",
    "    512,\n",
    "    sliding_context=True,\n",
    "    limit_prediction_length=False,\n",
    ")\n",
    "_ = plot_model_prediction(\n",
    "    chronos,\n",
    "    circuit_data,\n",
    "    512,\n",
    "    512,\n",
    "    transpose=True,\n",
    "    num_samples=1,\n",
    "    limit_prediction_length=False,\n",
    "    color=\"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coupling Strength Scaling Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify data by type {1, 2, 3} and sort by coupling strength\n",
    "fpaths = os.listdir(f\"{base_dir}/electronic_circuit/R1\")\n",
    "ec_fpaths = defaultdict(list)\n",
    "for fpath in fpaths:\n",
    "    ec_fpaths[int(fpath.split(\"_\")[2][0])].append(fpath)\n",
    "for k, v in ec_fpaths.items():\n",
    "    ec_fpaths[k] = sorted(v, key=lambda x: int(x.split(\"_\")[1]))\n",
    "print(ec_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "pft_errors = {\n",
    "    k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()\n",
    "}\n",
    "chronos_errors = {\n",
    "    k: {m: np.zeros((n_steps, len(v))) for m in metrics} for k, v in ec_fpaths.items()\n",
    "}\n",
    "for k, v in ec_fpaths.items():\n",
    "    for i, fpath in tqdm(\n",
    "        enumerate(v), desc=f\"Processing type-{k} circuit data\", total=len(v)\n",
    "    ):\n",
    "        circuit_data = np.loadtxt(f\"{base_dir}/electronic_circuit/R1/{fpath}\")\n",
    "        pft_prediction = forecast(\n",
    "            pft_model,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            sliding_context=True,\n",
    "        )\n",
    "        chronos_prediction = forecast(\n",
    "            chronos,\n",
    "            circuit_data[:context_length],\n",
    "            prediction_length,\n",
    "            transpose=True,\n",
    "            limit_prediction_length=False,\n",
    "            num_samples=1,\n",
    "        )\n",
    "        for chunk, j in enumerate(\n",
    "            np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "        ):\n",
    "            pft_submetrics = compute_metrics(\n",
    "                pft_prediction[0 : j + step],\n",
    "                circuit_data[context_length : context_length + j + step],\n",
    "                include=metrics,\n",
    "            )\n",
    "            chronos_submetrics = compute_metrics(\n",
    "                chronos_prediction[0 : j + step],\n",
    "                circuit_data[context_length : context_length + j + step],\n",
    "                include=metrics,\n",
    "            )\n",
    "            for metric in metrics:\n",
    "                pft_errors[k][metric][chunk, i] = pft_submetrics[metric]\n",
    "                chronos_errors[k][metric][chunk, i] = chronos_submetrics[metric]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pft_errors = {\n",
    "    m: np.mean([pft_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}\n",
    "mean_chronos_errors = {\n",
    "    m: np.mean([chronos_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}\n",
    "std_pft_errors = {\n",
    "    m: np.std([pft_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}\n",
    "std_chronos_errors = {\n",
    "    m: np.std([chronos_errors[k][m] for k in ec_fpaths], axis=0) for m in metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(mean_pft_errors[\"smape\"][-1], color=\"red\")\n",
    "plt.plot(mean_chronos_errors[\"smape\"][-1], color=\"blue\")\n",
    "plt.fill_between(\n",
    "    np.arange(len(mean_pft_errors[\"smape\"][-1])),\n",
    "    mean_pft_errors[\"smape\"][-1] - std_pft_errors[\"smape\"][-1],\n",
    "    mean_pft_errors[\"smape\"][-1] + std_pft_errors[\"smape\"][-1],\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.fill_between(\n",
    "    np.arange(len(mean_chronos_errors[\"smape\"][-1])),\n",
    "    mean_chronos_errors[\"smape\"][-1] - std_chronos_errors[\"smape\"][-1],\n",
    "    mean_chronos_errors[\"smape\"][-1] + std_chronos_errors[\"smape\"][-1],\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "plt.xlabel(\"Coupling Strength\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.title(\"%$\\Delta$sMAPE ($\\\\uparrow$ is better)\")\n",
    "percentage_error = (\n",
    "    chronos_errors[k][\"smape\"] - pft_errors[k][\"smape\"]\n",
    ") / chronos_errors[k][\"smape\"]\n",
    "plt.imshow(percentage_error, cmap=\"seismic\", label=f\"Type-{k}\", aspect=\"auto\")\n",
    "plt.ylabel(\"Prediction length\")\n",
    "plt.yticks(\n",
    "    np.arange(n_steps),\n",
    "    np.arange(0, prediction_length, prediction_length // n_steps)\n",
    "    + prediction_length // n_steps,\n",
    ")\n",
    "plt.xlabel(\"Coupling strength\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = f\"{base_dir}/electrocardiogram/ecg_train.csv.gz\"\n",
    "ecg_data = np.loadtxt(fpath, delimiter=\",\")\n",
    "print(ecg_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 512\n",
    "prediction_length = 512\n",
    "start = 0\n",
    "stride = 1\n",
    "\n",
    "subsampled_ecg_data = ecg_data[start::stride]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pft_prediction = forecast(\n",
    "    pft_model,\n",
    "    subsampled_ecg_data[:context_length],\n",
    "    prediction_length,\n",
    "    limit_prediction_length=False,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "pft_metrics = defaultdict(list)\n",
    "step = 8\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        pft_prediction[0 : i + step],\n",
    "        subsampled_ecg_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        pft_metrics[metric].append(submetrics[metric])\n",
    "print(pft_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_prediction = forecast(\n",
    "    chronos,\n",
    "    subsampled_ecg_data[:context_length],\n",
    "    prediction_length,\n",
    "    transpose=True,\n",
    "    limit_prediction_length=False,\n",
    "    num_samples=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "chronos_metrics = defaultdict(list)\n",
    "for i in np.arange(0, prediction_length, step):\n",
    "    submetrics = compute_metrics(\n",
    "        chronos_prediction[0 : i + step],\n",
    "        subsampled_ecg_data[context_length : context_length + i + step],\n",
    "        include=metrics,\n",
    "    )\n",
    "    for metric in metrics:\n",
    "        chronos_metrics[metric].append(submetrics[metric])\n",
    "print(chronos_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "context_ts = np.arange(context_length + 1)\n",
    "pred_ts = np.arange(context_length, context_length + prediction_length)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10), sharex=True)\n",
    "plt.subplots_adjust(hspace=0.0)\n",
    "axes[0].plot(\n",
    "    context_ts,\n",
    "    subsampled_ecg_data[: context_length + 1],\n",
    "    color=\"black\",\n",
    "    alpha=0.5,\n",
    "    label=\"context\",\n",
    ")\n",
    "axes[0].plot(\n",
    "    pred_ts,\n",
    "    subsampled_ecg_data[context_length : context_length + prediction_length],\n",
    "    color=\"black\",\n",
    "    linestyle=\"--\",\n",
    "    label=\"groundtruth\",\n",
    ")\n",
    "axes[0].plot(pred_ts, pft_prediction, color=\"red\", label=\"prediction\")\n",
    "axes[0].plot(pred_ts, chronos_prediction, color=\"blue\", label=\"chronos\")\n",
    "\n",
    "error_ts = (\n",
    "    np.arange(context_length - step, context_length + prediction_length, step) + step\n",
    ")\n",
    "ticks = np.arange(0, context_length + prediction_length + 128, 128)\n",
    "pft_with_zero = np.r_[0, pft_metrics[\"smape\"]]\n",
    "chronos_with_zero = np.r_[0, chronos_metrics[\"smape\"]]\n",
    "axes[1].plot(np.arange(context_length), np.zeros(context_length), color=\"red\")\n",
    "axes[1].plot(error_ts, pft_with_zero, color=\"red\")\n",
    "axes[1].plot(error_ts, chronos_with_zero, color=\"blue\")\n",
    "axes[1].set_xlabel(\"Prediction length\")\n",
    "axes[1].set_ylabel(\"sMAPE\")\n",
    "axes[1].set_xticks(np.arange(0, context_length + prediction_length + 128, 128))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
