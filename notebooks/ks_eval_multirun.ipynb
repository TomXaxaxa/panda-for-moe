{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.base import DynSys\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm import trange\n",
    "\n",
    "from dystformer.augmentations import StandardizeTransform\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../custom_style.mplstyle\"):\n",
    "    plt.style.use([\"ggplot\", \"../custom_style.mplstyle\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuramotoShivashinsky(DynSys):\n",
    "    \"\"\"Implements the 1+1D KS equation in fourier space\"\"\"\n",
    "\n",
    "    def __init__(self, L: float, modes: int):\n",
    "        super().__init__(metadata_path=None, dimension=2 * modes, parameters={})\n",
    "        self.L = L\n",
    "        self.modes = modes\n",
    "        self.dimension = 2 * self.modes\n",
    "        self.wave_nums = 2 * np.pi * np.arange(0, self.modes + 2) / self.L\n",
    "        self.N = self.dimension + 2\n",
    "\n",
    "        # precompute some quantities\n",
    "        self.freq_domain = np.zeros(self.modes + 2, dtype=np.complex128)\n",
    "        self.nonlinear_factor = -0.5 * 1j * self.wave_nums * self.N\n",
    "        self.diffusion_ffts = self.wave_nums**2 - self.wave_nums**4\n",
    "\n",
    "    def to_spatial(self, q: np.ndarray, N: int) -> np.ndarray:\n",
    "        \"\"\"Inverse FFT of the modes to get u(x) at a certain time\n",
    "\n",
    "        :param q: array of flattened fourier coefficients (real and imag components), can have batch dimensions\n",
    "        :param N: grid resolution in the spatial domain\n",
    "\n",
    "        :returns: solution in the spatial domain\n",
    "        \"\"\"\n",
    "        coeffs = np.zeros(q.shape[:-1] + (self.modes + 2,), dtype=complex)\n",
    "        coeffs[..., 1:-1] = q[..., : self.modes] + 1j * q[..., self.modes :]\n",
    "        return np.fft.irfft(coeffs, n=N)\n",
    "\n",
    "    def rhs(self, t: float, X: np.ndarray) -> np.ndarray:\n",
    "        self.freq_domain[1:-1] = X[: self.modes] + 1j * X[self.modes :]\n",
    "        u = np.fft.irfft(self.freq_domain, n=self.N)\n",
    "        pseudospectral_term = self.nonlinear_factor * np.fft.rfft(u * u)\n",
    "        linear_term = self.diffusion_ffts * self.freq_domain\n",
    "\n",
    "        # repackage components\n",
    "        flow = (linear_term + pseudospectral_term)[1:-1]\n",
    "        return np.concatenate([np.real(flow), np.imag(flow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = KuramotoShivashinsky(L=100, modes=64)\n",
    "\n",
    "tfinal = 100\n",
    "rng = np.random.default_rng(12)  # 1234\n",
    "ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "teval = np.linspace(0, tfinal, 4096)\n",
    "sol = solve_ivp(\n",
    "    ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8\n",
    ")\n",
    "ts, freq_traj = sol.t, sol.y.T\n",
    "spatial_traj = ks.to_spatial(freq_traj, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0, ks.L, ks.dimension)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.pcolormesh(ts, grid, spatial_traj.T, cmap=\"Spectral\", shading=\"gouraud\")\n",
    "plt.colorbar()\n",
    "plt.ylabel(\"x\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"  # \"pft_chattn_noembed_pretrained_correct-0\"\n",
    "pipeline = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=\"cuda:3\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    normalize: bool = True,\n",
    "    transpose: bool = False,\n",
    "    prediction_length: int | None = None,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    context = trajectory[:context_length]\n",
    "    if normalize:\n",
    "        normalizer = StandardizeTransform()\n",
    "        context = normalizer(context, axis=0)\n",
    "\n",
    "    if prediction_length is None:\n",
    "        prediction_length = trajectory.shape[0] - context_length\n",
    "\n",
    "    if transpose:\n",
    "        context = context.T\n",
    "\n",
    "    predictions = (\n",
    "        pipeline.predict(\n",
    "            context=torch.tensor(context).float(),\n",
    "            prediction_length=prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    full_trajectory = np.concatenate([context, predictions], axis=1 if transpose else 0)\n",
    "\n",
    "    if transpose:\n",
    "        full_trajectory = full_trajectory.T\n",
    "\n",
    "    if normalize:\n",
    "        return normalizer(\n",
    "            full_trajectory,\n",
    "            axis=0,\n",
    "            context=trajectory[:context_length],\n",
    "            denormalize=True,\n",
    "        )\n",
    "\n",
    "    return full_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(\n",
    "    ts: np.ndarray,\n",
    "    grid: np.ndarray,\n",
    "    trajectory: np.ndarray,\n",
    "    predictions: np.ndarray,\n",
    "    run_name: str = \"\",\n",
    "    context_length: int = 0,\n",
    "    save_path: str | None = None,\n",
    "    v_abs: float | None = None,\n",
    "    show_colorbar: bool = True,\n",
    "    show_ticks: bool = True,\n",
    "    display_pred_error: bool = True,\n",
    "    figsize: tuple[int, int] = (5, 5),\n",
    "    title_kwargs: dict = {},\n",
    "):\n",
    "    fig, axes = plt.subplots(3, 1, sharex=True, figsize=figsize)\n",
    "\n",
    "    vmin = min(trajectory.min(), predictions.min())\n",
    "    vmax = max(trajectory.max(), predictions.max())\n",
    "    vabs = max(abs(vmin), abs(vmax))\n",
    "    if v_abs is not None:\n",
    "        print(f\"Using v_abs: {v_abs} instead of {vabs}\")\n",
    "        vabs = v_abs\n",
    "\n",
    "    for i, (ax, data, label) in enumerate(\n",
    "        zip(\n",
    "            axes,\n",
    "            [trajectory, predictions, predictions - trajectory],\n",
    "            [\n",
    "                \"Ground Truth\",\n",
    "                f\"Predictions ({run_name})\",\n",
    "                f\"Prediction Error {f'({np.mean(np.abs(predictions - trajectory)):.2e}) ' if display_pred_error else ''}({run_name})\",\n",
    "            ],\n",
    "        )\n",
    "    ):\n",
    "        im = ax.pcolormesh(\n",
    "            ts, grid, data.T, cmap=\"Spectral\", shading=\"gouraud\", vmin=-vabs, vmax=vabs\n",
    "        )\n",
    "        if show_ticks:\n",
    "            ax.set_ylabel(\"x\")\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticks([])\n",
    "            ax.set_xticks([])\n",
    "        ax.set_title(label, **title_kwargs)\n",
    "        if show_colorbar:\n",
    "            fig.colorbar(im, ax=ax)\n",
    "        # draw black vertical line at middle of plot (x axis middle)\n",
    "        ax.axvline(ts[context_length], color=\"black\", linewidth=1)\n",
    "        if i == 2:\n",
    "            # draw a black dotted vertical line at the end of 128 pred length window\n",
    "            ax.axvline(\n",
    "                ts[context_length + 128], color=\"gray\", linestyle=\"--\", linewidth=1\n",
    "            )\n",
    "    if show_ticks:\n",
    "        axes[-1].set_xlabel(\"t\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 1024\n",
    "end_time = 2048\n",
    "context_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "preds_spatial = forecast(\n",
    "    pipeline,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    prediction_length=None,\n",
    "    normalize=True,\n",
    "    sliding_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    preds_spatial,\n",
    "    run_name=\"Our Model\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"figs_ks/ks_our_model_spatial.pdf\",\n",
    "    show_colorbar=True,\n",
    "    show_ticks=False,\n",
    "    display_pred_error=False,\n",
    "    figsize=(5, 6),\n",
    "    title_kwargs={\"fontweight\": \"bold\", \"fontsize\": 10},\n",
    "    # v_abs=0.025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 20\n",
    "parent_rng = np.random.default_rng(12)  # 1234\n",
    "rng_stream = parent_rng.spawn(n_runs)\n",
    "\n",
    "traj_lst = []\n",
    "\n",
    "for rng in rng_stream:\n",
    "    ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "    teval = np.linspace(0, tfinal, 4096)\n",
    "    sol = solve_ivp(\n",
    "        ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8\n",
    "    )\n",
    "    ts, freq_traj = sol.t, sol.y.T\n",
    "    spatial_traj = ks.to_spatial(freq_traj, N=ks.dimension)\n",
    "    traj_lst.append(spatial_traj)\n",
    "\n",
    "# traj_lst = np.array(traj_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "preds_spatial_lst = []\n",
    "\n",
    "for spatial_traj in traj_lst:\n",
    "    preds_spatial_curr = forecast(\n",
    "        pipeline,\n",
    "        spatial_traj[start_time:end_time],\n",
    "        context_length,\n",
    "        prediction_length=None,\n",
    "        normalize=True,\n",
    "        sliding_context=True,\n",
    "    )\n",
    "    preds_spatial_lst.append(preds_spatial_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_spatial_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape(x, y):\n",
    "    \"\"\"Symmetric mean absolute percentage error\"\"\"\n",
    "    return 100 * np.mean(np.abs(x - y) / (np.abs(x) + np.abs(y))) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_spatial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_error(prediction, ground_truth, time_intervals_lst):\n",
    "    pred_error_dict = {}\n",
    "    for time_interval in time_intervals_lst:\n",
    "        curr_mae = np.mean(\n",
    "            np.abs(prediction[:time_interval] - ground_truth[:time_interval])\n",
    "        )\n",
    "        curr_rmse = np.sqrt(\n",
    "            np.mean((prediction[:time_interval] - ground_truth[:time_interval]) ** 2)\n",
    "        )\n",
    "        curr_mse = np.mean(\n",
    "            (prediction[:time_interval] - ground_truth[:time_interval]) ** 2\n",
    "        )\n",
    "        curr_smape = smape(prediction[:time_interval], ground_truth[:time_interval])\n",
    "        error_dict = {\n",
    "            \"mae\": curr_mae,\n",
    "            \"rmse\": curr_rmse,\n",
    "            \"mse\": curr_mse,\n",
    "            \"smape\": curr_smape,\n",
    "        }\n",
    "        pred_error_dict[time_interval] = error_dict\n",
    "    return pred_error_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_intervals_lst = np.arange(64, 512 + 64, 64)\n",
    "print(time_intervals_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_lst[0][start_time:end_time][context_length:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_median_std_metrics_dicts_rollout(pred_lst):\n",
    "    pred_error_dict_lst = []\n",
    "    for preds, traj in zip(pred_lst, traj_lst):\n",
    "        actual_preds = preds[context_length:]\n",
    "        actual_gt = traj[start_time:end_time][context_length:]\n",
    "        print(actual_preds.shape, actual_gt.shape)\n",
    "        pred_error_dict_lst.append(\n",
    "            compute_pred_error(actual_preds, actual_gt, time_intervals_lst)\n",
    "        )\n",
    "\n",
    "    metrics_lst = [\"mse\", \"mae\", \"rmse\", \"smape\"]\n",
    "    metric_dict = defaultdict(dict)\n",
    "    for time_interval in pred_error_dict_lst[0].keys():\n",
    "        for metric in metrics_lst:\n",
    "            values = []\n",
    "            for pred_error_dict in pred_error_dict_lst:\n",
    "                values.append(pred_error_dict[time_interval][metric])\n",
    "            values = np.array(values)\n",
    "            mean_metric = np.mean(values, axis=0)\n",
    "            median_metric = np.median(values, axis=0)\n",
    "            std_metric = np.std(values, axis=0)\n",
    "            metric_dict[time_interval][metric] = {\n",
    "                \"mean\": mean_metric,\n",
    "                \"median\": median_metric,\n",
    "                \"std\": std_metric,\n",
    "            }\n",
    "\n",
    "    mean_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals_lst:\n",
    "        for metric in metrics_lst:\n",
    "            mean_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"mean\"]\n",
    "\n",
    "    median_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals_lst:\n",
    "        for metric in metrics_lst:\n",
    "            median_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"median\"]\n",
    "\n",
    "    std_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals_lst:\n",
    "        for metric in metrics_lst:\n",
    "            std_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"std\"]\n",
    "\n",
    "    return mean_metrics_dict, median_metrics_dict, std_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "    get_mean_median_std_metrics_dicts_rollout(preds_spatial_lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(mean_metrics_dict[\"mse\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(median_metrics_dict[\"mse\"].values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_bolt_mini-12/checkpoint-final\",\n",
    "    device_map=\"cuda:1\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_chronos(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    chunk_size: int,\n",
    ") -> np.ndarray:\n",
    "    subchannel_predictions = []\n",
    "    for i in trange(0, trajectory.shape[1] // chunk_size):\n",
    "        subpreds = forecast(\n",
    "            pipeline,\n",
    "            trajectory[:, i * chunk_size : (i + 1) * chunk_size],\n",
    "            context_length,\n",
    "            prediction_length=None,\n",
    "            transpose=True,\n",
    "            normalize=False,\n",
    "            num_samples=1,\n",
    "        )\n",
    "        subchannel_predictions.append(subpreds)\n",
    "\n",
    "    return np.concatenate(subchannel_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # predict in frequency domain\n",
    "# chronos_preds_freq = forecast_chronos(\n",
    "#     chronos, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    "# )\n",
    "\n",
    "# # convert to spatial domain\n",
    "# chronos_preds_freq_to_spatial = ks.to_spatial(chronos_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(\n",
    "#     ts[start_time:end_time],\n",
    "#     grid,\n",
    "#     spatial_traj[start_time:end_time],\n",
    "#     chronos_preds_freq_to_spatial,\n",
    "#     run_name=\"Chronos 20M Finetune\",\n",
    "#     context_length=context_length,\n",
    "#     save_path=\"ks_freq_to_spatial.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_ft_preds_spatial = forecast_chronos(\n",
    "    chronos_ft,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_ft_preds_spatial,\n",
    "    run_name=\"Chronos 20M Finetune\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"figs_ks/ks_chronos_ft_spatial.pdf\",\n",
    "    show_colorbar=True,\n",
    "    show_ticks=False,\n",
    "    display_pred_error=False,\n",
    "    # v_abs=0.025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "chronos_ft_preds_spatial_lst = []\n",
    "\n",
    "for spatial_traj in traj_lst:\n",
    "    chronos_ft_preds_spatial_curr = forecast_chronos(\n",
    "        chronos_ft,\n",
    "        spatial_traj[start_time:end_time],\n",
    "        context_length,\n",
    "        chunk_size=ks.dimension,\n",
    "    )\n",
    "    chronos_ft_preds_spatial_lst.append(chronos_ft_preds_spatial_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "    get_mean_median_std_metrics_dicts_rollout(chronos_ft_preds_spatial_lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=\"cuda:1\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chronos_zs_preds_freq = forecast_chronos(\n",
    "#     chronos_zs, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    "# )\n",
    "\n",
    "# # convert to spatial domain\n",
    "# chronos_zs_preds_freq_to_spatial = ks.to_spatial(chronos_zs_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_forecast(\n",
    "#     ts[start_time:end_time],\n",
    "#     grid,\n",
    "#     spatial_traj[start_time:end_time],\n",
    "#     chronos_zs_preds_freq_to_spatial,\n",
    "#     run_name=\"Chronos 20M\",\n",
    "#     context_length=context_length,\n",
    "#     save_path=\"ks_chronos_zs_freq_to_spatial.pdf\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_zs_preds_spatial = forecast_chronos(\n",
    "    chronos_zs,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_zs_preds_spatial,\n",
    "    run_name=\"Chronos 20M\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"figs_ks/ks_chronos_zs_spatial.pdf\",\n",
    "    show_colorbar=True,\n",
    "    show_ticks=False,\n",
    "    display_pred_error=False,\n",
    "    # v_abs=0.025,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "chronos_zs_preds_spatial_lst = []\n",
    "\n",
    "for spatial_traj in traj_lst:\n",
    "    chronos_zs_preds_spatial_curr = forecast_chronos(\n",
    "        chronos_zs,\n",
    "        spatial_traj[start_time:end_time],\n",
    "        context_length,\n",
    "        chunk_size=ks.dimension,\n",
    "    )\n",
    "    chronos_zs_preds_spatial_lst.append(chronos_zs_preds_spatial_curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "    get_mean_median_std_metrics_dicts_rollout(chronos_zs_preds_spatial_lst)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_spatial_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric_to_plot, title_metric_name in [\n",
    "    (\"smape\", \"sMAPE\"),\n",
    "    (\"mse\", \"MSE\"),\n",
    "    (\"mae\", \"MAE\"),\n",
    "    (\"rmse\", \"RMSE\"),\n",
    "]:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    for run_name, plist in zip(\n",
    "        [\"Our Model\", \"Chronos 20M Finetune\", \"Chronos 20M\"],\n",
    "        [preds_spatial_lst, chronos_ft_preds_spatial_lst, chronos_zs_preds_spatial_lst],\n",
    "    ):\n",
    "        mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "            get_mean_median_std_metrics_dicts_rollout(plist)\n",
    "        )\n",
    "        plt.plot(\n",
    "            time_intervals_lst,\n",
    "            list(median_metrics_dict[metric_to_plot].values()),\n",
    "            label=run_name,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            time_intervals_lst,\n",
    "            np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "            - np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "            / np.sqrt(len(time_intervals_lst)),\n",
    "            np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "            + np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "            / np.sqrt(len(time_intervals_lst)),\n",
    "            alpha=0.2,\n",
    "        )\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(f\"{title_metric_name}\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"figs_ks/ks_all_models_{metric_to_plot}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot with two subplots: one for smape and one for mae, stacked vertically\n",
    "plt.figure(figsize=(4, 6))\n",
    "\n",
    "# sMAPE subplot\n",
    "plt.subplot(2, 1, 1)\n",
    "for run_name, plist in zip(\n",
    "    [\"Our Model\", \"Chronos 20M Finetune\", \"Chronos 20M\"],\n",
    "    [preds_spatial_lst, chronos_ft_preds_spatial_lst, chronos_zs_preds_spatial_lst],\n",
    "):\n",
    "    mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "        get_mean_median_std_metrics_dicts_rollout(plist)\n",
    "    )\n",
    "    plt.plot(\n",
    "        time_intervals_lst,\n",
    "        list(median_metrics_dict[\"smape\"].values()),\n",
    "        label=run_name,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        time_intervals_lst,\n",
    "        np.array(list(mean_metrics_dict[\"smape\"].values()))\n",
    "        - np.array(list(std_metrics_dict[\"smape\"].values()))\n",
    "        / np.sqrt(len(time_intervals_lst)),\n",
    "        np.array(list(mean_metrics_dict[\"smape\"].values()))\n",
    "        + np.array(list(std_metrics_dict[\"smape\"].values()))\n",
    "        / np.sqrt(len(time_intervals_lst)),\n",
    "        alpha=0.2,\n",
    "    )\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"sMAPE\", fontweight=\"bold\")\n",
    "\n",
    "# MAE subplot\n",
    "plt.subplot(2, 1, 2)\n",
    "for run_name, plist in zip(\n",
    "    [\"Our Model\", \"Chronos 20M Finetune\", \"Chronos 20M\"],\n",
    "    [preds_spatial_lst, chronos_ft_preds_spatial_lst, chronos_zs_preds_spatial_lst],\n",
    "):\n",
    "    mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "        get_mean_median_std_metrics_dicts_rollout(plist)\n",
    "    )\n",
    "    plt.plot(\n",
    "        time_intervals_lst,\n",
    "        list(median_metrics_dict[\"mae\"].values()),\n",
    "        label=run_name,\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        time_intervals_lst,\n",
    "        np.array(list(mean_metrics_dict[\"mae\"].values()))\n",
    "        - np.array(list(std_metrics_dict[\"mae\"].values()))\n",
    "        / np.sqrt(len(time_intervals_lst)),\n",
    "        np.array(list(mean_metrics_dict[\"mae\"].values()))\n",
    "        + np.array(list(std_metrics_dict[\"mae\"].values()))\n",
    "        / np.sqrt(len(time_intervals_lst)),\n",
    "        alpha=0.2,\n",
    "    )\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.title(\"MAE\", fontweight=\"bold\")\n",
    "plt.xlabel(\"Prediction Length\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs_ks/ks_all_models_smape_mae.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
