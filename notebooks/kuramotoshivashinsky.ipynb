{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from dysts.base import DynSys\n",
    "from scipy.integrate import solve_ivp\n",
    "from tqdm import trange\n",
    "\n",
    "from dystformer.chronos.pipeline import ChronosPipeline\n",
    "from dystformer.patchtst.pipeline import PatchTSTPipeline\n",
    "from dystformer.utils import safe_standardize\n",
    "\n",
    "device_rank = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KuramotoShivashinsky(DynSys):\n",
    "    \"\"\"Implements the 1+1D KS equation in fourier space\"\"\"\n",
    "\n",
    "    def __init__(self, L: float, modes: int):\n",
    "        super().__init__(metadata_path=None, dimension=2 * modes, parameters={})\n",
    "        self.L = L\n",
    "        self.modes = modes\n",
    "        self.dimension = 2 * self.modes\n",
    "        self.wave_nums = 2 * np.pi * np.arange(0, self.modes + 2) / self.L\n",
    "        self.N = self.dimension + 2\n",
    "\n",
    "        # precompute some quantities\n",
    "        self.freq_domain = np.zeros(self.modes + 2, dtype=np.complex128)\n",
    "        self.nonlinear_factor = -0.5 * 1j * self.wave_nums * self.N\n",
    "        self.diffusion_ffts = self.wave_nums**2 - self.wave_nums**4\n",
    "\n",
    "    def to_spatial(self, q: np.ndarray, N: int) -> np.ndarray:\n",
    "        \"\"\"Inverse FFT of the modes to get u(x) at a certain time\n",
    "\n",
    "        :param q: array of flattened fourier coefficients (real and imag components), can have batch dimensions\n",
    "        :param N: grid resolution in the spatial domain\n",
    "\n",
    "        :returns: solution in the spatial domain\n",
    "        \"\"\"\n",
    "        coeffs = np.zeros(q.shape[:-1] + (self.modes + 2,), dtype=complex)\n",
    "        coeffs[..., 1:-1] = q[..., : self.modes] + 1j * q[..., self.modes :]\n",
    "        return np.fft.irfft(coeffs, n=N)\n",
    "\n",
    "    def rhs(self, t: float, X: np.ndarray) -> np.ndarray:\n",
    "        self.freq_domain[1:-1] = X[: self.modes] + 1j * X[self.modes :]\n",
    "        u = np.fft.irfft(self.freq_domain, n=self.N)\n",
    "        pseudospectral_term = self.nonlinear_factor * np.fft.rfft(u * u)\n",
    "        linear_term = self.diffusion_ffts * self.freq_domain\n",
    "\n",
    "        # repackage components\n",
    "        flow = (linear_term + pseudospectral_term)[1:-1]\n",
    "        return np.concatenate([np.real(flow), np.imag(flow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = KuramotoShivashinsky(L=100, modes=64)\n",
    "\n",
    "tfinal = 100\n",
    "rng = np.random.default_rng(12)  # 1234\n",
    "ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "teval = np.linspace(0, tfinal, 4096)\n",
    "sol = solve_ivp(\n",
    "    ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8\n",
    ")\n",
    "ts, freq_traj = sol.t, sol.y.T\n",
    "spatial_traj = ks.to_spatial(freq_traj, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.linspace(0, ks.L, ks.dimension)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.pcolormesh(ts, grid, spatial_traj.T, cmap=\"Spectral\", shading=\"gouraud\")\n",
    "plt.colorbar()\n",
    "plt.ylabel(\"x\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_trajectory(\n",
    "    trajectory: np.ndarray,\n",
    "    title: str = \"3D Trajectory\",\n",
    "    figsize: tuple[int, int] = (12, 8),\n",
    ") -> None:\n",
    "    \"\"\"Plot the first three dimensions of a trajectory in 3D space.\n",
    "\n",
    "    Args:\n",
    "        trajectory: Array of shape (T, D) where T is time steps and D is dimensions\n",
    "        title: Plot title\n",
    "        figsize: Figure size in inches (width, height)\n",
    "    \"\"\"\n",
    "    if trajectory.shape[1] < 3:\n",
    "        raise ValueError(\n",
    "            f\"Trajectory must have at least 3 dimensions, but has {trajectory.shape[1]}\"\n",
    "        )\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # Plot the trajectory\n",
    "    ax.plot(trajectory[:, 0], trajectory[:, 1], trajectory[:, 2])\n",
    "\n",
    "    # Add scatter points to show direction\n",
    "    n_points = min(20, len(trajectory))\n",
    "    indices = np.linspace(0, len(trajectory) - 1, n_points, dtype=int)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(indices)))\n",
    "\n",
    "    ax.scatter(\n",
    "        trajectory[indices, 0],\n",
    "        trajectory[indices, 1],\n",
    "        trajectory[indices, 2],\n",
    "        c=colors,\n",
    "        s=30,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"Dimension 1\")\n",
    "    ax.set_ylabel(\"Dimension 2\")\n",
    "    ax.set_zlabel(\"Dimension 3\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example: Plot the first 1000 time steps using the first 3 spatial points\n",
    "plot_3d_trajectory(freq_traj, title=\"KS Equation - First 3 Frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"pft_chattn_emb_w_poly-0\"\n",
    "pipeline = PatchTSTPipeline.from_pretrained(\n",
    "    mode=\"predict\",\n",
    "    pretrain_path=f\"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/{run_name}/checkpoint-final\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    normalize: bool = True,\n",
    "    transpose: bool = False,\n",
    "    prediction_length: int | None = None,\n",
    "    **kwargs,\n",
    ") -> np.ndarray:\n",
    "    context = trajectory[:context_length]\n",
    "    if normalize:\n",
    "        context = safe_standardize(context, axis=0)\n",
    "\n",
    "    if prediction_length is None:\n",
    "        prediction_length = trajectory.shape[0] - context_length\n",
    "\n",
    "    if transpose:\n",
    "        context = context.T\n",
    "\n",
    "    predictions = (\n",
    "        pipeline.predict(\n",
    "            context=torch.tensor(context).float(),\n",
    "            prediction_length=prediction_length,\n",
    "            limit_prediction_length=False,\n",
    "            **kwargs,\n",
    "        )\n",
    "        .squeeze()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "    full_trajectory = np.concatenate([context, predictions], axis=1 if transpose else 0)\n",
    "\n",
    "    if transpose:\n",
    "        full_trajectory = full_trajectory.T\n",
    "\n",
    "    if normalize:\n",
    "        return safe_standardize(\n",
    "            full_trajectory,\n",
    "            axis=0,\n",
    "            context=trajectory[:context_length],\n",
    "            denormalize=True,\n",
    "        )\n",
    "\n",
    "    return full_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_forecast(\n",
    "    ts: np.ndarray,\n",
    "    grid: np.ndarray,\n",
    "    trajectory: np.ndarray,\n",
    "    predictions: np.ndarray,\n",
    "    run_name: str = \"\",\n",
    "    context_length: int = 0,\n",
    "    save_path: str | None = None,\n",
    "    v_abs: float | None = None,\n",
    "    prediction_horizon: int = 128,\n",
    "):\n",
    "    fig, axes = plt.subplots(3, 1, sharex=True, figsize=(9, 9))\n",
    "\n",
    "    vmin = min(trajectory.min(), predictions.min())\n",
    "    vmax = max(trajectory.max(), predictions.max())\n",
    "    vabs = v_abs or max(abs(vmin), abs(vmax))\n",
    "\n",
    "    for i, (ax, data, label) in enumerate(\n",
    "        zip(\n",
    "            axes,\n",
    "            [trajectory, predictions, predictions - trajectory],\n",
    "            [\n",
    "                \"Ground Truth\",\n",
    "                f\"Predictions ({run_name})\",\n",
    "                f\"Prediction Error ({np.mean(np.abs(predictions - trajectory)):.2e}) ({run_name})\",\n",
    "            ],\n",
    "        )\n",
    "    ):\n",
    "        im = ax.pcolormesh(\n",
    "            ts, grid, data.T, cmap=\"Spectral\", shading=\"gouraud\", vmin=-vabs, vmax=vabs\n",
    "        )\n",
    "        ax.set_ylabel(\"x\")\n",
    "        ax.set_title(label, fontweight=\"bold\")\n",
    "        fig.colorbar(im, ax=ax)\n",
    "        # draw black vertical line at middle of plot (x axis middle)\n",
    "        ax.axvline(ts[context_length], color=\"black\", linewidth=1)\n",
    "        if i == 2:\n",
    "            # draw a black dotted vertical line at the end of 128 pred length window\n",
    "            ax.axvline(\n",
    "                ts[context_length + prediction_horizon],\n",
    "                color=\"gray\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=1,\n",
    "            )\n",
    "    axes[-1].set_xlabel(\"t\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches=\"tight\")\n",
    "\n",
    "    return vabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = 1024\n",
    "end_time = 2048\n",
    "context_length = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in frequency domain\n",
    "preds_freq = forecast(\n",
    "    pipeline,\n",
    "    freq_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    prediction_length=512,\n",
    "    normalize=True,\n",
    "    sliding_context=True,\n",
    ")\n",
    "\n",
    "# convert to spatial domain\n",
    "preds_freq_to_spatial = ks.to_spatial(preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_freq_vabs = plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    preds_freq_to_spatial,\n",
    "    run_name=\"Our Model\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_our_model_freq_to_spatial.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in spatial domain\n",
    "preds_spatial = forecast(\n",
    "    pipeline,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    prediction_length=None,\n",
    "    normalize=True,\n",
    "    sliding_context=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_spatial_vabs = plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    preds_spatial,\n",
    "    run_name=\"Our Model\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_our_model_spatial.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft = ChronosPipeline.from_pretrained(\n",
    "    \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_finetune_stand_updated-0/checkpoint-final\",\n",
    "    # \"/stor/work/AMDG_Gilpin_Summer2024/checkpoints/chronos_mini_ft-0/checkpoint-final\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_chronos(\n",
    "    pipeline,\n",
    "    trajectory: np.ndarray,\n",
    "    context_length: int,\n",
    "    chunk_size: int,\n",
    ") -> np.ndarray:\n",
    "    subchannel_predictions = []\n",
    "    for i in trange(0, trajectory.shape[1] // chunk_size):\n",
    "        subpreds = forecast(\n",
    "            pipeline,\n",
    "            trajectory[:, i * chunk_size : (i + 1) * chunk_size],\n",
    "            context_length,\n",
    "            prediction_length=None,\n",
    "            transpose=True,\n",
    "            normalize=False,\n",
    "            num_samples=1,\n",
    "        )\n",
    "        subchannel_predictions.append(subpreds)\n",
    "\n",
    "    return np.concatenate(subchannel_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict in frequency domain\n",
    "chronos_preds_freq = forecast_chronos(\n",
    "    chronos_ft, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    ")\n",
    "\n",
    "# convert to spatial domain\n",
    "chronos_preds_freq_to_spatial = ks.to_spatial(chronos_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_preds_freq_to_spatial,\n",
    "    run_name=\"Chronos 20M Finetune\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_chronos_ft_freq_to_spatial.pdf\",\n",
    "    v_abs=our_freq_vabs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_preds_spatial = forecast_chronos(\n",
    "    chronos_ft,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_preds_spatial,\n",
    "    run_name=\"Chronos 20M Finetune\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_chronos_ft_spatial.pdf\",\n",
    "    v_abs=our_spatial_vabs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs = ChronosPipeline.from_pretrained(\n",
    "    \"amazon/chronos-t5-mini\",\n",
    "    device_map=f\"cuda:{device_rank}\",\n",
    "    torch_dtype=torch.float32,\n",
    ")\n",
    "chronos_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_preds_freq = forecast_chronos(\n",
    "    chronos_zs, freq_traj[start_time:end_time], context_length, chunk_size=ks.dimension\n",
    ")\n",
    "\n",
    "# convert to spatial domain\n",
    "chronos_zs_preds_freq_to_spatial = ks.to_spatial(chronos_zs_preds_freq, N=ks.dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_zs_preds_freq_to_spatial,\n",
    "    run_name=\"Chronos 20M\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_chronos_zs_freq_to_spatial.pdf\",\n",
    "    v_abs=our_freq_vabs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial domain chronos prediction\n",
    "chronos_zs_preds_spatial = forecast_chronos(\n",
    "    chronos_zs,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    context_length,\n",
    "    chunk_size=ks.dimension,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(\n",
    "    ts[start_time:end_time],\n",
    "    grid,\n",
    "    spatial_traj[start_time:end_time],\n",
    "    chronos_zs_preds_spatial,\n",
    "    run_name=\"Chronos 20M\",\n",
    "    context_length=context_length,\n",
    "    save_path=\"../figures/ks_chronos_zs_spatial.pdf\",\n",
    "    v_abs=our_spatial_vabs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rollout Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from dysts.metrics import smape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeated for convenience\n",
    "start_time = 1024\n",
    "end_time = 2048\n",
    "context_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 20\n",
    "parent_rng = np.random.default_rng(12)\n",
    "rng_stream = parent_rng.spawn(n_runs)\n",
    "\n",
    "predict_spatial = True  # predict in spatial domain instead of frequency domain\n",
    "convert_to_spatial = False  # if prediction in freq domain, convert to spatial domain\n",
    "\n",
    "trajectories = []\n",
    "\n",
    "for rng in rng_stream:\n",
    "    ic = 0.1 * rng.normal(size=(ks.dimension,))\n",
    "    teval = np.linspace(0, tfinal, 4096)\n",
    "    sol = solve_ivp(\n",
    "        ks.rhs, (0, tfinal), ic, method=\"DOP853\", t_eval=teval, rtol=1e-8, atol=1e-8\n",
    "    )\n",
    "    ts, freq_traj = sol.t, sol.y.T\n",
    "    if predict_spatial:\n",
    "        trajectories.append(ks.to_spatial(freq_traj, N=ks.dimension))\n",
    "    else:\n",
    "        trajectories.append(freq_traj)\n",
    "\n",
    "time_intervals = [(0, end) for end in np.arange(64, 512 + 64, 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pred_error(prediction, ground_truth, time_intervals: list[tuple[int, int]]):\n",
    "    pred_error_dict = {}\n",
    "    for start, end in time_intervals:\n",
    "        curr_mae = np.mean(np.abs(prediction[start:end] - ground_truth[start:end]))\n",
    "        curr_rmse = np.sqrt(\n",
    "            np.mean((prediction[start:end] - ground_truth[start:end]) ** 2)\n",
    "        )\n",
    "        curr_mse = np.mean((prediction[start:end] - ground_truth[start:end]) ** 2)\n",
    "        curr_smape = smape(prediction[start:end], ground_truth[start:end])\n",
    "        error_dict = {\n",
    "            \"mae\": curr_mae,\n",
    "            \"rmse\": curr_rmse,\n",
    "            \"mse\": curr_mse,\n",
    "            \"smape\": curr_smape,\n",
    "        }\n",
    "        pred_error_dict[start, end] = error_dict\n",
    "    return pred_error_dict\n",
    "\n",
    "\n",
    "def get_mean_median_std_metrics_dicts_rollout(\n",
    "    predictions: list[np.ndarray],\n",
    "    trajectories: list[np.ndarray],\n",
    "    time_intervals: list[tuple[int, int]],\n",
    "):\n",
    "    pred_error_dict_lst = []\n",
    "    for preds, traj in zip(predictions, trajectories):\n",
    "        actual_preds = preds[context_length:]\n",
    "        actual_gt = traj[start_time:end_time][context_length:]\n",
    "        pred_error_dict_lst.append(\n",
    "            compute_pred_error(actual_preds, actual_gt, time_intervals)\n",
    "        )\n",
    "\n",
    "    metrics_lst = [\"mse\", \"mae\", \"rmse\", \"smape\"]\n",
    "    metric_dict = defaultdict(dict)\n",
    "    for time_interval in pred_error_dict_lst[0].keys():\n",
    "        for metric in metrics_lst:\n",
    "            values = []\n",
    "            for pred_error_dict in pred_error_dict_lst:\n",
    "                values.append(pred_error_dict[time_interval][metric])\n",
    "            values = np.array(values)\n",
    "            mean_metric = np.mean(values, axis=0)\n",
    "            median_metric = np.median(values, axis=0)\n",
    "            std_metric = np.std(values, axis=0)\n",
    "            metric_dict[time_interval][metric] = {\n",
    "                \"mean\": mean_metric,\n",
    "                \"median\": median_metric,\n",
    "                \"std\": std_metric,\n",
    "            }\n",
    "\n",
    "    mean_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            mean_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"mean\"]\n",
    "\n",
    "    median_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            median_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"median\"]\n",
    "\n",
    "    std_metrics_dict = defaultdict(dict)\n",
    "    for time_interval in time_intervals:\n",
    "        for metric in metrics_lst:\n",
    "            std_metrics_dict[metric][time_interval] = metric_dict[time_interval][\n",
    "                metric\n",
    "            ][\"std\"]\n",
    "\n",
    "    return mean_metrics_dict, median_metrics_dict, std_metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "\n",
    "for traj in trajectories:\n",
    "    sample_pred = forecast(\n",
    "        pipeline,\n",
    "        traj[start_time:end_time],\n",
    "        context_length,\n",
    "        prediction_length=None,\n",
    "        normalize=True,\n",
    "        sliding_context=True,\n",
    "    )\n",
    "    if convert_to_spatial and not predict_spatial:\n",
    "        sample_pred = ks.to_spatial(sample_pred, N=ks.dimension)\n",
    "    preds.append(sample_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_ft_preds = []\n",
    "\n",
    "for traj in trajectories:\n",
    "    chronos_ft_sample_pred = forecast_chronos(\n",
    "        chronos_ft,\n",
    "        traj[start_time:end_time],\n",
    "        context_length,\n",
    "        chunk_size=ks.dimension,\n",
    "    )\n",
    "    if convert_to_spatial and not predict_spatial:\n",
    "        chronos_ft_sample_pred = ks.to_spatial(chronos_ft_sample_pred, N=ks.dimension)\n",
    "    chronos_ft_preds.append(chronos_ft_sample_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chronos Zeroshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chronos_zs_preds = []\n",
    "\n",
    "for traj in trajectories:\n",
    "    chronos_zs_sample_pred = forecast_chronos(\n",
    "        chronos_zs,\n",
    "        traj[start_time:end_time],\n",
    "        context_length,\n",
    "        chunk_size=ks.dimension,\n",
    "    )\n",
    "    if convert_to_spatial and not predict_spatial:\n",
    "        chronos_zs_sample_pred = ks.to_spatial(chronos_zs_sample_pred, N=ks.dimension)\n",
    "    chronos_zs_preds.append(chronos_zs_sample_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_times = [end_time for _, end_time in time_intervals]\n",
    "for metric_to_plot, title_metric_name in [\n",
    "    (\"smape\", \"sMAPE\"),\n",
    "    (\"mse\", \"MSE\"),\n",
    "    (\"mae\", \"MAE\"),\n",
    "    (\"rmse\", \"RMSE\"),\n",
    "]:\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    for run_name, plist in zip(\n",
    "        [\"Our Model\", \"Chronos 20M Finetune\", \"Chronos 20M\"],\n",
    "        [preds, chronos_ft_preds, chronos_zs_preds],\n",
    "    ):\n",
    "        mean_metrics_dict, median_metrics_dict, std_metrics_dict = (\n",
    "            get_mean_median_std_metrics_dicts_rollout(\n",
    "                plist, trajectories, time_intervals\n",
    "            )\n",
    "        )\n",
    "        plt.plot(\n",
    "            end_times,\n",
    "            list(mean_metrics_dict[metric_to_plot].values()),\n",
    "            label=run_name,\n",
    "        )\n",
    "        plt.fill_between(\n",
    "            end_times,\n",
    "            np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "            - np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "            / np.sqrt(len(time_intervals)),\n",
    "            np.array(list(mean_metrics_dict[metric_to_plot].values()))\n",
    "            + np.array(list(std_metrics_dict[metric_to_plot].values()))\n",
    "            / np.sqrt(len(time_intervals)),\n",
    "            alpha=0.2,\n",
    "        )\n",
    "    plt.xticks(end_times)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(f\"{title_metric_name}\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"Prediction Length\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"../figures/ks_all_models_{metric_to_plot}.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dystformer_jeff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
